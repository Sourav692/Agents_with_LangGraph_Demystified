{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1"
      },
      "source": [
        "# Build an Augmented LLM with Tools in LangGraph\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this notebook, you will be able to:\n",
        "1. **Understand tool augmentation** - Learn why and how to give LLMs access to tools\n",
        "2. **Create custom tools** - Define tools using the `@tool` decorator\n",
        "3. **Bind tools to LLMs** - Attach tools to language models\n",
        "4. **Use LangGraph's ToolNode** - Leverage built-in tool execution\n",
        "\n",
        "## Why Augment LLMs with Tools?\n",
        "\n",
        "LLMs have inherent limitations:\n",
        "- **Knowledge cutoff** - Training data has a date limit\n",
        "- **No real-time access** - Can't fetch current information\n",
        "- **Limited computation** - Struggle with complex math\n",
        "- **No external actions** - Can't send emails, query databases, etc.\n",
        "\n",
        "**Tools** extend LLM capabilities by allowing them to:\n",
        "- Search the web for current information\n",
        "- Execute calculations accurately\n",
        "- Query databases and APIs\n",
        "- Perform actions in the real world\n",
        "\n",
        "## What We're Building\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│               AUGMENTED LLM ARCHITECTURE                        │\n",
        "├─────────────────────────────────────────────────────────────────┤\n",
        "│                                                                  │\n",
        "│  User Query ──► [LLM + Tools] ──►  Decision:                    │\n",
        "│                                     ├─► Answer directly         │\n",
        "│                                     └─► Call a tool             │\n",
        "│                                                                  │\n",
        "│  Tools Available:                                                │\n",
        "│    • search_web: Search the internet for information            │\n",
        "│    • (more tools can be added)                                  │\n",
        "│                                                                  │\n",
        "└─────────────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "We already know Tools help the LLM interact with external sources of information like web search.\n",
        "\n",
        "Augmented LLM with Search Tool: Here we will build a simple augmented LLM using the capabilities of Tavily Search as a tool to allow the LLM to fetch relevant information from the web when necessary.\n",
        "\n",
        "![](https://i.imgur.com/5r015dw.png)"
      ],
      "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# SETUP: Import dependencies and LLM helper functions\n",
        "# ============================================================================\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add parent directory to path for importing helpers\n",
        "sys.path.append(os.path.abspath(\"..\"))\n",
        "\n",
        "# Import LLM factory functions\n",
        "from helpers.utils import get_groq_llm, get_openai_llm\n",
        "\n",
        "print(\"Setup complete! Ready to build an augmented LLM.\")"
      ],
      "execution_count": 1,
      "outputs": [],
      "id": "c61d30d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8"
      },
      "source": [
        "## Step 1: Define the State\n",
        "\n",
        "For tool-augmented LLMs, the state needs to track messages which may include:\n",
        "- **HumanMessage** - User's input query\n",
        "- **AIMessage** - LLM's response (may contain tool calls)\n",
        "- **ToolMessage** - Results returned from tool execution\n",
        "\n",
        "The `add_messages` reducer ensures all these are preserved in order.\n",
        "\n",
        "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
      ],
      "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a90709b-ddfa-4671-8acc-c59969a29991"
      },
      "source": [
        "# ============================================================================\n",
        "# DEFINING STATE FOR TOOL-AUGMENTED LLM\n",
        "# ============================================================================\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    \"\"\"\n",
        "    State schema for tool-augmented LLM.\n",
        "    \n",
        "    The messages list will contain a mix of:\n",
        "    - HumanMessage: User queries\n",
        "    - AIMessage: LLM responses (possibly with tool_calls)\n",
        "    - ToolMessage: Results from tool execution\n",
        "    \n",
        "    Using add_messages reducer to preserve the full interaction history.\n",
        "    \"\"\"\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "execution_count": 2,
      "outputs": [],
      "id": "6a90709b-ddfa-4671-8acc-c59969a29991"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "888509e1-cbde-4c03-99a0-2560dd2e262d"
      },
      "source": [
        "## Step 2: Create and Bind Tools to the LLM\n",
        "\n",
        "### What is a Tool?\n",
        "A **tool** is a function that the LLM can decide to call. It consists of:\n",
        "1. **Function definition** - The actual Python code to execute\n",
        "2. **Name** - How the LLM refers to the tool\n",
        "3. **Description** - Helps the LLM decide when to use the tool\n",
        "4. **Parameters** - What inputs the tool expects\n",
        "\n",
        "### The @tool Decorator\n",
        "LangChain's `@tool` decorator transforms a Python function into a tool:\n",
        "- Automatically extracts the function name\n",
        "- Uses the docstring as the description\n",
        "- Infers parameter types from type hints\n",
        "\n",
        "### Binding Tools to LLMs\n",
        "`llm.bind_tools(tools)` creates an augmented LLM that:\n",
        "- Knows about available tools and their capabilities\n",
        "- Can decide whether to call a tool or respond directly\n",
        "- Generates structured tool call requests when needed\n",
        "\n",
        "Here we define our custom search tool and then bind it to the LLM to augment the LLM."
      ],
      "id": "888509e1-cbde-4c03-99a0-2560dd2e262d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lYXBn1ImzlB"
      },
      "source": [
        "# ============================================================================\n",
        "# CREATING AND BINDING TOOLS TO THE LLM\n",
        "# ============================================================================\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 1: Initialize the base LLM\n",
        "# We use Groq for fast inference (can swap to OpenAI)\n",
        "# -----------------------------------------------------------------------------\n",
        "llm = get_groq_llm()\n",
        "print(f\"Base LLM initialized\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 2: Create a search tool using Tavily\n",
        "# Tavily is a search API designed for AI applications\n",
        "# -----------------------------------------------------------------------------\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "@tool\n",
        "def search_web(query: str, num_results: int = 5):\n",
        "    \"\"\"\n",
        "    Search the web for a query. Useful for general information or general news.\n",
        "    \n",
        "    This docstring is CRITICAL - it tells the LLM:\n",
        "    - WHAT the tool does (search the web)\n",
        "    - WHEN to use it (for general info/news)\n",
        "    \n",
        "    Args:\n",
        "        query: The search query to look up\n",
        "        num_results: Number of results to return (default 5)\n",
        "        \n",
        "    Returns:\n",
        "        Search results from the web\n",
        "    \"\"\"\n",
        "    print(f\"  [Tool] Searching web for: '{query}'\")\n",
        "    results = tavily_search.raw_results(\n",
        "        query=query,\n",
        "        max_results=num_results,\n",
        "        search_depth='advanced',\n",
        "        include_raw_content=True\n",
        "    )\n",
        "    return results\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 3: Create the tools list and bind to LLM\n",
        "# bind_tools() creates an \"augmented\" LLM that knows about these tools\n",
        "# -----------------------------------------------------------------------------\n",
        "tools = [search_web]  # List of all available tools\n",
        "\n",
        "# Bind tools to the LLM\n",
        "# This creates a new LLM that can decide to call tools when needed\n",
        "llm_with_tools = llm.bind_tools(tools=tools)\n",
        "\n",
        "print(f\"LLM augmented with {len(tools)} tool(s): {[t.name for t in tools]}\")"
      ],
      "execution_count": 3,
      "outputs": [],
      "id": "2lYXBn1ImzlB"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# TEST: Call the tool directly\n",
        "# ============================================================================\n",
        "# We can invoke the tool directly to test it works\n",
        "# This is useful for debugging before integrating with the LLM\n",
        "\n",
        "print(\"Testing search_web tool directly:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "result = search_web.invoke('what is AI in 1 line')\n",
        "\n",
        "# Show a summary of results\n",
        "print(f\"\\nReturned {len(result.get('results', []))} results\")\n",
        "if result.get('results'):\n",
        "    print(f\"First result title: {result['results'][0].get('title', 'N/A')}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'what is AI in 1 line',\n",
              " 'response_time': 1.33,\n",
              " 'follow_up_questions': None,\n",
              " 'answer': None,\n",
              " 'images': [],\n",
              " 'results': [{'url': 'https://aws.amazon.com/what-is/artificial-intelligence/',\n",
              "   'title': 'What is Artificial Intelligence (AI)? - AWS',\n",
              "   'content': '## What Is Artificial Intelligence (AI)?\\n\\nArtificial Intelligence (AI) is a transformative technology that enables machines to perform human-like problem-solving tasks. From recognizing images and generating creative content to making data-driven predictions, AI empowers businesses to make smarter decisions at scale.\\n\\nIn today’s digital landscape, organizations generate vast amounts of data from sensors, user interactions, and system logs. AI harnesses this data to streamline operations—automating customer support, enhancing marketing strategies, and providing actionable insights through advanced analytics. [...] Artificial intelligence (AI) is an umbrella term for different strategies and techniques for making machines more human-like. It includes everything from self-driving cars to robotic vacuum cleaners and smart assistants like Alexa. While machine learning and deep learning fall under the AI umbrella, not all AI activities are machine learning and deep learning. For example, generative AI demonstrates human-like creative capabilities and is a very advanced form of deep learning.\\n\\n### Machine learning [...] Artificial intelligence architecture consists of three core layers, all supported by robust IT infrastructure that delivers the compute power and memory needed to run AI at scale. Each layer plays a critical role in enabling seamless AI operations, from data processing to advanced decision-making.\\n\\n### Layer 1: data layer\\n\\nAI is built upon various technologies, such as machine learning, natural language processing, and image recognition. Central to these technologies is data, which forms the foundational layer of AI. This layer primarily focuses on preparing the data for AI applications.\\n\\n### Layer 2: model layer',\n",
              "   'score': 0.9942697,\n",
              "   'raw_content': '* [Overview](/ai/)\\n* Products\\n* Learn\\n* [Our Story](/ai/our-story/)\\n* [Customers](/ai/generative-ai/customers/)\\n* More\\n\\n* [What is Cloud Computing](/what-is-cloud-computing/)›\\n* [Cloud Computing Concepts Hub](/what-is/)›\\n* [Artificial Intelligence](/what-is/artificial-intelligence/)›\\n* What is Artificial Intelligence (AI)?\\n\\n# What is Artificial Intelligence (AI)?\\n\\n[Create an AWS account](https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?pg=what_is_header)\\n\\n## Page topics\\n\\n* [What Is Artificial Intelligence (AI)?](#what-is-artificial-intelligence-ai--1xgrnvz)\\n* [What is the history of AI?](#what-is-the-history-of-ai--1xgrnvz)\\n* [What is the difference between machine learning, deep learning, and artificial intelligence?](#what-is-the-difference-between-machine-learning-deep-learning-and-artificial-intelligence--1xgrnvz)\\n* [How does AI work?](#how-does-ai-work--1xgrnvz)\\n* [What are the key components of AI application architecture?](#what-are-the-key-components-of-ai-application-architecture--1xgrnvz)\\n* [How are businesses harnessing the power of AI?](#how-are-businesses-harnessing-the-power-of-ai--1xgrnvz)\\n* [What is the power of AI technologies?](#what-is-the-power-of-ai-technologies--1xgrnvz)\\n* [How AI is transforming industries today?](#how-ai-is-transforming-industries-today--1xgrnvz)\\n* [What are the benefits of AI for business transformation?](#what-are-the-benefits-of-ai-for-business-transformation--1xgrnvz)\\n* [How do AI services and tools unlock business potential?](#how-do-ai-services-and-tools-unlock-business-potential--1xgrnvz)\\n* [What is Responsible AI?](#what-is-responsible-ai--1xgrnvz)\\n* [What are the challenges in artificial intelligence implementation?](#what-are-the-challenges-in-artificial-intelligence-implementation--1xgrnvz)\\n* [How can I start using artificial intelligence for my business?](#how-can-i-start-using-artificial-intelligence-for-my-business--1xgrnvz)\\n* [How can I start using artificial intelligence in my day-to-day life?](#how-can-i-start-using-artificial-intelligence-in-my-day-to-day-life--1xgrnvz)\\n* [What is AI innovation on AWS and how can you build and scale it?](#what-is-ai-innovation-on-aws-and-how-can-you-build-and-scale-it--1xgrnvz)\\n* [What is AI training for beginners?](#what-is-ai-training-for-beginners--1xgrnvz)\\n* [How customers are innovating with AI on AWS?](#how-customers-are-innovating-with-ai-on-aws--1xgrnvz)\\n* [How can AWS support your artificial intelligence requirements?](#how-can-aws-support-your-artificial-intelligence-requirements--1xgrnvz)\\n\\n## What Is Artificial Intelligence (AI)?\\n\\nArtificial Intelligence (AI) is a transformative technology that enables machines to perform human-like problem-solving tasks. From recognizing images and generating creative content to making data-driven predictions, AI empowers businesses to make smarter decisions at scale.\\n\\nIn today’s digital landscape, organizations generate vast amounts of data from sensors, user interactions, and system logs. AI harnesses this data to streamline operations—automating customer support, enhancing marketing strategies, and providing actionable insights through advanced analytics.\\n\\nWith AWS, businesses can seamlessly integrate AI to accelerate innovation, optimize customer experiences, and solve complex challenges. AWS\\'s AI solutions empower companies to deliver personalized interactions, automate decision-making, and unlock new growth opportunities in a rapidly evolving digital world—all while benefiting from AWS’s commitment to privacy, security, and responsible AI.\\n\\n## What is the history of AI?\\n\\nIn 1950, Alan Turing introduced the concept of artificial intelligence in his seminal paper, \"Computing Machinery and Intelligence,\" where he explored the possibility of machines thinking like humans. While Turing laid the theoretical groundwork, the AI we know today is the result of decades of innovation, shaped by the collective efforts of scientists and engineers advancing the technology across multiple fields.\\n\\n### 1940-1980\\n\\nIn 1943, Warren McCulloch and Walter Pitts proposed a model of artificial neurons, laying the foundation for neural networks, the core technology within AI.\\n\\nQuickly following, in 1950, Alan Turing published \"Computing Machinery and Intelligence,\" introducing the concept of the Turing Test to assess machine intelligence.\\n\\nThis lead to graduate students Marvin Minsky and Dean Edmonds building the first neural net machine known as the SNARC, Frank Rosenblatt developed the Perceptron which is one of the earliest models of a neural network, and Joseph Weizenbaum created ELIZA, one of the first chatbots to simulate a Rogerian psychotherapist between 1951 and 1969.\\n\\nFrom 1969 until 1979 Marvin Minsky demonstrated the limitations of neural networks, which caused a temporary decline in neural network research. The first \"AI winter\" occurred due to reduced funding and hardware and computing limitations.\\n\\n### 1980-2006\\n\\nThe 1980s marked a renewed surge of interest in AI, fueled by government funding and research, particularly in areas like translation and transcription. During this time, expert systems like MYCIN gained prominence by simulating human decision-making in specialized fields such as medicine. The revival of neural networks also took shape, with groundbreaking work from David Rumelhart and John Hopfield on deep learning techniques, demonstrating that computers could learn from experience.\\n\\nHowever, between 1987 and 1997, socio-economic factors, including the dot-com boom, led to a second \"AI winter,\" during which research became more fragmented and commercially limited.\\n\\nThe tide turned starting in 1997, when IBM’s Deep Blue famously defeated world chess champion Garry Kasparov, a milestone achievement for AI. Around the same time, Judea Pearl’s work in probability and decision theory advanced the field, and pioneers like Geoffrey Hinton reignited interest in deep learning, setting the stage for the resurgence of neural networks. Though commercial interest was still building, these innovations laid the foundation for AI\\'s next phase of growth.\\n\\n### 2007-Present\\n\\nFrom 2007 to 2018, advancement in cloud computing made computing power and AI infrastructure more accessible. It led to increasing adoption. innovation and advancement in machine learning. The advancements included a convolutional neural network (CNN) architecture called AlexNet, developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton winning the ImageNet competition, showcasing the power of deep learning in image recognition and Google\\'s AlphaZero mastered the games of chess, shogi, and Go without human data, relying on self-play.\\n\\nIn 2022, [chatbots](https://aws.amazon.com/what-is/chatbot/) that use artificial intelligence (AI) and natural language processing (NLP) to have human-like conversations and complete tasks like OpenAI\\'s ChatGPT became widely known for its conversational abilities, renewing AI interest and development.\\n\\n## What is the difference between machine learning, deep learning, and artificial intelligence?\\n\\nArtificial intelligence (AI) is an umbrella term for different strategies and techniques for making machines more human-like. It includes everything from self-driving cars to robotic vacuum cleaners and smart assistants like Alexa. While machine learning and deep learning fall under the AI umbrella, not all AI activities are machine learning and deep learning. For example, generative AI demonstrates human-like creative capabilities and is a very advanced form of deep learning.\\n\\n### Machine learning\\n\\nWhile you may see the terms artificial intelligence and machine learning being used interchangeably in many places, machine learning is technically one among many other branches of artificial intelligence. It is the science of developing algorithms and statistical models to correlate data. Computer systems use machine learning algorithms to process large quantities of historical data and identify data patterns. In the current context, machine learning refers to a set of statistical techniques called machine learning models that you can use independently or to support other more complex AI techniques.\\n\\n[Read about machine learning](https://aws.amazon.com/what-is/machine-learning/)\\n\\n[Read about AI vs. machine learning](https://aws.amazon.com/compare/the-difference-between-artificial-intelligence-and-machine-learning/)\\n\\n### Deep learning\\n\\nDeep learning takes machine learning one step further. Deep learning models use neural networks that work together to learn and process information. They comprise millions of software components that perform micromathematical operations on small data units to solve a larger problem. For example, they process individual pixels in an image to classify that image. Modern AI systems often combine multiple deep neural networks to perform complex tasks like writing poems or creating images from text prompts.\\n\\n[Read about deep learning](https://aws.amazon.com/what-is/deep-learning/)\\n\\n## How does AI work?\\n\\nAI systems leverage advanced technologies to transform raw data - whether it\\'s text, images, videos, or audio - into meaningful insights. By identifying patterns and relationships within this data, AI enables intelligent decision-making at scale. These systems are trained on vast datasets, allowing them to continuously learn and improve over time, much like how humans learn from experience. With each interaction, AI models become more accurate, driving innovation and unlocking new opportunities for businesses.\\n\\n## Neural Networks\\n\\nArtificial neural networks form the core of artificial intelligence technologies. They mirror the processing that happens in the human brain. A brain contains millions of neurons that process and analyze information. An artificial neural network uses artificial neurons that process information together. Each artificial neuron, or node, uses mathematical calculations to process information and solve complex problems.\\n\\n[Read about neural networks](https://aws.amazon.com/what-is/neural-network/)\\n\\n## Natural Language Processing (NLP)\\n\\nNatural language processing (NLP) uses neural networks to interpret, understand, and gather meaning from text data. It uses various computing techniques that specialize in decoding and comprehending human language. These techniques allow machines to process words, grammar syntax, and word combinations to process human text and even generate new text. Natural language processing is critical in summarizing documents chatbots, and conducting sentiment analysis.\\n\\n[Read about NLP](https://aws.amazon.com/what-is/nlp/)\\n\\n## Computer Vision\\n\\nComputer vision uses deep learning techniques to extract information and insights from videos and images. You can use it to monitor online content for inappropriate images, recognize faces, and classify image details. It is critical in everything from content moderation to autonomous vehicles, where split-second decisions are critical.\\n\\n[Read about computer vision](https://aws.amazon.com/computer-vision/)\\n\\n## Speech Recognition\\n\\nSpeech recognition software uses deep learning models to interpret human speech, identify words, and detect meaning. The neural networks can transcribe speech to text and indicate vocal sentiment. You can use speech recognition in technologies like virtual assistants and call center software to identify meaning and perform related tasks.\\n\\n[Read about speech-to-text](https://aws.amazon.com/what-is/speech-to-text/)\\n\\n## Generative AI\\n\\nGenerative AI refers to artificial intelligence systems that create new content and artifacts such as images, videos, text, and audio from simple text prompts. Unlike past AI, which was limited to analyzing data, generative AI leverages deep learning and massive datasets to produce high-quality, human-like creative outputs. While enabling exciting creative applications, concerns around bias, harmful content, and intellectual property exist. Overall, generative AI represents a major evolution in AI capabilities to generate human language and new content and artifacts in a human-like manner.\\n\\n[Read about generative AI](https://aws.amazon.com/what-is/generative-ai/)\\n\\n## What are the key components of AI application architecture?\\n\\nArtificial intelligence architecture consists of three core layers, all supported by robust IT infrastructure that delivers the compute power and memory needed to run AI at scale. Each layer plays a critical role in enabling seamless AI operations, from data processing to advanced decision-making.\\n\\n### Layer 1: data layer\\n\\nAI is built upon various technologies, such as machine learning, natural language processing, and image recognition. Central to these technologies is data, which forms the foundational layer of AI. This layer primarily focuses on preparing the data for AI applications.\\n\\n### Layer 2: model layer\\n\\nPresent-day artificial intelligence primarily uses foundation and large language models to perform complex digital tasks. Foundation models are deep learning models trained on a broad spectrum of generalized and unlabeled data. Based on input prompts, they can perform a wide range of disparate tasks with a high degree of accuracy.\\n\\nOrganizations take existing, pre-trained foundation models and customize them with internal data to add AI capabilities to existing applications or create new AI applications.\\n\\nIt is important to note that many organizations continue using machine learning models for many digital tasks. Machine learning models can outperform foundation models for many use cases, and artificial intelligence developers can flexibly choose the best models for specific tasks.\\n\\nRead more about foundation models »\\n\\n### Layer 3: application layer\\n\\nThe third layer is the application layer, the customer-facing part of AI architecture. You can ask AI systems to complete specific tasks, generate information, provide information, or make data-driven decisions. The application layer allows end users to interact with AI systems.\\n\\n## How are businesses harnessing the power of AI?\\n\\nExplore some real-world examples of how businesses are harnessing the power of AI to innovate and drive efficiencies.\\n\\n### Chatbots and smart assistants\\n\\nAI-powered chatbots and virtual assistants are transforming customer interactions by delivering human-like, context-aware conversations. They excel in customer support, virtual assistance, and content generation by offering intelligent, coherent responses to natural language queries. These AI models continuously learn and improve over time, ensuring personalized experiences that drive customer satisfaction and operational efficiency.\\n\\n**Deriv**, one of the world’s largest online brokers, implemented an AI-powered assistant to manage data across customer support, marketing, and recruiting platforms. By leveraging AI, Deriv reduced new hire onboarding time by 45% and slashed recruiting task times by 50%.\\n\\n### Intelligent Document Processing (IDP)\\n\\nAI simplifies the extraction of meaningful data from unstructured formats such as emails, PDFs, and images, transforming them into actionable insights. Intelligent Document Processing (IDP) uses advanced technologies like natural language processing (NLP), deep learning, and computer vision to streamline document-heavy workflows.\\n\\n**HM Land Registry (HMLR)**, which manages property titles for over 87% of England and Wales, deployed AI to automate legal document comparison. With AI, they cut document review time by 50% and accelerated the approval process for property transfers. Learn how HMLR uses Amazon Textract.\\n\\n### Application Performance Monitoring (APM)\\n\\nAI-based application performance monitoring helps businesses maintain peak performance by predicting and preventing issues before they impact users. These tools analyze historical data to recommend proactive solutions, ensuring continuous uptime and operational efficiency.\\n\\n**Atlassian** relies on AI-powered APM tools to continuously monitor and prioritize application issues. By leveraging machine learning recommendations, their teams can resolve performance challenges faster and improve application reliability. Learn more about APM.\\n\\n[Explore AI use cases](https://aws.amazon.com/machine-learning/ai-use-cases/)\\n\\n## What is the power of AI technologies?\\n\\nAI offers a broad set of powerful technologies that are transforming industries and unlocking new opportunities for businesses. Here are key AI capabilities you can leverage to innovate and scale your operations.\\n\\n### Image generation\\n\\nAI transforms simple text descriptions into high-quality, realistic images in seconds. For instance, by inputting a prompt like \"a sunset over the mountains,\" AI can instantly produce stunning visuals. This groundbreaking technology is revolutionizing creative industries such as marketing, entertainment, and design, dramatically accelerating the content creation process.\\n\\n### Text generation\\n\\nAI can automatically generate human-like text, from short-form content like emails to complex reports. Widely adopted across customer support, marketing, and content creation, this technology enhances efficiency and saves valuable time by streamlining the writing process.\\n\\n### Speech generation and recognition\\n\\nAI-powered speech generation creates natural, human-like speech, while speech recognition enables machines to understand and process spoken words. These technologies are key to delivering seamless, voice-activated experiences through virtual assistants like Alexa, enhancing customer service, smart devices, and accessibility solutions.\\n\\n### Multimodal AI\\n\\nMultimodal AI integrates text, images, and audio data to provide a more comprehensive understanding of complex content. By recognizing objects, transcribing speech, and interpreting on-screen text all at once, multimodal AI delivers advanced insights in real-time. This capability is crucial for industries leveraging AI for video analysis, autonomous vehicles, and beyond - enabling smarter, faster decision-making and unlocking new possibilities for innovation.\\n\\n## How AI is transforming industries today?\\n\\nAI is revolutionizing industries, driving innovation, automating complex processes, and delivering exceptional user experiences at scale.\\n\\n### Content recommendations\\n\\nAI powers recommendation engines for leading streaming services like Netflix and Spotify, analyzing user preferences to deliver personalized content suggestions. By keeping customers engaged, AI helps businesses improve retention and boost customer satisfaction.\\n\\n### Personalized shopping\\n\\nE-commerce platforms use AI to provide personalized product recommendations based on customers’ browsing history and preferences, driving higher sales and better shopping experiences.\\n\\n### Healthcare\\n\\nAI is reshaping healthcare with advanced diagnostics, treatment planning, and patient monitoring. AI systems can analyze medical images to detect diseases early and help customize treatment plans based on patient history and data.\\n\\n### Traffic management\\n\\nAI optimizes traffic flows by analyzing real-time data, predicting traffic patterns, and suggesting alternate routes. This improves transportation efficiency, reduces congestion, and helps lower emissions.\\n\\n### Conservation\\n\\nAI is a powerful tool in conservation efforts, helping monitor wildlife, combat deforestation, and prevent poaching with AI-powered drones and satellite imagery. AI’s real-time monitoring capabilities are transforming environmental protection strategies.\\n\\n## What are the benefits of AI for business transformation?\\n\\nYour organization can leverage the power of AI to optimize operations, enhance customer experiences, and drive innovation at scale.\\n\\n### Automate intelligently\\n\\nAI-driven systems can intelligently scan and record data, like invoices, across any template, classify information based on various criteria such as supplier or region, and even detect errors to ensure seamless payment processing with minimal human intervention.\\n\\n### Boost productivity\\n\\nAI empowers knowledge workers by giving them access to critical information instantly and in context. Whether it\\'s healthcare professionals retrieving patient records or airline employees looking up flight data, AI streamlines these tasks, allowing workers to focus on what truly matters. For example, Ryanair, Europe’s largest airline, implemented AI systems to enhance employee productivity and satisfaction, making information retrieval faster and more efficient.\\n\\n### Solve complex problems\\n\\nAI excels at analyzing vast datasets to identify patterns and unlock insights that can solve even the most complex challenges. Industries like manufacturing and healthcare can leverage AI to make data-driven decisions, such as determining optimal maintenance schedules by analyzing machine data and usage reports, leading to significant cost savings. AI can also revolutionize fields like genomic research, helping accelerate breakthroughs in drug discovery and innovation.\\n\\n### Create new customer experiences\\n\\nAI enables businesses to deliver personalized, secure, and responsive customer experiences. By combining customer profile data with product or service information, AI provides real-time recommendations and tailored solutions that enhance engagement. Lonely Planet, for instance, utilized AI to generate curated travel itineraries for customers, reducing the time required by 80% while providing personalized travel recommendations at scale.\\n\\n[Read about Deep Learning](https://aws.amazon.com/what-is/deep-learning/)\\n\\n## How do AI services and tools unlock business potential?\\n\\n### Generative AI\\n\\nAccelerate generative AI innovation with enterprise-grade security, privacy, and a choice of leading foundation models (FMs). Powered by a data-first approach and cutting-edge infrastructure, AWS delivers the highest performance while optimizing costs. Organizations of all sizes trust AWS to transform prototypes and demos into real-world innovation and measurable productivity gains.\\n\\n[Explore generative AI services and tools](https://aws.amazon.com/ai/generative-ai/)\\n\\n### AI services\\n\\nAWS pretrained AI services provide ready-made intelligence for your applications and workflows. AI services easily integrate with your applications to address common use cases such as personalized recommendations, modernizing your contact center, improving safety and security, and increasing customer engagement.\\n\\n[View AI services](https://aws.amazon.com/ai/services/)\\n\\n### Machine learning\\n\\nGet deeper insights from your data while lowering costs with machine learning (ML). AWS helps you at every stage of your ML adoption journey with the most comprehensive set ML services and purpose-built infrastructure. Amazon SageMaker makes it easy to build, train, and deploy machine learning and foundation models at scale. With SageMaker, data scientists and ML engineers have the flexibility and fine-grain control over infrastructure and tools to pre-train, evaluate, customize, and deploy over 250 FMs for optimized performance, latency, and cost.\\n\\n[Explore ML services and resources](https://aws.amazon.com/ai/machine-learning/)\\n\\n### AI infrastructure\\n\\nWith the growth of AI comes the increased usage, management, and cost of infrastructure resources. To maximize performance, lower costs, and avoid complexity during the training and deployment of foundation models to production, AWS provides specialized infrastructure that\\'s optimized for your AI use cases.\\n\\n[Find purpose-built AI infrastructure services](https://aws.amazon.com/ai/infrastructure/)\\n\\n### Data foundation for AI\\n\\nOnly AWS provides the most comprehensive set of data capabilities for an end-to-end data foundation that supports any workload or use case, including generative AI. Quickly and easily connect to and act on all your data with end-to-end [data governance](https://aws.amazon.com/what-is/data-governance/) that helps your teams move faster with confidence. And with AI built into our data services, AWS makes the complexities of data management easier, so you spend less time managing data and more time getting value out of it.\\n\\n[Build an end-to-end data foundation for AI](https://aws.amazon.com/data/)\\n\\n## What is Responsible AI?\\n\\nResponsible AI considers the societal and environmental impact of AI systems while ensuring fairness, transparency, and accountability in how AI is developed and used. As AI becomes increasingly transformative, organizations are tasked with building systems that drive innovation without infringing on civil liberties or human rights. At AWS, we are committed to developing AI responsibly, taking a people-centric approach that prioritizes education, science, and our customers - to integrate responsible AI across the end-to-end AI lifecycle with tools like Guardrails for Amazon Bedrock, Amazon SageMaker Clarify, and much more.\\n\\n[Learn more about responsible AI](https://aws.amazon.com/machine-learning/responsible-ai/)\\n\\n## What are the challenges in artificial intelligence implementation?\\n\\nWhile AI offers immense potential, there are key challenges that organizations must navigate to fully unlock its value.\\n\\n### AI governance\\n\\nData governance policies must abide by regulatory restrictions and privacy laws. To implement AI, you must manage data quality, privacy, and security. You are accountable for customer data and privacy protection. To manage data security, your organization should understand how AI models use and interact with customer data across each layer.\\n\\n### Technical difficulties\\n\\nTraining AI with machine learning consumes vast resources. A high threshold of processing power is essential for deep learning technologies to function. You must have robust computational infrastructure to run AI applications and train your models. Processing power can be costly and limit your AI systems\\' scalability.\\n\\n### Data limitations\\n\\nYou need to input vast volumes of data to train unbiased AI systems. You must have sufficient storage capacity to handle and process the training data. Equally, you must have effective management and data quality processes in place to ensure the accuracy of the data you use for training.\\n\\n## How can I start using artificial intelligence for my business?\\n\\nTo start using AI in your business, identify areas where AI can improve efficiency, such as automating customer service with chatbots, analyzing data for better decision-making, or personalizing marketing efforts. Tools like predictive analytics, AI-driven content generation, and recommendation systems can help drive business growth.\\n\\n## How can I start using artificial intelligence in my day-to-day life?\\n\\nYou can start using AI in daily life through virtual assistants like Alexa or smart home devices that automate tasks. Additionally, AI-powered apps for fitness tracking, language learning, and budgeting can make everyday activities more efficient and tailored to your needs.\\n\\n## What is AI innovation on AWS and how can you build and scale it?\\n\\nReinvent customer experiences and streamline operations with the most comprehensive set of artificial intelligence and machine learning services.\\n\\n## Build with a proven AI leader\\n\\nScale the next wave of innovation in AI by leveraging more than 25 years of pioneering AI experience from Amazon. AWS makes AI accessible to more people – from builders and data scientists to business analysts and students. With the most comprehensive set of AI services, tools, and resources, AWS brings deep expertise to over 100,000 customers to meet the demands of their business and unlock the value of their data. Security, privacy, and responsible AI have never been more critical. Customers can build and scale with AWS on a foundation of privacy, end-to-end security, and AI governance to transform at an unprecedented rate.\\n\\n[View more customer stories.](https://aws.amazon.com/ai/generative-ai/customers/?customer-references-cards.sort-by=item.additionalFields.sortDate&customer-references-cards.sort-order=desc&awsf.customer-references-location=*all&awsf.customer-references-industry=*all)\\n\\n## What is AI training for beginners?\\n\\nAI training typically starts with the basics of programming and computer science. You should learn languages like Python, along with mathematics, statistics, and linear algebra.\\n\\nYou can then move on to more specialized training. Pursue a master’s degree in artificial intelligence, machine learning, or data science to gain a deeper understanding and hands-on experience. These programs typically involve topics such as neural networks, natural language processing, and computer vision in-depth.\\n\\nHowever, formal education isn’t the only path. You can use online courses to learn at your own pace and master specific skills. For example,\\xa0[generative AI training on AWS](https://aws.amazon.com/training/learn-about/generative-ai/) includes certifications by AWS experts on topics like:\\n\\n* [Introduction to generative AI](https://explore.skillbuilder.aws/learn/course/external/view/elearning/17176/introduction-to-generative-ai-art-of-the-possible)\\n* [Generative AI for executives](https://explore.skillbuilder.aws/learn/course/external/view/elearning/16666/generative-ai-for-executives)\\n* [Generative AI essentials for business](https://training.resources.awscloud.com/partner-ai-ml-training/aws-partner-generative-ai-essentials-business)\\n\\n## How customers are innovating with AI on AWS?\\n\\nMore than 100,000 customers have chosen AWS for AI to provide better customer service, optimize their businesses, create new customer experiences, and more.\\n\\n[View more customer stories.](https://aws.amazon.com/ai/generative-ai/customers/?customer-references-cards.sort-by=item.additionalFields.sortDate&customer-references-cards.sort-order=desc&awsf.customer-references-location=*all&awsf.customer-references-industry=*all)\\n\\n## How can AWS support your artificial intelligence requirements?\\n\\nAWS makes AI accessible to more people—from builders and data scientists to business analysts and students. With the most comprehensive set of AI services, tools, and resources, AWS brings deep expertise to over 100,000 customers to meet their business demands and unlock the value of their data. Customers can build and scale with AWS on a foundation of privacy, end-to-end security, and AI governance to transform at an unprecedented rate. AI on AWS includes pre-trained AI services for ready-made intelligence and AI infrastructure to maximize performance and lower costs.\\n\\nAWS makes AI accessible to more people, from builders and data scientists to business analysts and students. With the most comprehensive set of AI services, tools, and resources, AWS brings deep expertise to over 100,000 customers to meet their business demands and unlock the value of their data. Customers can build and scale with AWS on a foundation of privacy, end-to-end security, and AI governance to transform at an unprecedented rate.\\n\\nAI on AWS includes pre-trained AI services for ready-made intelligence and AI infrastructure to maximize performance and lower costs.\\n\\nExamples of pre-trained services:\\n\\n* [Amazon Rekogniton](https://aws.amazon.com/rekognition/) automates, streamlines, and scales image recognition and video analysis.\\n* [Amazon Textract](https://aws.amazon.com/textract/) extracts printed text, analyzes handwriting, and automatically captures data from any document.\\n* [Amazon Transcribe](https://aws.amazon.com/transcribe/) converts speech to text, extracts critical business insights from video files, and improves business outcomes.\\n\\nExamples of AI infrastructure:\\n\\n* [Amazon Bedrock](https://aws.amazon.com/bedrock/) offers a choice of high-performing FMs and a broad set of capabilities. You can experiment with various top FMs and privately customize them with your data.\\n* [Amazon SageMaker](https://aws.amazon.com/sagemaker/) offers tools to pre-train FMs from scratch so they can be used internally.\\n* [Amazon Elastic Compute Cloud (EC2) Trn1](https://aws.amazon.com/ec2/instance-types/trn1/) instances, powered by [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/) chips, are purpose-built for high-performance deep learning (DL) training of generative AI models.\\n\\nGet started with AI on AWS by creating a [free account](https://signin.aws.amazon.com/signin/) today!today!\\n\\n## Next steps on AWS\\n\\n[### Check out additional product-related resources\\n\\nLearn more](https://aws.amazon.com/ai/services/)\\n\\n[### Sign up for a free account\\n\\nInstantly get access to the AWS Free Tier.\\n\\nSign up](https://portal.aws.amazon.com/gp/aws/developer/registration/index.html)\\n\\n[### Start building in the console\\n\\nGet started building with AWS in the AWS Management Console.\\n\\nSign in](https://console.aws.amazon.com/)\\n\\n '},\n",
              "  {'url': 'https://www.iso.org/artificial-intelligence/what-is-ai',\n",
              "   'title': 'What is artificial intelligence (AI)? - ISO',\n",
              "   'content': '## What is AI? Decoding the AI meaning\\n\\nArtificial intelligence (AI) is a branch of computer science that creates systems and software capable of tasks once thought to be uniquely human. It enables machines to learn from experience, adapt to new information, and uses data, algorithms and computational power to interpret complex situations and make decisions with minimal human input. AI can understand language, recognize patterns, solve problems and even demonstrate creativity – often at speeds and scales far beyond our own. By harnessing these capabilities, it is reshaping how we interact with technology and pushing the boundaries of what machines can achieve. [...] So what can AI do? Today’s AI is more powerful than ever. It sees, listens and responds. It learns from experience, refines its skills and integrates seamlessly into our daily lives. From personalized recommendations to fully autonomous systems, AI is transforming the way we innovate, compete and grow in real-time. Self-driving cars? That’s just the beginning.\\n\\nAI has crossed a new threshold in the past year. The real game-changer is generative AI– machines that don’t just process data, they create. They write code, compose music, generate lifelike images and videos, and even produce entire articles indistinguishable from human work. [...] ## Strong AI vs weak AI\\n\\nAI spans a wide spectrum of capabilities, but essentially, it falls into two broad categories: weak AI and strong AI. Weak AI, often referred to as artificial narrow intelligence (ANI) or narrow AI, refers to systems designed to excel at specific tasks within well-defined parameters. These systems operate within a limited scope and lack the capacity for general intelligence. Think of them as highly specialized tools – efficient, precise, but confined to their programmed functions.',\n",
              "   'score': 0.99304235,\n",
              "   'raw_content': '# What is artificial intelligence (AI)?\\n\\nIn the not-so-distant past, the idea of machines that could think, learn and make decisions was confined to the realm of science fiction. Today, [artificial intelligence (AI)](/artificial-intelligence \"artificial-intelligence-what-is\")\\xa0has transcended those fictional boundaries, embedding itself into the fabric of our daily lives. But what is\\xa0artificial intelligence?\\n\\nAt its core, AI refers to computer systems capable of performing tasks that typically require human intelligence, such as reasoning, learning, perception and language understanding. These systems analyse vast datasets, recognize patterns and make decisions with **unprecedented speed and accuracy**. From Amazon’s Alexa+ anticipating your needs to AI-driven drug development accelerating medical breakthroughs, AI’s applications are vast and varied.\\n\\nBut AI isn’t just about chatbots\\xa0– it’s a transformative force reshaping entire industries. From its core principles to cutting-edge applications, join us as we dive deep into the technology that is redefining the future.\\n\\n## What is AI? Decoding the AI meaning\\n\\nArtificial intelligence (AI) is a branch of computer science that creates systems and software capable of tasks once thought to be uniquely human. It enables machines to learn from experience, adapt to new information, and uses **data**, **algorithms** and **computational power** to interpret complex situations and make decisions with minimal human input. AI can understand language, recognize patterns, solve problems and even demonstrate creativity – often at speeds and scales far beyond our own. By harnessing these capabilities, it is **reshaping how we interact with technology** and pushing the boundaries of what machines can achieve.\\n\\nSo what can AI do? Today’s AI is more powerful than ever. It sees, listens and responds. It learns from experience, refines its skills and integrates seamlessly into our daily lives. From personalized recommendations to fully autonomous systems, AI is transforming the way we innovate, compete and grow in real-time. Self-driving cars? That’s just the beginning.\\n\\nAI has crossed a new threshold in the past year. **The real game-changer is** **generative AI**– machines that don’t just process data, they *create*. They write code, compose music, generate lifelike images and videos, and even produce entire articles indistinguishable from human work.\\n\\nAt the heart of this revolution are **machine learning** and **deep learning**, the driving forces accelerating AI’s evolution. These technologies are rewriting the rules of innovation, transforming how we interact with technology, and unlocking a future we’re only beginning to imagine.\\n\\n### Sign up for email updates\\n\\nStay updated on artificial intelligence and related standards!\\n\\nHow your data will be used\\n\\nPlease see [ISO privacy notice](https://www.iso.org/privacy.html \"privacy-and-copyright\"). This site is protected by reCAPTCHA and the Google [Privacy Policy](https://policies.google.com/privacy) and [Terms of Service](https://policies.google.com/terms) apply.\\n\\n## What are the benefits of AI?\\n\\nAI technology is redefining how we live and work, driving smarter automation, deeper insights and more strategic decision-making. Here’s a look at the key benefits of AI.\\n\\n**Automating processes**  \\n AI takes efficiency to the next level by automating complex workflows and reducing human workload. In cybersecurity, AI-powered systems hunt down threats before they strike. In smart factories, robots with AI-driven vision spot defects, optimize production and keep operations seamless. And companies that use AI in business? They can scale faster, work smarter and do more with less.\\n\\n**Zero human error**  \\n Unlike humans, AI never slips up or gets distracted. It follows strict AI algorithms, ensuring pinpoint accuracy in finance, healthcare and manufacturing. From detecting fraud in banking to perfectly calibrated robotic surgeries, AI enhances reliability across industries.\\n\\n**No more repetitive tasks**  \\n Why waste time on mind-numbing work? AI in business handles document validation, call transcriptions and customer queries\\u202f– freeing up human talent for creative problem-solving. In hazardous environments, AI-powered robots take over risky jobs, keeping workers safe.\\n\\n**Faster, smarter decisions**  \\n AI processes vast amounts of data at lightning speed, uncovering patterns and insights far beyond human capabilities. It powers real-time financial fraud detection, medical diagnostics and predictive analytics, enabling professionals to stay ahead of the curve. In a world where speed and accuracy are everything, the benefits of AI are game-changing – faster decisions, sharper insights, and the confidence to act before it’s too late.\\n\\n**24/7 reliability**  \\n Forget downtime – AI works around the clock without breaks, fatigue or errors. From cybersecurity monitoring to healthcare diagnostics and customer support, AI technology ensures uninterrupted performance, keeping businesses and services running smoothly around the clock.\\n\\n**Accelerating breakthroughs**  \\n AI is reshaping research and development, driving discoveries in medicine, climate science and engineering. It speeds up drug discovery, deciphers genetic data for personalized medicine and optimizes renewable energy models. With AI, progress happens faster and smarter.\\n\\n## How does AI work?\\n\\nAt its core, AI processes vast amounts of data, uncovering patterns and making predictions with remarkable precision. It achieves this by leveraging large datasets and intelligent AI algorithms\\u202f– structured sets of rules\\u202fthat allow software to learn from patterns in the data. The driving force behind this capability? **Neural networks**: complex systems of interconnected nodes that pass information through multiple layers to find connections and extract meaning from data.\\n\\nTo truly understand how AI works, we must unpack the following concepts:\\n\\n* **Learning**: At the heart of AI lies\\xa0**machine learning**, enabling systems to analyse data, recognize patterns and make decisions without explicit programming. Taking this further, **deep learning**\\xa0uses advanced neural networks to process millions of data points, allowing AI software to understand more complex patterns and continually improve its performance.\\n* **Reasoning**: AI doesn’t just recognize trends\\xa0– it can think and infer. By mimicking human reasoning, AI evaluates commands, context and available data to develop strategies, form hypotheses and make informed decisions in real time.\\n* **Problem solving**: AI approaches problem solving through data manipulation, running simulations, testing different possibilities and refining its strategy. Through intelligent AI\\xa0algorithms, it explores various possible paths to find the most optimal solution to complex problems.\\n* **Language processing**: AI uses natural language processing – or NLP – to analyse human language data in a way that computers can understand. What is NLP? It refers to the ability of machines to understand, interpret and generate human language, using text analysis, sentiment analysis and machine translation.\\n* **Perception**: Through **computer vision**, AI-powered systems process data from cameras and sensors to identify objects, detect faces and recognize images with precision. From facial recognition to self-driving cars, perception-driven AI is revolutionizing the way machines interact with the world.\\n\\n## Strong AI vs weak AI\\n\\nAI spans a wide spectrum of capabilities, but essentially, it falls into two broad categories: weak AI and strong AI. Weak AI, often referred to as **artificial narrow intelligence (ANI)**\\xa0or\\xa0**narrow AI**, refers to systems designed to excel at specific tasks within well-defined parameters. These systems operate within a limited scope and lack the capacity for general intelligence. Think of them as highly specialized tools\\xa0– efficient, precise, but confined to their programmed functions.\\n\\nBut don’t let the name fool you! Weak AI is anything but weak\\xa0– it powers countless artificial intelligence applications we interact with daily. Examples of narrow AI are all around us. From Siri and Alexa’s instant responses to self-driving cars, ANI is the impetus behind today’s most advanced AI innovations.\\n\\nHere are some real-world examples of AI applications powered by narrow AI:\\n\\n* **Smart assistants**: Among the best-known examples of weak AI, digital assistants use natural language processing to handle tasks such as setting reminders, answering questions and controlling smart home devices.\\n* **Chatbots**: Ever chatted with customer support on an e-commerce site? Chances are you were speaking with an ANI-powered chatbot. These AI-driven systems answer routine enquiries, leaving humans free to perform higher-level tasks.\\n* **Recommendation engines**: Whether it’s Netflix curating your next must-watch series or Amazon predicting your next purchase, ANI analyses user habits to provide personalized recommendations based on viewing, buying or browsing patterns.\\n* **Navigation apps**: How do you get from A to B without getting lost? Apps like Google Maps\\xa0rely on ANI algorithms to process real-time traffic data, optimize routes and guide users to their destinations efficiently.\\n* **Email spam filters**: Do you wonder why most spam emails never reach your inbox? ANI-powered filters scan messages, detect suspicious content and redirect unwanted emails to the spam folder.\\n* **Autocorrect features**: Whether you’re texting on an iPhone or composing an email, AI software refines your writing by correcting typos and suggesting words based on your typing patterns, ensuring smoother, more efficient communication.\\n\\nEach of these applications showcases ANI’s ability to tackle specific tasks by leveraging large datasets and specialized algorithms. So, the next time you’re impressed by AI’s capabilities, remember\\xa0– it’s weak AI driving these remarkable innovations, transforming our world in ways we once thought impossible.\\n\\nIn contrast to narrow AI, the concept of strong AI\\xa0– also known as **general AI**\\xa0– aims to develop systems capable of handling a broad range of tasks with human-like proficiency. Unlike their task-specific ANI counterparts, strong AI systems aspire to possess a form of general intelligence that enables them to learn, adapt and apply knowledge across multiple domains. The ultimate goal? To create artificial entities with cognitive abilities that mirror those of humans, capable of engaging in intellectual tasks spanning diverse fields.\\n\\nFor now, strong AI remains purely speculative, with no practical examples in real life. However, that hasn’t stopped AI researchers from pushing the boundaries of AI’s potential development. Research in **artificial general intelligence (AGI)** is exploring how AI could evolve beyond its specialized functions into autonomous systems capable of independent reasoning.\\n\\nIn theory, AGI could take on any human job, whether it’s cleaning, coding or scientific research. While we’re not there yet, the potential impact of AGI spans multiple industries, including:\\n\\n* **Language**: Writing essays, poems and engaging in conversations.\\n* **Healthcare**: Medical imaging, drug research and surgery.\\n* **Transportation**: Fully automated cars, trains and planes.\\n* **Arts and entertainment**: Creating music, visual art and films.\\n* **Domestic robots**: Cooking, cleaning and childcare.\\n* **Manufacturing**: Supply chain management, stocktaking and consumer services.\\n* **Engineering**: Programming, building and architecture.\\n* **Security**: Detecting fraud, preventing security breaches and improving public safety.\\n\\nWhile researchers and developers continue to push the limits of AGI, achieving true general intelligence, on a par with human cognition, remains a formidable challenge and a distant goal. That said, with rapid advancements in AI technology and machine learning, the real question is no longer *if* AGI will emerge, but *when*.\\n\\n## What are the four types of AI?\\n\\nArtificial intelligence spans a wide range of capabilities, each designed for specific functions and objectives. Understanding the four types of AI provides insight into the ever-evolving landscape of machine intelligence.\\n\\n* **Reactive machines**: These AI systems operate strictly within predefined rules\\xa0but lack the ability to learn from new data or experiences. A prime example is chatbots, which generate responses based on **programmed algorithms**, rather than adapting to conversations. While they excel at specific tasks, they cannot evolve beyond their initial programming.\\n* **Limited memory**: Unlike reactive machines, AI systems with limited memory can learn from historical data, enabling them to make informed decisions based on **past experiences**. These types of AI are seen in self-driving cars, which use sensors and machine learning algorithms to analyse traffic patterns and navigate safely through dynamic environments. Similarly, natural language processing applications leverage historical data to refine language comprehension and interpretation over time.\\n* **Theory of mind**: Still theoretical, this type of AI would be capable of understanding human emotions, intentions and social cues. A machine with a theory of mind could then use that information to **anticipate human actions** and engage in intuitive, empathetic interactions. If realized, this AI could revolutionize human-computer and social robotics, creating systems that genuinely understand us.\\n* **Self-aware AI**: The most futuristic (and controversial) concept, self-aware AI refers to machines with **human-like consciousness**\\xa0– aware of their own existence and capable of perceiving emotions in others. While captivating in science-fiction classics like *Blade Runner*, this level of AI remains purely hypothetical, sparking both fascination and debate about the future of artificial intelligence.\\n\\nThese four types of AI highlight the vast spectrum of intelligence within artificial systems. As AI technology advances, exploring the capabilities and limitations of each type will deepen our understanding of machine intelligence and its impact on society.\\n\\n## Machine learning vs deep learning\\n\\nCentral to these advancements are machine learning and deep learning, two subfields of AI that drive many of today’s innovations. While closely related, each has its own distinct approach to learning and problem solving.\\n\\n**Machine learning** relies on different learning methods to train AI systems. The three primary types are:\\n\\n* **Supervised learning**: The algorithm is trained on a labelled dataset, where each input has a known output. By learning from these labelled examples, the model can make accurate predictions on new, unseen data.\\n* **Unsupervised learning**: Unlike supervised learning, this method works without predefined labels or outputs. Instead, the algorithm learns to identify hidden structures or groupings within the data, making it essential for tasks like clustering or anomaly detection.\\n* **Reinforcement learning**: In this approach, an AI agent interacts with an environment and learns through trial and error. It receives rewards for desirable actions or penalties for mistakes, gradually improving its decision-making over time. This technique is widely used in robotics, gaming and autonomous systems.\\n\\nA subset of machine learning, **deep learning** focuses on training artificial neural networks with multiple layers, inspired by the human brain’s\\u202fstructure and function. These networks consist of **interconnected nodes (neurons)** that process and transmit signals, enabling AI to learn complex patterns.\\n\\nUnlike traditional machine learning models, deep learning algorithms automatically extract features from raw data, refining their understanding through layers of abstraction. This makes them **exceptionally powerful** in image and speech recognition, natural language processing and other advanced AI applications. Yet their high complexity comes at a cost\\xa0– deep learning requires massive datasets, extensive training and significant computational power to achieve optimal performance.\\n\\n## Examples of AI technology\\n\\nWhile many people associate AI with smart assistants like Siri and Alexa, new AI technology is emerging fast, making daily tasks more efficient and transforming industries in unexpected ways. Here are some key applications:\\n\\n* **Healthcare**: AI can process and analyse vast amounts of patient data, enabling accurate diagnoses, predictive analytics and personalized treatment recommendations for better health outcomes. It also plays a crucial role in drug discovery and medical imaging, helping doctors detect diseases earlier and more effectively.\\n* **Business and manufacturing**: AI-driven automation enhances efficiency across industries, from fraud detection and risk assessment to market trend\\xa0analysis. In manufacturing, AI-powered robots streamline production while predictive maintenance helps prevent equipment failures before they happen. In retail, AI enables personalized shopping experiences, smart inventory management, chatbots for customer support and data-driven advertising strategies to increase sales.\\n* **Education**: AI-powered intelligent tutoring systems adapt to students’ learning styles, providing personalized feedback and guidance. AI also automates grading, content creation and virtual-reality simulations, making education more interactive and efficient.\\n* **Transport**: AI keeps traffic moving, prevents breakdowns\\xa0and streamlines logistics in shipping and supply chains. From fleet tracking to automated scheduling, it ensures faster, smarter and more efficient operations.\\n* **Agriculture**: AI-driven drones and sensors monitor soil health, detect crop diseases and optimize irrigation. Smart systems also recommend efficient pesticide use and resource management, helping farmers maximize crop yields with minimal waste.\\n* **Entertainment**: AI curates personalized recommendations, matching you with the perfect movie, song or book based on your preferences. Virtual and augmented reality push immersion to new levels, while AI-driven CGI and special effects bring movies and games to life with stunning realism.\\n\\n## The growth and impact of generative AI\\n\\nThe rise of large-scale language models like Chat GPT is just the beginning. Welcome to the era of\\xa0**generative AI**\\xa0– a groundbreaking frontier in artificial intelligence that goes beyond analysing data to creating entirely new content. Unlike traditional AI systems, which excel at classification and prediction, generative models push boundaries by **mimicking human creativity and imagination**. They generate text, images, music, and even entire virtual worlds, blurring the line between machine output and human innovation.\\n\\nBut generative AI isn’t flawless. While its capabilities are revolutionary, challenges remain. Deepfakes, misinformation, biases, copyright issues and job displacement are all real concerns. These generative models also demand immense computational power, driving up costs and environmental impact while posing security and quality control risks.\\n\\nDespite these hurdles, examples of artificial intelligence in this space continue to expand, proving its **extraordinary potential**. Researchers are actively tackling these challenges through improved detection systems, refined training data, enhanced security measures and optimized computational efficiency. A balanced approach, supported by guidelines and stronger regulation, will also be key to ensuring generative AI serves as a force for progress, not disruption.\\n\\n## AI governance and regulations\\n\\nAs AI becomes deeply embedded in industries worldwide, ensuring the quality and reliability of AI software is more critical than ever. Yet, despite its rapid growth, AI still operates in a largely unregulated space, posing risks that demand urgent attention.\\n\\nThis is where International Standards come in. Standards, such as those developed by ISO/IEC\\xa0JTC\\xa01/SC\\xa042 on artificial intelligence, play a pivotal role in addressing the **responsible development and use of AI technologies**. They provide decision makers and policymakers with a structured framework to create consistent, auditable and transparent AI systems, closing regulatory gaps.\\n\\nFor businesses, aligning with these standards isn’t just about compliance\\xa0– it’s a strategic advantage. From risk management to responsible AI governance, standardized AI practices enhance credibility, build trust with stakeholders, and ensure that the benefits of artificial intelligence outweigh the risks.\\n\\n* [ISO/IEC 42001:2023](/standard/42001)AI management systems\\n* [ISO/IEC 23894:2023](/standard/77304.html)AI — Guidance on risk management\\n* [ISO/IEC 23053:2022](/standard/74438.html)Framework for AI systems using machine learning\\n\\n## History of artificial intelligence: who invented AI?\\n\\nAI has progressed in leaps and bounds, transforming many aspects of our world. But to truly appreciate its current capabilities, it’s important to **understand its origins and evolution**. So who created AI? To find out, let’s take a journey through the fascinating history of artificial intelligence.\\n\\nToday’s AI loosely stems from the 19th-century invention of Charles Babbage’s “difference engine”\\u202f– the **world’s first successful automatic calculator**. British code-breaker Alan Turing, who was a key figure in the Allies’ intelligence arsenal during WWII, amongst other feats, can also be seen as a father figure of today’s iterations of AI. In 1950, he proposed the Turing Test, designed to assess a machine’s ability to exhibit intelligent behaviour indistinguishable from that of a human.\\n\\nFrom that point onward, advancements in AI technology began to accelerate exponentially, spearheaded by such influential figures as John McCarthy, Marvin Minsky, Herbert Simon, Geoffrey Hinton, Yoshua Bengio, Yann LeCun, and many others. But it wasn’t all smooth sailing. While AI flourished in the early years, with **computers’ capability to store more information**, it soon hit a roadblock: computers simply couldn’t store enough information or process it fast enough. It wasn’t until the 1980s that AI experienced a renaissance, sparked by an expansion of the algorithm toolkit and an increase in funding.\\n\\nTo cut a long story short, here are some key events and milestones in the history of artificial intelligence:\\n\\n* **1950**: Alan Turing publishes the paper “Computing Machinery and Intelligence”, in which he proposes the Turing Test as a way of assessing whether or not a computer counts as intelligent.\\n* **1956**: A small group of scientists gather for the Dartmouth Summer Research Project on Artificial Intelligence, which is regarded as the birth of this field of research.\\n* **1966–1974**: This is conventionally known as the “First AI Winter”, a period marked by reduced funding and progress in AI research due to failure to live up to early hype and expectations.\\n* **1997**: Deep Blue, an IBM chess computer, defeats world champion Garry Kasparov in a highly publicized chess match, demonstrating the fabulous potential of AI systems. In the same year, speech recognition software, developed by Dragon Systems, was implemented on Windows.\\n* **2011**: In a televised *Jeopardy!* contest, IBM’s Watson Deep QA computer defeats two of the quiz shows’ all-time champions, showcasing the ability of AI systems to understand natural language.\\n* **2012**: The “deep learning” approach, inspired by the human brain, revolutionizes many AI applications, ushering in the current AI boom.\\n* **2016**: Developed by a Google subsidiary, the computer program AlphaGo captures the world’s attention when it defeats legendary Go player Lee Sedol. The ancient board game “Go” is one of the most complex ever created.\\n* **2017 to date**: Rapid advancements in computer vision, natural language processing, robotics and autonomous systems are driven by progress in deep learning and increased computational power.\\n* **2023**: The rise of large language models, such as GPT-3 and its successors, demonstrates the potential of AI systems to generate human-like text, answer questions and assist with a wide range of tasks.\\n* **2024**: New breakthroughs in multimodal AI allow systems to process and integrate various types of data (text, images, audio and video) for more comprehensive and intelligent solutions. AI-powered digital assistants are now capable of engaging in natural, contextual conversations as well as assisting with a wide variety of tasks.\\n\\n## How will AI change our world?\\n\\nThe exponential growth of computing power and the Internet has propelled machine learning from concept to reality. Today, AI algorithms don’t just follow instructions, they learn from vast datasets, improving with each iteration. At its most advanced, this has led to deep learning, where computers refine their “intelligence” through experience, much like the human brain.\\n\\nAnd the impact? AI is everywhere\\xa0– powering how we work, communicate and engage with technology. From medical breakthroughs to climate solutions, its impact will be profound and far-reaching. But with innovation comes responsibility. As AI becomes more powerful and pervasive, we must ensure it is developed and used responsibly. For this to be achieved, it is crucial to stay informed and be proactive in shaping its development\\xa0– to build a future that is both beneficial and empowering for all.\\n\\n### Media contact\\n\\nThe Content Team  \\n ISO, Geneva, Switzerland  \\n +41 22 749 01 11  \\n [team-content@iso.org](mailto:team-content@iso.org)\\n\\n1. Insights & news\\n2. Insights\\n3. [All insights](/insights)\\n4. What is artificial intelligence (AI)?\\n\\n* [Standards](/standards.html \"Covering almost every product, process or service imaginable, ISO makes standards used everywhere.\")\\n  + [Benefits](/benefits-of-standards.html \"Whether you run a business, work for a company or government, or you are a consumer looking for goods and services that meet customer expectations: Find out what standards can do for you.\")\\n  + [Popular standards](/popular-standards.html \"Here you can discover some of the best-known and most widely-used standards, as well as those that address recently emerged challenges affecting us all.\\n\\n    \")\\n  + [Conformity assessment](/conformity-assessment.html \"A set of processes that show your product, service or system meets the requirements of a standard.\")\\n  + [SDGs](/sdg \"Organizations and companies looking to contribute to the SDGs will find that International Standards provide effective tools to help them rise to the challenge.\")\\n* Sectors\\n  + [Health](/sectors/health \"(including medicine and laboratory equipment)\")\\n  + [IT & related technologies](/sectors/it-technologies \"(including communication technology, graphics and photography)\")\\n  + [Management & services](/sectors/management-services \"(Business management, financial and professional services)\")\\n  + [Security, safety & risk](/sectors/security-safety-risk)\\n  + [Transport](/sectors/transport \"(including vehicles, parts and infrastructure, freight, packaging and distribution)\")\\n  + [Energy](/sectors/energy \"(including power generation and transport, fuels)\")\\n  + [Environmental sustainability](/sectors/environment \"Explore our Environmental sustainability sector.\")\\n  + [Materials](/sectors/materials \"(Ores and metals, non-metallic materials, chemicals)\")\\n* [About ISO](/about \"ISO brings together global experts to develop International Standards that help solve problems and drive innovation.\")\\n  + [What we do](/what-we-do.html \"Find out how we develop and publish international standards by bringing together more than 160 members and more than 45,000 experts\")\\n  + [Structure](/structure.html)\\n  + [Members](/about/members \"The members of the International Organization for Standardization are 175 national standards bodies, each representing ISO in their country.\")\\n  + [Events](/events.html \"Find out what\\'s coming up and what you might have missed.\")\\n  + [Strategy](/strategy2030.html \"Making lives easier, safer and better. Our Strategy outlines our vision and our mission for the next 10 years and a set of goals and priorities to help us get there.\")\\n* Insights & news\\n  + Insights\\n    - [All insights](/insights)\\n    - [Healthcare](/insights/filtered-list-healthcare)\\n    - [Artificial intelligence](/insights/filtered-list-artificial-intelligence)\\n    - [Climate change](/insights/filtered-list-climate-change)\\n    - [Transport](/home/insights-news/insights/transport.html)\\n  + News\\n    - [Expert talk](/insights/thought-leadership)\\n    - [Standards world](/insights/standards-world)\\n    - [Media kit](/home/insights-news/news/dossier-medias.html)\\n  + Resources\\n    - [ISO 22000 explained](/home/insights-news/resources/iso-22000-explained.html)\\n    - [ISO 9001 explained](/home/insights-news/resources/iso-9001-explained.html)\\n    - [ISO 14001 explained](/home/insights-news/resources/iso-14001-explained.html)\\n* [Taking part](/developing-standards.html \"Find out how the ISO process bring together global experts to create standards that are chosen the world over.\")\\n  + [Who develops standards](/who-develops-standards.html \"ISO has put together groups of experts that represent every sector imaginable from soaps to spacecraft, MP3 to coffee. In fact there are more than 250 technical committees. You can find out what they do here.\")\\n  + [Deliverables](/deliverables-all.html \"The different types of ISO publications.\")\\n  + [Get involved](/get-involved.html)\\n  + [Collaborating to accelerate effective climate action](/ClimateAction.html \"The ISO Climate Action Kit is a collection of case studies from around the world on how standards can be effectively used as a tool for sustainability.\")\\n  + [Resources](/resources.html \"Resources to support the work of individuals involved in standards development. \")\\n    - [Drafting standards](/drafting-standards.html)\\n* [Store](/store.html \"Are you looking to buy International Standards, guidelines, collections and checklists? They\\'re all right here, in the ISO Store.\")\\n  + [Store](/store.html)\\n  + [Publications and products](/publication-list.html \"ISO publications give insights and guidance into specific applications and show how standards add value.\")\\n\\n#### Add to cart\\n\\n '},\n",
              "  {'url': 'https://www.mtu.edu/computing/ai/',\n",
              "   'title': 'What is Artificial intelligence (AI)? - Michigan Technological University',\n",
              "   'content': 'What is Artificial intelligence (AI)?\\n\\nArtificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like learning, reasoning, problem-solving, perception, and language understanding. Instead of relying on explicit instructions from a programmer, AI systems learn from data that enables them to handle complex problems and simple repetitive tasks, improving how they respond over time.\\n\\nAI handles many tasks faster with exceptional accuracy and reliability, freeing humans from repetitive and tedious chores. Businesses and organizations save time and money by automating and optimizing routine processes, using the technology to stay connected with customers and gain a competitive edge. [...] In healthcare, AI is improving medical diagnostics, enabling personalized treatments, and assisting in complex surgical procedures. The transportation sector is experiencing the emergence of autonomous vehicles and intelligent traffic management systems, promising safer and more efficient mobility. In finance and economics and business analytics, AI is reshaping algorithmic trading, fraud detection, and economic forecasting, altering the dynamics of global markets. And AI is transforming education by offering personalized learning experiences and intelligent tutoring systems. [...] Deep learning started to take off in the early 2010s. An abundance of data, advancements in learning algorithms, and increases in computational power led to achievements in speech recognition, natural language processing, visual recognition, and reinforcement learning.\\n\\nAI continues to evolve at a rapid pace as an integral part of daily life. The integration of AI into everyday applications impacts industries such as finance, healthcare, transportation, and entertainment. The convergence of AI with other technologies, such as the Internet of Things (IoT), blockchain, and quantum computing, continues.',\n",
              "   'score': 0.9868787,\n",
              "   'raw_content': 'What is Artificial intelligence (AI)?\\n===============\\n\\n[Skip to page content](https://www.mtu.edu/computing/ai/#main)[Skip to footer navigation](https://www.mtu.edu/computing/ai/#mtu-footer)\\n\\nMenu\\n\\n[![Image 1: Michigan Tech Logo](https://www.mtu.edu/mtu_resources/images/logos/michigan-tech-logo-full-yellow.svg)](https://www.mtu.edu/)\\n\\n*   [Request Info](https://www.mtu.edu/request/index.html)\\n*   [Visit](https://www.mtu.edu/visit/index.html)\\n*   [Apply](https://www.mtu.edu/apply/index.html)\\n*    Resources for You  \\n    *   [Prospective Students](https://www.mtu.edu/future/index.html)\\n    *   [Admitted Students](https://www.mtu.edu/admissions/enroll/index.html)\\n    *   [Current Students](https://www.mtu.edu/current/index.html)\\n    *   [Faculty and Staff](https://www.mtu.edu/faculty-staff/index.html)\\n    *   [Alumni and Friends](https://www.mtu.edu/alumni/index.html)\\n    *   [Parents and Family](https://www.mtu.edu/admissions/connect/parents/index.html)\\n    *   [Industry/Partners](https://www.mtu.edu/industry/index.html)\\n\\n*    Tech Links  \\n    *   [A to Z](https://www.mtu.edu/a2z/index.html)\\n    *   [Campus Directory](https://www.mtu.edu/directory/)\\n    *   [Canvas](https://mtu.instructure.com/)\\n    *   [Concur](https://sso.mtu.edu/cas/idp/profile/SAML2/Unsolicited/SSO?providerId=https%3A%2F%2Fwww.concursolutions.com)\\n    *   [Email](https://mail.google.com/a/mtu.edu/)\\n    *   [Experience](https://www.mtu.edu/experience/)\\n    *   [Safety Data Sheets](https://www.mtu.edu/sds/)\\n    *   [Website Settings](https://www.mtu.edu/site-settings/index.html)\\n\\n Search   Clear Search Input  Search Category   Go  Open Search \\n\\n*   [Undergraduate](https://www.mtu.edu/computing/undergraduate/)\\n    *   [Computer Science BS](https://www.mtu.edu/cs/undergraduate/computer-science/)\\n    *   [Cybersecurity BS](https://www.mtu.edu/applied-computing/undergraduate/cybersecurity/)\\n    *   [Data Science BS](https://www.mtu.edu/cs/undergraduate/data-science/)\\n    *   [Electrical Engineering Technology BS](https://www.mtu.edu/applied-computing/undergraduate/eet/)\\n    *   [Information Technology BS](https://www.mtu.edu/applied-computing/undergraduate/it/)\\n    *   [Mechatronics BS](https://www.mtu.edu/applied-computing/undergraduate/mechatronics/)\\n    *   [Software Engineering BS](https://www.mtu.edu/cs/undergraduate/software/)\\n    *   [General Computing](https://www.mtu.edu/cs/undergraduate/general-computing/)\\n    *   [Computing Minors](https://www.mtu.edu/computing/undergraduate/minors/)\\n    *   [Advising](https://www.mtu.edu/computing/undergraduate/advising/)\\n    *   [Computing Learning Center](https://www.mtu.edu/computing/undergraduate/cclc/)\\n    *   [Student Organizations](https://www.mtu.edu/computing/undergraduate/student-orgs/)\\n\\n*   [Graduate](https://www.mtu.edu/computing/graduate/)\\n    *   [Applied Computer Science MS](https://www.mtu.edu/cs/graduate/applied-computer-science/)\\n    *   [Computational Science and Engineering PhD](https://www.mtu.edu/academics/cse/)\\n    *   [Computer Science MS, PhD](https://www.mtu.edu/cs/graduate/computer-science/)\\n    *   [Cybersecurity MS](https://www.mtu.edu/cs/graduate/cybersecurity/)\\n    *   [Data Science MS](https://www.mtu.edu/cs/graduate/data-science/masters/)\\n    *   [Health Informatics MS](https://www.mtu.edu/applied-computing/graduate/health-informatics/)\\n    *   [Mechatronics MS](https://www.mtu.edu/applied-computing/graduate/mechatronics/)\\n    *   [Accelerated Master\\'s](https://www.mtu.edu/accelerated/)\\n    *   [Program Directors](https://www.mtu.edu/computing/graduate/program-directors/)\\n    *   [Theses and Dissertations](https://www.mtu.edu/computing/graduate/dissertations/)\\n\\n*   Departments \\n    *   [Applied Computing](https://www.mtu.edu/applied-computing/)\\n    *   [Computer Science](https://www.mtu.edu/cs/)\\n\\n*   [About](https://www.mtu.edu/computing/about/)\\n    *   [Welcome from the Dean](https://www.mtu.edu/computing/about/welcome/)\\n    *   [Our College](https://www.mtu.edu/computing/about/college/)\\n    *   [Our Students](https://www.mtu.edu/computing/about/students/)\\n    *   [Our Alumni](https://www.mtu.edu/computing/about/alumni-friends/)\\n    *   [Leadership](https://www.mtu.edu/computing/about/leadership/)\\n    *   [External Advisory Boards](https://www.mtu.edu/computing/about/advisory-boards/)\\n    *   [Honor Academy](https://www.mtu.edu/computing/about/honor-academy/)\\n    *   [Staff Directory](https://www.mtu.edu/computing/about/staff/)\\n    *   [Employment](https://www.mtu.edu/computing/about/employment/)\\n    *   [Gateway Magazine](https://www.mtu.edu/computing/gateway/)\\n\\n*   [Research](https://www.mtu.edu/computing/research/)\\n    *   [Active Research](https://www.mtu.edu/computing/research/active-research/)\\n    *   [Infinite Loop Journal](https://www.mtu.edu/computing/research/infinite-loop/)\\n    *   [Computing Education](https://www.mtu.edu/icc/centers/computing-education/)\\n    *   [Biocomputing and Digital Health](https://www.mtu.edu/icc/centers/bdh-center/)\\n    *   [Cyber-Physical Systems](https://www.mtu.edu/icc/centers/cyber-physical-systems/)\\n    *   [Cybersecurity](https://www.mtu.edu/icc/centers/cybersecurity/)\\n    *   [Data Sciences](https://www.mtu.edu/icc/centers/ai/)\\n    *   [Human-Centered Computing](https://www.mtu.edu/icc/centers/human-centered-computing/)\\n    *   [Scalable Architectures and Systems](https://www.mtu.edu/icc/centers/scalable-architectures-systems/)\\n\\n*   [Giving](https://www.mtu.edu/computing/giving/)\\n    *   [Student Recruitment](https://www.mtu.edu/computing/giving/recruitment/)\\n    *   [Outreach](https://www.mtu.edu/computing/giving/outreach/)\\n    *   [World-Class Research](https://www.mtu.edu/computing/giving/research/)\\n    *   [Learning and Research Facilities](https://www.mtu.edu/computing/giving/facilities/)\\n    *   [Campus and College Enrichment](https://www.mtu.edu/computing/giving/enrichment/)\\n    *   [High Impact Giving](https://www.mtu.edu/computing/giving/high-impact/)\\n\\n*   [Apply](https://www.mtu.edu/apply/)\\n\\n Search   Clear Search Input  Search Category   Search \\n\\n*   [Undergraduate](https://www.mtu.edu/computing/undergraduate/)\\n    *   [Computer Science BS](https://www.mtu.edu/cs/undergraduate/computer-science/)\\n    *   [Cybersecurity BS](https://www.mtu.edu/applied-computing/undergraduate/cybersecurity/)\\n    *   [Data Science BS](https://www.mtu.edu/cs/undergraduate/data-science/)\\n    *   [Electrical Engineering Technology BS](https://www.mtu.edu/applied-computing/undergraduate/eet/)\\n    *   [Information Technology BS](https://www.mtu.edu/applied-computing/undergraduate/it/)\\n    *   [Mechatronics BS](https://www.mtu.edu/applied-computing/undergraduate/mechatronics/)\\n    *   [Software Engineering BS](https://www.mtu.edu/cs/undergraduate/software/)\\n    *   [General Computing](https://www.mtu.edu/cs/undergraduate/general-computing/)\\n    *   [Computing Minors](https://www.mtu.edu/computing/undergraduate/minors/)\\n    *   [Advising](https://www.mtu.edu/computing/undergraduate/advising/)\\n    *   [Computing Learning Center](https://www.mtu.edu/computing/undergraduate/cclc/)\\n    *   [Student Organizations](https://www.mtu.edu/computing/undergraduate/student-orgs/)\\n\\n*   [Graduate](https://www.mtu.edu/computing/graduate/)\\n    *   [Applied Computer Science MS](https://www.mtu.edu/cs/graduate/applied-computer-science/)\\n    *   [Computational Science and Engineering PhD](https://www.mtu.edu/academics/cse/)\\n    *   [Computer Science MS, PhD](https://www.mtu.edu/cs/graduate/computer-science/)\\n    *   [Cybersecurity MS](https://www.mtu.edu/cs/graduate/cybersecurity/)\\n    *   [Data Science MS](https://www.mtu.edu/cs/graduate/data-science/masters/)\\n    *   [Health Informatics MS](https://www.mtu.edu/applied-computing/graduate/health-informatics/)\\n    *   [Mechatronics MS](https://www.mtu.edu/applied-computing/graduate/mechatronics/)\\n    *   [Accelerated Master\\'s](https://www.mtu.edu/accelerated/)\\n    *   [Program Directors](https://www.mtu.edu/computing/graduate/program-directors/)\\n    *   [Theses and Dissertations](https://www.mtu.edu/computing/graduate/dissertations/)\\n\\n*   Departments \\n    *   [Applied Computing](https://www.mtu.edu/applied-computing/)\\n    *   [Computer Science](https://www.mtu.edu/cs/)\\n\\n*   [About](https://www.mtu.edu/computing/about/)\\n    *   [Welcome from the Dean](https://www.mtu.edu/computing/about/welcome/)\\n    *   [Our College](https://www.mtu.edu/computing/about/college/)\\n    *   [Our Students](https://www.mtu.edu/computing/about/students/)\\n    *   [Our Alumni](https://www.mtu.edu/computing/about/alumni-friends/)\\n    *   [Leadership](https://www.mtu.edu/computing/about/leadership/)\\n    *   [External Advisory Boards](https://www.mtu.edu/computing/about/advisory-boards/)\\n    *   [Honor Academy](https://www.mtu.edu/computing/about/honor-academy/)\\n    *   [Staff Directory](https://www.mtu.edu/computing/about/staff/)\\n    *   [Employment](https://www.mtu.edu/computing/about/employment/)\\n    *   [Gateway Magazine](https://www.mtu.edu/computing/gateway/)\\n\\n*   [Research](https://www.mtu.edu/computing/research/)\\n    *   [Active Research](https://www.mtu.edu/computing/research/active-research/)\\n    *   [Infinite Loop Journal](https://www.mtu.edu/computing/research/infinite-loop/)\\n    *   [Computing Education](https://www.mtu.edu/icc/centers/computing-education/)\\n    *   [Biocomputing and Digital Health](https://www.mtu.edu/icc/centers/bdh-center/)\\n    *   [Cyber-Physical Systems](https://www.mtu.edu/icc/centers/cyber-physical-systems/)\\n    *   [Cybersecurity](https://www.mtu.edu/icc/centers/cybersecurity/)\\n    *   [Data Sciences](https://www.mtu.edu/icc/centers/ai/)\\n    *   [Human-Centered Computing](https://www.mtu.edu/icc/centers/human-centered-computing/)\\n    *   [Scalable Architectures and Systems](https://www.mtu.edu/icc/centers/scalable-architectures-systems/)\\n\\n*   [Giving](https://www.mtu.edu/computing/giving/)\\n    *   [Student Recruitment](https://www.mtu.edu/computing/giving/recruitment/)\\n    *   [Outreach](https://www.mtu.edu/computing/giving/outreach/)\\n    *   [World-Class Research](https://www.mtu.edu/computing/giving/research/)\\n    *   [Learning and Research Facilities](https://www.mtu.edu/computing/giving/facilities/)\\n    *   [Campus and College Enrichment](https://www.mtu.edu/computing/giving/enrichment/)\\n    *   [High Impact Giving](https://www.mtu.edu/computing/giving/high-impact/)\\n\\n*   [Apply](https://www.mtu.edu/apply/)\\n*    Connect with Us  \\n    *   [Request Info](https://www.mtu.edu/request/index.html)\\n    *   [Visit](https://www.mtu.edu/visit/index.html)\\n    *   [Apply](https://www.mtu.edu/apply/index.html)\\n\\n*    Resources for You  \\n    *   [Prospective Students](https://www.mtu.edu/future/index.html)\\n    *   [Admitted Students](https://www.mtu.edu/admissions/enroll/index.html)\\n    *   [Current Students](https://www.mtu.edu/current/index.html)\\n    *   [Faculty and Staff](https://www.mtu.edu/faculty-staff/index.html)\\n    *   [Alumni and Friends](https://www.mtu.edu/alumni/index.html)\\n    *   [Parents and Family](https://www.mtu.edu/admissions/connect/parents/index.html)\\n    *   [Industry/Partners](https://www.mtu.edu/industry/index.html)\\n\\n*    Tech Links  \\n    *   [A to Z](https://www.mtu.edu/a2z/index.html)\\n    *   [Campus Directory](https://www.mtu.edu/directory/)\\n    *   [Canvas](https://mtu.instructure.com/)\\n    *   [Concur](https://sso.mtu.edu/cas/idp/profile/SAML2/Unsolicited/SSO?providerId=https%3A%2F%2Fwww.concursolutions.com)\\n    *   [Email](https://mail.google.com/a/mtu.edu/)\\n    *   [Experience](https://www.mtu.edu/experience/)\\n    *   [Safety Data Sheets](https://www.mtu.edu/sds/)\\n    *   [Website Settings](https://www.mtu.edu/site-settings/index.html)\\n\\n[College of Computing](https://www.mtu.edu/computing/)\\n\\n*   [Michigan Tech](https://www.mtu.edu/)\\n*   [Computing](https://www.mtu.edu/computing/)\\n*   What is AI\\n\\n![Image 2: Network storage to support AI](https://www.mtu.edu/computing/ai/images/network-storage-1018-banner2400.jpg)\\n\\nWhat is Artificial intelligence (AI)?\\n=====================================\\n\\nArtificial intelligence (AI) encompasses the fields of computer and [data science](https://www.mtu.edu/cs/undergraduate/data-science/what-is/index.html) focused on building machines with human intelligence to perform tasks like learning, reasoning, problem-solving, perception, and language understanding. Instead of relying on explicit instructions from a programmer, AI systems learn from data that enables them to handle complex problems and simple repetitive tasks, improving how they respond over time.\\n\\nAI handles many tasks faster with exceptional accuracy and reliability, freeing humans from repetitive and tedious chores. Businesses and organizations save time and money by automating and optimizing routine processes, using the technology to stay connected with customers and gain a competitive edge.\\n\\nAI is part of everyday life. If you\\'ve used a self-service kiosk to check in before a flight, typed keywords into a search bar and received suggested results, or communicated with a digital assistant, you\\'ve interacted with AI.\\n\\nAI Technologies Include:\\n------------------------\\n\\n*   Autonomous vehicles\\n*   Biometrics\\n*   Chatbots\\n*   Decision management\\n*   Deep learning platforms\\n*   Digital assistants\\n*   Digital image processing\\n*   Entertainment streaming apps\\n*   Facial, speech, and image recognition\\n*   Fraud detection\\n*   Gaming\\n*   Generative AI tools like ChatGPT\\n*   GPS navigation\\n*   Image generators\\n*   Natural language processing and text analytics\\n*   Pattern recognition\\n*   Personalized marketing\\n*   Robotics, [mechatronics](https://www.mtu.edu/applied-computing/undergraduate/mechatronics/what-is/index.html), and automation\\n*   Security and surveillance\\n*   Self-driving vehicles\\n*   Speech recognition\\n*   Virtual assistants\\n*   Weather prediction\\n\\nFundamental Components of AI\\n----------------------------\\n\\n*   **Data:** AI systems learn and make decisions based on data, and they require large quantities of information to train effectively, especially for machine learning (ML) models.\\n*   **Algorithms:** Algorithms are the sets of rules AI systems use to process data and make decisions. Machine learning algorithms, for instance, learn and make predictions and decisions without explicit programming.\\n*   **Computing power:**AI algorithms often need significant computing resources to process large quantities of data and run complex algorithms.\\n\\nFour Basic Functions of AI\\n--------------------------\\n\\n*   **Learning.** A key aspect of AI is learning, which allows AI systems to digest data and enhance their functions without direct human coding.\\n*   **Reasoning and decision-making.** Reasoning and decision-making systems employ logical rules, probability models, and algorithms to reach conclusions and make reliable decisions based on inference.\\n*   **Problem-solving.** Problem-solving in AI involves processing data, manipulating it, and applying it to devise solutions for specific issues.\\n*   **Perception.** The perception component of AI includes tasks like image recognition, object detection, image segmentation, and video analysis.\\n\\n### Understanding Traditional vs. Generative AI\\n\\n**Traditional AI analyzes and interprets data** using programmed rules, algorithms, and historical data to make predictions and decisions. It\\'s often trained on carefully curated data for specific purposes. It is known for its precision, reliability, and efficiency in performing repetitive tasks. Traditional AI is often used in finance, healthcare, and manufacturing.\\n\\n**Generative AI creates new content,** such as text, images, music, video, or software code, in response to a user\\'s request or prompt. Generative AI learns to identify patterns and create new variations based on those patterns. Generative AI is known for its creativity and adaptability. It\\'s often used in music, design, and marketing.\\n\\nSome Artificial Intelligence Terms\\n----------------------------------\\n\\n*   **Computer vision.** Computer vision techniques assist computers in seeing and understanding digital images and videos in order to teach themselves about the context of visual data. Computer vision applications include object tracking, image classification, and facial recognition.\\n*   **Fuzzy logic.** Fuzzy logic helps to solve issues or statements that can either be true or false. It is used for reasoning about uncertain concepts.\\n*   **Expert systems.** An expert system program specializes in a singular task to solve intricate problems using human-like decision-making capabilities.\\n*   **Robotics.** Robots are programmed machines that can independently carry out complex series of actions, helping humans with tedious and repetitive tasks.\\n*   **Machine learning.** Machine learning (ML) focuses on using data and algorithms to imitate the way that humans learn. This enables machine learning systems to gradually improve their accuracy without being specifically programmed to do so.\\n*   **Neural networks/deep learning.**Neural networks are at the heart of deep learning algorithms, which simulate the complex decision-making power of the human brain. They rely on training data to learn and improve their accuracy over time.\\n*   **Natural language processing.**Natural language processing (NLP) refers to the development of algorithms and techniques that allow computers to understand both text and spoken words like humans can.\\n\\n### A Brief History of AI\\n\\nThe modern groundwork for AI began in the early 1900s, but the biggest strides were made in the middle of the 20th century, when pioneers like Alan Turing began exploring foundational concepts like artificial neural networks, machine learning, and symbolic reasoning.\\n\\nThe term artificial intelligence was coined and came into popular use in the mid-1950s following Turing\\'s publication of \"Computer Machinery and Intelligence,\" a paper that proposed a test of machine intelligence called the Imitation Game. Turing\\'s publication eventually became the **Turing Test,** which experts used to measure computer intelligence.\\n\\nAI technology continued to develop from the mid-1950s to the late 1970s, as computers became faster, cheaper, more accessible, and could store more information. During this time, the first AI programming languages were created, machine learning algorithms were improved, and books and films began to explore the idea of robots. But computers were still millions of times too weak to exhibit intelligence. Research funding declined until the 1980s.\\n\\nThe 1980s were a period of rapid growth and interest in AI following breakthroughs in research and additional government funding. Deep learning techniques and the use of expert systems became more popular, both of which allowed computers to learn from their mistakes and make independent decisions.\\n\\nThe early 1990s showed some strides forward in AI research, including the first AI system that could defeat a reigning world champion chess player. The early 2000s saw innovations such as the first robot vacuum and the first commercially available speech recognition software.\\n\\nThe late 1990s and the early 2000s also saw significant advances in artificial intelligence. Computerized automation began to emerge, and machine learning was applied to many problems in academia and industry due to the availability of powerful computer hardware, immense collections of data, and the application of advanced mathematical methods.\\n\\n**Deep learning** started to take off in the early 2010s. An abundance of data, advancements in learning algorithms, and increases in computational power led to achievements in speech recognition, natural language processing, visual recognition, and reinforcement learning.\\n\\nAI continues to evolve at a rapid pace as an integral part of daily life. The integration of AI into everyday applications impacts industries such as finance, healthcare, transportation, and entertainment. The convergence of AI with other technologies, such as the Internet of Things (IoT), blockchain, and quantum computing, continues.\\n\\nAs AI systems become more powerful and pervasive, concerns about bias, transparency, and accountability have grown. There is a growing focus on ethical and responsible AI practices. Researchers and policymakers are working to establish guidelines and frameworks to ensure AI is developed and deployed responsibly.\\n\\nWhat Programming Languages are used in AI?\\n------------------------------------------\\n\\n*   C++\\n*   Haskell\\n*   Java\\n*   JavaScript\\n*   Julia\\n*   Lisp\\n*   Prolog\\n*   Python\\n*   R\\n*   Scala\\n\\nBenefits of AI\\n--------------\\n\\n*   Contributes to medical advances.\\n*   Enables smart decision-making by analyzing trends, providing forecasts, and quantifying uncertainties.\\n*   Enhances customer experiences.\\n*   Allows faster, more efficient research and data analysis.\\n*   Improves business efficiency.\\n*   Manages and automates repetitive tasks.\\n*   Reduces human error and improves accuracy and precision.\\n*   Solves complex business problems.\\n*   Streamlines decision-making.\\n\\nHow Can AI Benefit Humanity?\\n----------------------------\\n\\nArtificial intelligence has enormous potential to serve society. Its problem-solving capabilities can help people and communities around the world by tackling some of today\\'s toughest challenges. Applications include:\\n\\n*   Developing new drugs, detecting disease, and improving medical applications.\\n*   Fighting climate change, poverty, and hunger.\\n*   National defense and [cybersecurity](https://www.mtu.edu/computing/cybersecurity/index.html).\\n*   Optimizing renewable energy generation.\\n*   Improving access to education, healthcare, and clean water.\\n*   Improving accessibility for disabled individuals.\\n*   Improving transportation safety and efficiency.\\n\\nIs AI Dangerous?\\n----------------\\n\\nAI is a powerful and promising technology that can bring many benefits and opportunities to humanity. But even with its many benefits, the use of AI comes with various concerns.\\n\\n*   **Security and safety:** AI can pose security and safety threats, such as hacking, cyberattacks, and accidents. AI can also malfunction and cause accidents, such as crashes, explosions, and injuries due to errors, bugs, or glitches.\\n*   **Ethical and moral dilemmas:** AI can raise ethical and moral dilemmas, such as privacy, bias, accountability, and autonomy. AI can collect and use our personal data, such as our location, preferences, and behavior, and potentially violate our privacy and security. AI can also reflect and amplify human biases, such as racism, sexism, ageism, and other forms of discrimination.\\n*   **Humanity and empathy loss:**AI can cause humanity and empathy loss, enabling dehumanization, isolation, and alienation. AI can reduce our human interactions and connections and make us more dependent and addicted to technology. AI can also diminish our human values and emotions such as compassion, creativity, and curiosity.\\n*   **Data privacy:**Due to plentiful and affordable data storage, data persists longer than the people who produced it, making it vulnerable to misuse. Data can also be used for purposes other than originally intended.\\n\\nWill AI Replace Jobs?\\n---------------------\\n\\nWhile AI may replace some tedious jobs, it\\'s important to note [AI will also create many new jobs](https://www.mtu.edu/computing/ai/career-affects/index.html). The World Economic Forum\\'s Future of Jobs Report notes that while 85 million jobs may be displaced by automation by 2025, **97 million new roles** are projected to emerge in the same time frame. AI\\'s development itself generates employment opportunities, as human activity is required to train and refine AI algorithms, leading to jobs that haven\\'t existed until now. Roles such as machine learning engineers, data scientists, and AI ethics specialists have emerged to design, oversee, and ensure responsible AI deployment.\\n\\nWho Uses AI?\\n------------\\n\\nTech companies are at the forefront of AI, but industries of all kinds use AI.\\n\\n*   Astronomy\\n*   Automotive\\n*   Agriculture\\n*   E-commerce\\n*   Education\\n*   Finance\\n*   Gaming\\n*   Government\\n*   Healthcare\\n*   Human resources\\n*   Lifestyle\\n*   Marketing\\n*   Navigation\\n*   Robotics\\n*   Security\\n*   Social media\\n*   Travel and transport\\n\\nThe Future of Artificial Intelligence\\n-------------------------------------\\n\\nAI applications affect many aspects of our lives. And AI is predicted to grow even more pervasive as it revolutionizes sectors including health care, education, finance, security, transportation, and advertising. As AI makes difficult tasks less complex and replaces tedious or dangerous tasks, the expectation is that the human workforce will shift our focus to endeavors that require creativity and empathy.\\n\\nIn **healthcare,** AI is improving medical diagnostics, enabling personalized treatments, and assisting in complex surgical procedures. The **transportation** sector is experiencing the emergence of autonomous vehicles and intelligent traffic management systems, promising safer and more efficient mobility. In **finance** and **economics** and [business analytics](https://www.mtu.edu/business/undergraduate/business-analytics/what-is/index.html), AI is reshaping algorithmic trading, fraud detection, and economic forecasting, altering the dynamics of global markets. And AI is transforming **education** by offering personalized learning experiences and intelligent tutoring systems.\\n\\nHowever, AI brings with it ethical and societal implications. Protecting privacy and ensuring data security are crucial, as AI draws on vast amounts of personal information. Issues of bias and fairness also emerge as AI decision-making algorithms can inadvertently introduce discriminatory practices. The impact of AI on human autonomy raises important questions about the boundaries between human capacity and technological influence.\\n\\nThe challenges and risks associated with AI can\\'t be overlooked, but neither can its tremendous potential. Collaboration between AI and human intelligence can lead to remarkable improvements in human skills and present solutions to complicated issues. AI augmentation, in which humans and machines collaborate, has promise in a variety of fields ranging from healthcare to scientific study. Other AI advancements can promote transparency and trust, as well as improve ethical decision-making.\\n\\nWhat Are the Best Degrees for a Job In AI?\\n------------------------------------------\\n\\nSpecific degrees in AI are still rare, but **AI is an interdisciplinary field** that is present in many courses of study, including computer science, mathematics, and statistics. A computer science or data science degree is a common choice for people seeking careers in artificial intelligence. AI-related degrees include:\\n\\n*   [Business Analytics](https://www.mtu.edu/business/undergraduate/business-analytics/index.html)\\n*   [Computer Science](https://www.mtu.edu/cs/undergraduate/computer-science/index.html)\\n*   [Data Science](https://www.mtu.edu/cs/undergraduate/data-science/index.html)\\n*   [Engineering](https://www.mtu.edu/engineering/undergraduate/index.html)\\n*   [Health/Medical Informatics](https://www.mtu.edu/applied-computing/graduate/health-informatics/index.html)\\n*   [Mathematics](https://www.mtu.edu/math/undergraduate/mathematics/index.html)\\n*   [Robotics](https://www.mtu.edu/ece/undergraduate/robotics/index.html)\\n*   [Statistics](https://www.mtu.edu/math/undergraduate/statistics/index.html)\\n\\nJobs In Artificial Intelligence\\n-------------------------------\\n\\nEvery day more job opportunities in AI are available, from data scientists to information managers to software developers. [AI is affecting career opportunities.](https://www.mtu.edu/computing/ai/career-affects/index.html) Some AI-related [computer career options and salary estimates](https://www.mtu.edu/computing/salaries/index.html) are below.\\n\\n*   **Artificial intelligence engineers** use AI and machine learning techniques to develop applications and systems that help organizations become more efficient. AI engineers can help cut costs, increase productivity and profits, and make business recommendations.\\n*   **ArtIficial intelligence research scientists** develop techniques and infrastructure to harness AI\\'s power in industries, from health care to financial services.\\n*   **Business intelligence developers** organize, analyze, and report data, and create visualization models.\\n*   **Computer vision engineers**create programs that can create and interpret visual information like a human brain would, such as scanning a QR code to view a restaurant menu.\\n*   **Data engineers** build systems that collect, manage, and convert raw data into usable information for data scientists, business analysts, and other data professionals to interpret.\\n*   **Data scientists** develop predictive models, forecast patterns and outcomes, and use machine learning techniques to improve products.\\n*   **Deep learning engineers** help improve AI so it can better mimic the way people acquire knowledge.\\n*   **Machine learning engineers** develop, build, design, test, maintain, and improve AI systems.\\n*   **Natural language processing engineers** may create tools that allow AI to recognize speech patterns, and improve existing tools to enhance the user experience.\\n*   [**Robotics engineers**](https://www.mtu.edu/ece/undergraduate/robotics/what-is/index.html) develop robotic applications for industries, including automotive, manufacturing, defense, and medicine.\\n*   **[Software engineers](https://www.mtu.edu/cs/undergraduate/software/what/index.html) and developers** create software for computers and applications using programming languages, platforms, and architectures to develop applications from computer games to network control systems.\\n\\nSalaries for Careers in Artificial Intelligence| Career | Mean Entry-Level Salary | Mean Annual Wage | Top 10 Percent |\\n| --- | --- | --- | --- |\\n| Artificial Intelligence Engineers | [$103,908](https://www.glassdoor.com/Salaries/ai-engineer-salary-SRCH_KO0,11.htm)(Glassdoor) | [$135,378](https://www.glassdoor.com/Salaries/ai-engineer-salary-SRCH_KO0,11.htm)(Glassdoor) | [$168,000](https://www.glassdoor.com/Salaries/ai-engineer-salary-SRCH_KO0,11.htm) (Glassdoor) |\\n| Artificial Intelligence Research Scientists | [$79,203](https://www.glassdoor.com/Salaries/research-scientist-ai-salary-SRCH_KO0,21.htm)(Glassdoor) | [$103,265](https://www.glassdoor.com/Salaries/research-scientist-ai-salary-SRCH_KO0,21.htm)(Glassdoor) | [$110,000](https://www.glassdoor.com/Salaries/research-scientist-ai-salary-SRCH_KO0,21.htm) (Glassdoor) |\\n| Business Intelligence Developers | [$78,732](https://www.glassdoor.com/Salaries/business-intelligence-developer-salary-SRCH_KO0,31.htm)(Glassdoor) | [$100,807](https://www.glassdoor.com/Salaries/business-intelligence-developer-salary-SRCH_KO0,31.htm)(Glassdoor) | [$118,000](https://www.glassdoor.com/Salaries/business-intelligence-developer-salary-SRCH_KO0,31.htm) (Glassdoor) |\\n| Computer Vision Engineers | [$93,585](https://www.glassdoor.com/Salaries/computer-vision-engineer-salary-SRCH_KO0,24.htm)(Glassdoor) | [$126,686](https://www.glassdoor.com/Salaries/computer-vision-engineer-salary-SRCH_KO0,24.htm)(Glassdoor) | [$169,000](https://www.glassdoor.com/Salaries/computer-vision-engineer-salary-SRCH_KO0,24.htm) (Glassdoor) |\\n| Database Administrator | [$61,445](https://www.payscale.com/research/US/Job=Database_Administrator_(DBA)/Salary/ea3e2f27/Entry-Level)(Payscale) | $107,440(BLS) | $160,890(BLS) |\\n| Database Architect | [$85,612](https://www.payscale.com/research/US/Job=Database_Architect/Salary/bc5622ea/Early-Career)(Payscale) | $142,620(BLS) | $209,990(BLS) |\\n| Data Engineers | [$87,223](https://www.glassdoor.com/Salaries/data-engineer-salary-SRCH_KO0,13.htm)(Glassdoor) | [$106,999](https://www.glassdoor.com/Salaries/data-engineer-salary-SRCH_KO0,13.htm)(Glassdoor) | [$126,000](https://www.glassdoor.com/Salaries/data-engineer-salary-SRCH_KO0,13.htm) (Glassdoor) |\\n| Data Scientist | [$87,943](https://www.payscale.com/research/US/Job=Data_Scientist/Salary/3eb9c016/Entry-Level)(Payscale) | $124,590(BLS) | $194,410(BLS) |\\n| Deep Learning Engineers | [$112,921](https://www.glassdoor.com/Salaries/deep-learning-software-engineer-salary-SRCH_KO0,31.htm)(Glassdoor) | [$132,709](https://www.glassdoor.com/Salaries/deep-learning-software-engineer-salary-SRCH_KO0,31.htm)(Glassdoor) | [$158,000](https://www.glassdoor.com/Salaries/deep-learning-software-engineer-salary-SRCH_KO0,31.htm) (Glassdoor) |\\n| Machine Learning Engineers | [$99,260](https://www.glassdoor.com/Salaries/machine-learning-engineer-salary-SRCH_KO0,25.htm)(Glassdoor) | [$124,698](https://www.glassdoor.com/Salaries/machine-learning-engineer-salary-SRCH_KO0,25.htm)(Glassdoor) | [$153,000](https://www.glassdoor.com/Salaries/machine-learning-engineer-salary-SRCH_KO0,25.htm) (Glassdoor) |\\n| Natural Language Processing Engineers | [$117,756](https://www.glassdoor.com/Salaries/nlp-engineer-salary-SRCH_KO0,12.htm)(Glassdoor) | [$123,846](https://www.glassdoor.com/Salaries/nlp-engineer-salary-SRCH_KO0,12.htm)(Glassdoor) | [$141,000](https://www.glassdoor.com/Salaries/nlp-engineer-salary-SRCH_KO0,12.htm) (Glassdoor) |\\n| Robotics Engineers | [$81,743](https://www.payscale.com/research/US/Job=Robotics_Engineer/Salary/1ad62c29/Entry-Level)(Payscale) | [$95,446](https://www.payscale.com/research/US/Job=Robotics_Engineer/Salary)(BLS) | [$137,000](https://www.payscale.com/research/US/Job=Robotics_Engineer/Salary)(BLS) |\\n| Software Developers/Sosftware Engineers | [$68,973](https://www.payscale.com/research/US/Job=Software_Developer/Salary/b40d08f6/Entry-Level)(Payscale) | $144,570(BLS) | $211,450(BLS) |\\n| _Figures from payscale.com, accessed April 2025._ _Figures from [U.S. Bureau of Labor Statistics](https://data.bls.gov/oes/#/industry/000000) (BLS), dated May 2024._ _Figures from Glassdoor accessed April 2025._ |\\n\\nSee additional [computing salary information](https://www.mtu.edu/computing/salaries/index.html) and [engineering salary information](https://www.mtu.edu/engineering/about/salary/index.html).\\n\\nWhat Skills Do You Need In Artificial Intelligence?\\n---------------------------------------------------\\n\\n*   AI ethics\\n*   Critical thinking\\n*   Creativity\\n*   Data modeling and analytics\\n*   Libraries and frameworks\\n*   Machine learning (ML) and deep learning\\n*   Mathematics and statistics\\n*   Natural language processing (NLP)\\n*   Problem-solving\\n*   Programming languages\\n\\nPursuing an Artificial Intelligence Degree\\n------------------------------------------\\n\\nThere are several paths you can take to start your [career in AI](https://www.mtu.edu/computing/ai/career-affects/index.html). Most entry-level positions require at least a bachelor\\'s degree. The following tips can help prepare you to pursue a degree in an AI-related computing field.\\n\\n### Tips for High School Students\\n\\nIf you\\'re currently in high school and are considering a career in an AI-related computing field, here are some things to consider:\\n\\n*   Focus on your computer and math classes, as these will form the basis for your computing education. Your enjoyment (or not!) of these courses can help you decide if a career in applied computing is right for you.\\n*   Research several different computing degrees to get a sense for the ones you may want to pursue.\\n*   Talk with your teachers, school advisor, parents, friends, and classmates about your choices to get some new perspectives.\\n\\nChoosing a College for Artificial Intelligence\\n----------------------------------------------\\n\\nChoosing the school where you want to study a computing field can be easier if you follow these tips:\\n\\n*   Research colleges and universities that offer computing degree programs. You don\\'t have to major in a program called \"artificial intelligence\" to start a successful career working with AI. Look for degrees that fall under the computing umbrella.\\n*   Make sure the schools you\\'re considering offer accredited degrees. Many employers will only consider graduates from accredited institutions.\\n*   Visit the schools you\\'re interested in and ask questions about their degree program(s), scholarships, and financial aid opportunities, and application requirements and deadlines. Ask to meet faculty.\\n*   Consider the school\\'s reputation, location, size, total cost of attendance, and student housing options.\\n*   Find out about campus life, academic support, career services, class sizes, and internship opportunities.\\n*   Apply to the schools you think are the right fit beginning in your junior year of high school. Don\\'t miss the application deadline and mark other important deadlines on your calendar!\\n\\n### Tips for College Students\\n\\nIf you\\'re currently in college, consider these tips to help ensure your success in your chosen computing field:\\n\\n*   Work with your academic advisor to choose the appropriate program and courses that will give you the knowledge and skills you\\'ll need for a career in an artificial intelligence field.\\n*   Gain experience through activities like student organizations, cooperative education opportunities (co-ops) and internships, professional conferences, and research projects.\\n*   Form relationships with faculty members in your program. These connections will help you to find relevant computing experiences and jobs, both during college and after you graduate.\\n*   Network with professionals. Whether you\\'re at a conference or an on-campus career fair, seize every opportunity to form connections with professionals in the field—you never know when these contacts could come in handy!\\n*   Keep your resume up to date and brush up on your interviewing skills. Your institution may even have a dedicated career center that can help you.\\n\\nFast Facts\\n----------\\n\\n### Data Scientist Salaries\\n\\n*   Mean Entry-Level Salary (Payscale): [$87,943](https://www.payscale.com/research/US/Job=Data_Scientist/Salary/3eb9c016/Entry-Level)\\n*   Median Annual Salary (BLS): $124,590\\n*   Top 10 Percent Salary (BLS): $194,410\\n\\n_Figures from payscale.com, accessed April 2025._\\n\\n_Figures from [U.S. Bureau of Labor Statistics](https://data.bls.gov/oes/#/industry/000000) (BLS), dated May 2024._\\n\\n### Industry Sectors\\n\\n*   Aerospace\\n*   Agriculture\\n*   Automotive\\n*   Defense\\n*   Healthcare\\n*   Manufacturing\\n\\nMore About Artificial Intelligence and Data Science\\n---------------------------------------------------\\n\\n*   [How AI Affects Careers in Computing](https://www.mtu.edu/computing/ai/career-affects/index.html)\\n*   [What is Data Science?](https://www.mtu.edu/cs/undergraduate/data-science/what-is/index.html)\\n*   [Data Science vs Artificial Intelligence: Key Differences, Careers, and How to Choose](https://www.mtu.edu/cs/data-sci-vs-ai/index.html)\\n*   [What is Computer Engineering?](https://www.mtu.edu/ece/undergraduate/computer/what-is/index.html)\\n*   [Computing Salaries](https://www.mtu.edu/computing/salaries/index.html)\\n\\n[Request Undergraduate Info](https://www.mtu.edu/admissions/connect/request/index.html)\\n\\n[Request Graduate Info](https://www.mtu.edu/gradschool/prospective/request-information/index.html)\\n\\n[Apply Now](https://www.mtu.edu/apply/index.html)\\n\\nArtificial Intelligence at Michigan Tech\\n----------------------------------------\\n\\nMichigan Tech\\'s College of Computing is the first college in Michigan fully dedicated to computing, and one of only a few nationwide. Michigan Tech computing students gain knowledge and experience through a wide range of classroom and hands-on learning opportunities. Multiple programs and research projects provide avenues for students to pursue an AI-intensive education.\\n\\nAI-Related Undergraduate Degree Programs\\n----------------------------------------\\n\\n*   [Computer Science (BS)](https://www.mtu.edu/cs/undergraduate/index.html)— Choose a concentration in Computer Science, Applications, Computer Systems, or Game Development.\\n*   [Cybersecurity (BS)](https://www.mtu.edu/applied-computing/undergraduate/cybersecurity/index.html)— Choose a concentration in Software Security or System and Network Security.\\n*   [Data Science (BS)](https://www.mtu.edu/cs/undergraduate/data-science/index.html)— Choose a technical focus area in Software Engineering, Cybersecurity, Statistics, or Business Technology.\\n*   [Math + Computer Science (BS)](https://www.mtu.edu/math/undergraduate/math-computer-science/index.html)\\n*   [Software Engineering (BS)](https://www.mtu.edu/cs/undergraduate/software/index.html)\\n\\nGeneral Computing Program\\n-------------------------\\n\\nIf you\\'re still deciding which computing focus you want to pursue, Michigan Tech offers a [General Computing program](https://www.mtu.edu/cs/undergraduate/general-computing/index.html) for first-year students that gives you one or two semesters to explore the computer science discipline and decide which degree program sparks your curiosity the most. It\\'s a starting point to give you some space to choose the computing field that fits you the best.\\n\\nAI-Related Graduate Degree Programs\\n-----------------------------------\\n\\n*   [Computer Science (MS, PhD)](https://www.mtu.edu/cs/graduate/computer-science/index.html)\\n*   [Cybersecurity (MS)](https://www.mtu.edu/cs/graduate/cybersecurity/index.html)\\n*   [Data Science (MS)](https://www.mtu.edu/cs/graduate/data-science/index.html)\\n*   [Computational Science and Engineering (PhD)](https://www.mtu.edu/academics/cse/index.html)\\n\\nAccelerated Master\\'s Program\\n----------------------------\\n\\nThe Michigan Tech [accelerated master\\'s program](https://www.mtu.edu/gradschool/programs/degrees/computer-science/index.html) allows undergraduate students to count up to 9 senior-level credits toward both a Bachelor of Science and a Master of Science in computer science, cybersecurity, data science, and many more majors. You can complete both a bachelor\\'s and a master\\'s in as little as five years.\\n\\nEnterprise Program\\n------------------\\n\\nFrom industry-standard learning labs to internships, co-ops, and the Michigan Tech Enterprise Program, you\\'ll get lots of hands-on experience. In the [Enterprise Program](https://www.mtu.edu/enterprise/index.html), you\\'ll work with a multidisciplinary team of students on real projects for real clients in an environment that\\'s more like a business than a classroom. With coaching from faculty mentors and industry professionals, Enterprise teams invent products, provide services, and pioneer solutions. You\\'ll gain robust experiences in engineering design, team building, project management, and end-to-end original product development.\\n\\nComputing Research\\n------------------\\n\\nComputing is a discipline without boundaries, and the College of Computing leads computing-related research and education at Michigan Tech. Graduate and undergraduate students contribute to [AI-related research](https://www.mtu.edu/cs/research/projects/index.html) across campus guided by faculty in engineering, science, and business, and working with industry professionals, local communities, professional societies, and alumni.\\n\\nMichigan Tech\\'s [Center for Artificial Intelligence](https://www.mtu.edu/icc/centers/ai/index.html) is pursuing AI research in fields including computing, transportation, manufacturing, humanities, and health. In the center, 30 faculty members—along with industry partners, community organizations, and other stakeholders—collaborate on interdisciplinary AI research initiatives through grants and contracts totaling $12.8 million. Their work investigates fundamental advances in AI and cross-cutting research in areas including transportation, materials design, health informatics, and climate resiliency.\\n\\nThe center is also committed to preparing a new generation of AI professionals by offering cutting-edge educational programs and professional development activities to promote ethical and trustworthy development and usage of AI.\\n\\n*   [Request Information](https://www.mtu.edu/request/index.html)\\n*   [Schedule a Visit](https://www.mtu.edu/visit/index.html)\\n*   [Give](https://www.mtu.edu/giving/index.html)\\n*   [Apply](https://www.mtu.edu/apply/index.html)\\n\\nAdmissions\\n----------\\n\\n*   [Undergraduate Admissions](https://www.mtu.edu/admissions/index.html)\\n*   [Graduate Admissions](https://www.mtu.edu/gradschool/index.html)\\n*   [Global Campus](https://www.mtu.edu/globalcampus/index.html)\\n*   [Request Information](https://www.mtu.edu/request/index.html)\\n*   [Schedule a Visit](https://www.mtu.edu/visit/index.html)\\n*   [Apply](https://www.mtu.edu/apply/index.html)\\n*   [Virtual Tours](https://www.mtu.edu/virtual-tours/index.html)\\n\\nStudy and Live\\n--------------\\n\\n*   [Academics](https://www.mtu.edu/academics/)\\n*   [Degrees / Majors](https://www.mtu.edu/majors/index.html)\\n*   [Library](https://www.mtu.edu/library/index.html)\\n*   [Athletics](https://www.michigantechhuskies.com/)\\n*   [Campus and Beyond](https://www.mtu.edu/tour/index.html)\\n*   [Events Calendar](https://events.mtu.edu/)\\n*   [Recreation](https://michigantechrecreation.com/index.aspx)\\n\\nCampus Info\\n-----------\\n\\n*   [About Michigan Tech](https://www.mtu.edu/about/index.html)\\n*   [Accreditation](https://www.mtu.edu/provost/accreditation/index.html)\\n*   [Campus Map](https://map.mtu.edu/)\\n*   [Jobs at Michigan Tech](https://www.mtu.edu/jobs/index.html)\\n*   [News](https://www.mtu.edu/news/index.html)\\n*   [Summer Youth Programs](https://www.mtu.edu/syp/)\\n*   [Webcams](https://www.mtu.edu/webcams/index.html)\\n\\nPolicies and Safety\\n-------------------\\n\\n*   [Campus Safety Information](https://www.mtu.edu/title-ix/resources/campus-safety/index.html)\\n*   [Emergency Contact Information](https://www.mtu.edu/emergencycontacts/index.html)\\n*   [Report a Concern](https://www.mtu.edu/deanofstudents/concern/index.html)\\n*   [Public Safety / Police Services](https://www.mtu.edu/publicsafety/index.html)\\n*   [Student Disclosures](https://www.mtu.edu/student-affairs/interests/student-disclosure/index.html)\\n*   [Title IX](https://www.mtu.edu/title-ix/index.html)\\n*   [University Policies](https://www.mtu.edu/policy/policies/index.html)\\n\\n[College of Computing](https://www.mtu.edu/computing/)\\n------------------------------------------------------\\n\\nRekhi Hall 221\\n\\n 1400 Townsend Drive\\n\\n Houghton, MI 49931 \\n\\n*   [906-487-2209](tel:9064872209)\\n*   [computing@mtu.edu](mailto:computing@mtu.edu)\\n\\n[Contact Us](https://www.mtu.edu/computing/about/contact/)\\n*   [Facebook](https://www.facebook.com/MichiganTechComputing)\\n*   [Instagram](https://www.instagram.com/mtu_computing)\\n*   [Twitter](https://twitter.com/mtu_computing)\\n*   [Linkedin](https://www.linkedin.com/company/michigan-tech-college-of-computing)\\n*   [Youtube](https://www.youtube.com/michigantech)\\n\\n[![Image 3: Michigan Technological University](https://www.mtu.edu/mtu_resources/images/logos/michigan-tech-logo-fullname-solid-old.svg)](https://www.mtu.edu/)\\n\\n*   [Accessibility](https://www.mtu.edu/accessibility/index.html)\\n*   [Equal Opportunity](https://www.mtu.edu/eo-compliance/equal-opportunity-hiring/index.html)\\n*   [Email the Webmaster](mailto:webmaster@mtu.edu)\\n\\n*   [**Tomorrow Needs Michigan Tech**](https://www.mtu.edu/tomorrowneeds/index.html)\\n*   © 2026 [Michigan Technological University](https://www.mtu.edu/)\\n\\n[©](https://a.cms.omniupdate.com/11/?skin=oucampus&account=MTU&site=www&action=de&path=/computing/ai/index.pcf)'},\n",
              "  {'url': 'https://learning.nd.edu/resource-library/ai-overview-and-definitions/',\n",
              "   'title': 'AI Overview and Definitions | Resource Library - Notre Dame Learning',\n",
              "   'content': 'Artificial Narrow Intelligence (ANI), also called weak AI or narrow AI, refers to systems that are designed to perform specific, often complex, tasks such as analyzing large data sets, making predictions, identifying patterns, or generating text and images. All existing AI systems in use today, including generative AI models, fall under this category. These systems operate within defined limits and do not possess human-like understanding, reasoning, or adaptability across multiple domains.',\n",
              "   'score': 0.9825575,\n",
              "   'raw_content': 'AI Overview and Definitions | Resource Library | Notre Dame Learning | University of Notre Dame\\n===============\\n\\n*   [Skip To Content](https://learning.nd.edu/resource-library/ai-overview-and-definitions#content \"Skip to content = C\")\\n*   [Skip To Navigation](https://learning.nd.edu/resource-library/ai-overview-and-definitions#nav \"Skip to navigation = S\")\\n*   [Skip To Search](https://learning.nd.edu/resource-library/ai-overview-and-definitions#search-input-nav-top)\\n\\n[University of Notre Dame](https://www.nd.edu/)\\n\\n[Notre Dame Learning](https://learning.nd.edu/ \"Homepage shortcut key = 1\")\\n\\n*   [Home](https://learning.nd.edu/)\\n*    Search\\n*   [Menu](https://learning.nd.edu/resource-library/ai-overview-and-definitions#nav)\\n\\n1.   [Home](https://learning.nd.edu/) › \\n2.   Resource Library\\n\\nAI for Teaching and Learning |\\n\\nAI Overview and Definitions\\n===========================\\n\\nWhat is generative AI?\\n----------------------\\n\\nArtificial intelligence (AI), in its simplest definition, refers to any technology or machine that can perform complex tasks typically associated with human intelligence. These tasks can include problem-solving, planning, reasoning, and decision-making. As the field of AI continues to expand, the terminology and definitions used to describe it also continue to evolve. The three main categories of AI presented in this overview are artificial narrow intelligence, artificial general intelligence, and generative artificial intelligence.\\n\\n*   **Artificial Narrow Intelligence** (ANI), also called weak AI or narrow AI, refers to systems that are designed to perform specific, often complex, tasks such as analyzing large data sets, making predictions, identifying patterns, or generating text and images. All existing AI systems in use today, including generative AI models, fall under this category. These systems operate within defined limits and do not possess human-like understanding, reasoning, or adaptability across multiple domains.\\n*   **Artificial General Intelligence** (AGI) refers to the hypothetical ability of a machine to demonstrate broad, human-level intelligence. This includes the capacity to learn new tasks independently, apply knowledge across a range of areas, and adapt to unfamiliar situations. AGI does not currently exist and remains a goal of ongoing research.\\n*   **Generative Artificial Intelligence** (GenAI) refers to a subset of artificial narrow intelligence that uses algorithms to create or generate new, realistic content such as text, images, audio, and video based on patterns found in training data. Examples of GenAI systems include ChatGPT, Claude, Gemini, and Midjourney. Although these tools can produce original-seeming results, they operate within the boundaries of their training and do not possess general understanding or self-awareness.\\n\\nGenAI systems have become a topic of significant discussion because they are challenging long-standing practices in education, especially in the assessment of learning and knowledge creation. The rapid growth of these tools has also raised questions about how they may transform professional roles, such as those in journalism, computer programming, and creative industries.\\n\\nWhat can and can’t generative AI do?\\n------------------------------------\\n\\nGenAI systems typically use deep learning techniques and massively large data sets to understand, summarize, generate, and predict new content. Such a system synthesizes seemingly new and realistic outputs based on the data it has been trained on.\\n\\nGenAI systems cannot think, do, or learn as humans do, even though they may seem that way. Additionally, these systems cannot evaluate the accuracy or quality of the data they have learned from or the output they provide. They may not provide accurate references or understand what they are explaining or the process by which they arrived at the output. They are not content experts, and cannot be relied on as such.\\n\\nWhat is a “prompt?”\\n-------------------\\n\\nGenerative AI platforms generate in response to user input, or prompts. Prompts can include words, phrases, questions, or keywords that users enter to signal the AI to generate a response based on those factors—the better the prompt, the better the results.\\n\\nA good prompt has **four key elements**: Persona, Task, Requirements, and Instructions.\\n\\n*   Persona: Prompts starting with “act as ... ” or “pretend to be ... ” will provide responses similar to that of the role which you provide. Setting a specific role for a given prompt increases the likelihood of more accurate information, when done appropriately.\\n*   Task: Be clear about what you want an answer to, what you want the AI generator to do, find, analyze, etc.\\n*   Requirements: Provide as much information as possible to reduce assumptions the generator may make.\\n*   Instructions: Inform the AI generator how to complete the task.\\n\\n**Example Prompt**: You are an expert computer scientist who has been asked to explain the relationship between sorting and searching techniques. Provide a paragraph comparing and contrasting these two techniques. Be concise and use an academic tone.\\n\\nYou can use this as a starting point and utilize follow up directions to refine the result.\\n\\n*   [Home](https://learning.nd.edu/)\\n*   [About](https://learning.nd.edu/about/)\\n*   [Projects & Partnerships](https://learning.nd.edu/projects-partnerships/)\\n*   [Consultations & Teaching Programs](https://learning.nd.edu/consultations-and-programs/)\\n*   [Learning Technology](https://learning.nd.edu/learning-technology/)\\n*   [Workshops & Events](https://learning.nd.edu/workshops-and-events/)\\n*   [Resource Library](https://learning.nd.edu/resource-library/)\\n*   [News](https://learning.nd.edu/news/)\\n\\n[Notre Dame Learning](https://learning.nd.edu/)\\n\\n353 DeBartolo Hall and 943 Flanner Hall\\n\\nNotre Dame, IN 46556 USA Phone [574-631-9146](tel:574-631-9146)[learning@nd.edu](mailto:learning@nd.edu)\\n\\n*   [YouTube](https://www.youtube.com/notredamelearning)\\n*   [LinkedIn](https://www.linkedin.com/company/nd-learning)\\n\\n[© 2026](https://www.nd.edu/copyright/)[University of Notre Dame](https://www.nd.edu/)\\n\\n[![Image 1: University of Notre Dame](https://static.nd.edu/images/marks/gray/ndmark.svg)](https://www.nd.edu/)\\n\\n*   [Search](https://search.nd.edu/)\\n*   [Mobile App](https://mobile.nd.edu/)\\n*   [News](https://news.nd.edu/)\\n*   [Events](https://events.nd.edu/)\\n*   [Visit](https://www.nd.edu/visit/)\\n*   [Accessibility](https://www.nd.edu/about/accessibility/)\\n\\n*   [Facebook](https://www.facebook.com/notredame/)\\n*   [X/Twitter](https://twitter.com/NotreDame/)\\n*   [Instagram](https://www.instagram.com/notredame/)\\n*   [YouTube](https://www.youtube.com/user/NDdotEDU)\\n*   [LinkedIn](https://www.linkedin.com/school/university-of-notre-dame/)'},\n",
              "  {'url': 'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai',\n",
              "   'title': 'What is AI (artificial intelligence)? - McKinsey',\n",
              "   'content': 'AI is a machine’s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting with the environment, problem-solving, and even exercising creativity. You’ve probably interacted with AI even if you don’t realize it—voice assistants like Siri and Alexa are founded on AI technology, as are some customer service chatbots that pop up to help you navigate websites. [...] In 2012, Hinton and two of his students highlighted the power of deep learning. They applied Hinton’s algorithm to neural networks with many more layers than was typical, sparking a new focus on deep neural networks. These have been the main AI approaches of recent years. [...] 1. Move from siloed work to interdisciplinary collaboration. AI projects shouldn’t be limited to discrete pockets of organizations. Rather, AI has the biggest impact when it’s employed by cross-functional teams with a mix of skills and perspectives, enabling AI to address broad business priorities.\\n2. Empower frontline data-based decision making. AI has the potential to enable faster, better decisions at all levels of an organization. But for this to work, people at all levels need to trust the algorithms’ suggestions and feel empowered to make decisions. (Equally, people should be able to override the algorithm or make suggestions for improvement when necessary.)',\n",
              "   'score': 0.97754294,\n",
              "   'raw_content': 'What is AI (artificial intelligence)? | McKinsey\\n\\n[Skip to main content](#skipToMain)\\n\\n# What is AI (artificial intelligence)?\\n\\n| Article\\n\\n[Print](#/print)\\n\\n[Save](#/save)\\n\\nArtificial intelligence is a machine’s ability to perform some cognitive functions we usually associate with human minds.\\n\\n3D robotics hand\\n\\n### DOWNLOADS\\n\\n[Article (10 pages)](#/download/%2F~%2Fmedia%2Fmckinsey%2Ffeatured%20insights%2Fmckinsey%20explainers%2Fwhat%20is%20ai%2Fwhat-is-ai-v2.pdf%3FshouldIndex%3Dfalse)\\n\\n**Humans and machines:** a match made in [productivity](/featured-insights/mckinsey-explainers/what-is-productivity)\\xa0heaven. Our species wouldn’t have gotten very far without our mechanized workhorses. From the wheel that revolutionized agriculture to the screw that held together increasingly complex construction projects to the robot-enabled assembly lines of today, machines have made life as we know it possible. And yet, despite their seemingly endless utility, humans have long feared machines—more specifically, the possibility that machines might someday [acquire human intelligence](/featured-insights/mckinsey-explainers/what-is-artificial-general-intelligence-agi)\\xa0and strike out on their own.\\n\\n##### **Get to know and directly engage with senior McKinsey experts on AI**\\n\\n**[Sven Blumberg](/our-people/sven-blumberg)** is a senior partner in McKinsey’s Düsseldorf office; **[Michael Chui](/our-people/michael-chui)** is a partner at the McKinsey Global Institute and is based in the Bay Area office, where **[Lareina Yee](/our-people/lareina-yee)** is a senior partner; **[Kia Javanmardian](/our-people/kia-javanmardian)** is a senior partner in the Chicago office, where **[Alex Singla](/our-people/alex-singla)**, the global leader of QuantumBlack, AI by McKinsey, is also a senior partner; **[Kate Smaje](/our-people/kate-smaje)** and **[Alex Sukharevsky](/our-people/alexander-sukharevsky)** are senior partners in the London office.\\n\\nWe strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: [McKinsey\\\\_Website\\\\_Accessibility@mckinsey.com](mailto:McKinsey_Website_Accessibility@mckinsey.com)\\n\\nBut we tend to view the possibility of sentient machines with fascination as well as fear. This curiosity has helped turn science fiction into actual science. Twentieth-century theoreticians, like computer scientist and mathematician Alan Turing, envisioned a future where machines could perform functions faster than humans. The work of Turing and others soon made this a reality. Personal calculators became widely available in the 1970s, and by 2016, the US census showed that [89 percent of American households](https://www.census.gov/content/dam/Census/library/publications/2018/acs/ACS-39.pdf) had a computer. Machines—*smart* machines at that—are now just an ordinary part of our lives and culture.\\n\\nThose smart machines are also getting faster and more complex. Some computers have now crossed the [exascale](/featured-insights/mckinsey-explainers/what-is-exascale-computing) threshold, meaning they can perform as many calculations in a single second as an individual could in [31,688,765,000 years](https://kb.iu.edu/d/apeq). And beyond computation, which machines have long been faster at than we have, computers and other devices are now acquiring skills and perception that were once unique to humans and a few other species.\\n\\nSidebar\\n\\n## About QuantumBlack, AI by McKinsey\\n\\n**QuantumBlack,** McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe.\\n\\nAI is a machine’s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting with the environment, problem-solving, and even exercising creativity. You’ve probably interacted with AI even if you don’t realize it—voice assistants like Siri and Alexa are founded on AI technology, as are some customer service chatbots that pop up to help you navigate websites.\\n\\n[Applied AI](/capabilities/tech-and-ai/our-insights/the-top-trends-in-tech-2023)—simply, artificial intelligence applied to real-world problems—has serious implications for the business world. By using artificial intelligence, companies have the potential to make business more efficient and profitable. But ultimately, the value of AI isn’t in the systems themselves. Rather, it’s in how companies use these systems to assist humans—and their ability to [explain](/capabilities/quantumblack/our-insights/why-businesses-need-explainable-ai-and-how-to-deliver-it) to shareholders and the public what these systems do—in a way that builds trust and confidence.\\n\\nFor more about AI, its history, its future, and how to apply it in business, read on.\\n\\n*Learn more about [QuantumBlack, AI by McKinsey](/capabilities/quantumblack/how-we-help-clients).*\\n\\n### Looking for direct answers to other complex questions?\\n\\n[Explore the full McKinsey Explainers series](/featured-insights/mckinsey-explainers)\\n\\n## What is machine learning?\\n\\nMachine learning is a form of artificial intelligence that can adapt to a wide range of inputs, including large sets of historical data, synthesized data, or human inputs. (Some machine learning algorithms are specialized in training themselves to detect patterns; [this is called deep learning](/featured-insights/mckinsey-explainers/what-is-deep-learning). See Exhibit 1.) These algorithms can detect patterns and learn how to make predictions and recommendations by processing data, rather than by receiving explicit programming instruction. Some algorithms can also adapt in response to new data and experiences to improve over time.\\n\\nExhibit 1\\n\\nWe strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: [McKinsey\\\\_Website\\\\_Accessibility@mckinsey.com](mailto:McKinsey_Website_Accessibility@mckinsey.com)\\n\\nThe volume and complexity of data that is now being generated, too vast for humans to process and apply efficiently, has increased the potential of machine learning, as well as the need for it. In the years since its widespread deployment, which began in the 1970s, machine learning has had an impact on a number of industries, including achievements in [medical-imaging analysis](/industries/healthcare/our-insights/transforming-healthcare-with-ai)\\xa0and high-resolution weather forecasting.\\n\\n> The volume and complexity of data that is now being generated, too vast for humans to process and apply efficiently, has increased the potential of machine learning, as well as the need for it.\\n\\n## What is deep learning?\\n\\nDeep learning is a more advanced version of machine learning that is particularly adept at processing a wider range of data resources (text as well as unstructured data including images), requires even less human intervention, and can often produce more accurate results than traditional machine learning. Deep learning uses neural networks—based on the [ways neurons interact in the human brain](/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-applications-and-value-of-deep-learning)—to ingest data and process it through multiple neuron layers that recognize increasingly complex features of the data. For example, an early layer might recognize something as being in a specific shape; building on this knowledge, a later layer might be able to identify the shape as a stop sign. Similar to machine learning, deep learning uses iteration to self-correct and improve its prediction capabilities. For example, once it “learns” what a stop sign looks like, it can recognize a stop sign in a new image.\\n\\n*Learn more about *[QuantumBlack, AI by McKinsey](/capabilities/quantumblack/how-we-help-clients)*.*\\n\\n## What is generative AI?\\n\\nSidebar\\n\\n## Case study: Vistra and the Martin Lake Power Plant\\n\\n**Vistra is a large power producer** in the United States, operating plants in 12 states with a capacity to power nearly 20 million homes. Vistra has committed to achieving net-zero emissions by 2050. In support of this goal, as well as to improve overall efficiency, [QuantumBlack, AI by McKinsey](/capabilities/quantumblack/how-we-help-clients) worked with Vistra to build and deploy an AI-powered heat rate optimizer (HRO) at one of its plants.\\n\\n“Heat rate” is a measure of the thermal efficiency of the plant; in other words, it’s the amount of fuel required to produce each unit of electricity. To reach the optimal heat rate, plant operators continuously monitor and tune hundreds of variables, such as steam temperatures, pressures, oxygen levels, and fan speeds.\\n\\nVistra and a McKinsey team, including data scientists and machine learning engineers, built a multilayered neural network model. The model combed through two years’ worth of data at the plant and learned which combination of factors would attain the most efficient heat rate at any point in time. When the models were accurate to 99 percent or higher and run through a rigorous set of real-world tests, the team converted them into an AI-powered engine that generates recommendations every 30 minutes for operators to improve the plant’s heat rate efficiency. One seasoned operations manager at the company’s plant in Odessa, Texas, said, “There are things that took me 20 years to learn about these power plants. This model learned them in an afternoon.”\\n\\nOverall, the AI-powered HRO helped Vistra achieve the following:\\n\\n* approximately 1.6 million metric tons of carbon abated annually\\n* 67 power generators optimized\\n* $60 million saved in about a year\\n\\n*Read more about the Vistra story [here](/capabilities/tech-and-ai/how-we-help-clients/an-ai-power-play-fueling-the-next-wave-of-innovation-in-the-energy-sector).*\\n\\n[Generative AI](/featured-insights/mckinsey-explainers/what-is-generative-ai) (gen AI) is an AI model that generates content in response to a prompt. It’s clear that generative AI tools like ChatGPT and DALL-E (a tool for AI-generated art) have the potential to change how [a range of jobs](/mgi/our-research/generative-ai-how-will-it-affect-future-jobs-and-workflows)\\xa0are performed. Much is still unknown about gen AI’s potential, but there are some questions we can answer—like how gen AI models are built, what kinds of problems they are best suited to solve, and how they fit into the broader category of AI and machine learning.\\n\\nFor more on generative AI and how it stands to affect business and society, check out our *Explainer* “[What is generative AI?](/featured-insights/mckinsey-explainers/what-is-generative-ai)”\\n\\n## What is the history of AI?\\n\\nThe term “artificial intelligence” was [coined in 1956](/capabilities/operations/our-insights/an-executive-primer-on-artificial-general-intelligence)\\xa0by computer scientist John McCarthy for a workshop at Dartmouth. But he wasn’t the first to write about the concepts we now describe as AI.\\nAlan Turing introduced the concept of the “[imitation game](https://slate.com/culture/2014/12/the-imitation-game-fact-vs-fiction-how-true-the-new-movie-is-to-alan-turings-real-life-story.html)” in a 1950 paper. That’s the test of a machine’s ability to exhibit intelligent behavior, now known as the “Turing test.” He believed researchers should focus on areas that don’t require too much sensing and action, things like games and language translation. Research communities dedicated to concepts like computer vision, natural language understanding, and neural networks are, in many cases, several decades old.\\n\\nMIT physicist Rodney Brooks [shared](/capabilities/operations/our-insights/an-executive-primer-on-artificial-general-intelligence) details on the four previous stages of AI:\\n\\n* *Symbolic AI (1956).* Symbolic AI is also known as classical AI, or even GOFAI (good old-fashioned AI). The key concept here is the use of symbols and logical reasoning to solve problems. For example, we know [a German shepherd is a dog](/capabilities/operations/our-insights/an-executive-primer-on-artificial-general-intelligence), which is a mammal; all mammals are warm-blooded; therefore, a German shepherd should be warm-blooded.\\n\\n  The main problem with symbolic AI is that humans still need to manually encode their knowledge of the world into the symbolic AI system, rather than allowing it to observe and encode relationships on its own. As a result, symbolic AI systems struggle with situations involving real-world complexity. They also lack the ability to learn from large amounts of data.\\n\\n  Symbolic AI was the dominant paradigm of AI research until the late 1980s.\\n* *Neural networks (1954, 1969, 1986, 2012).* Neural networks are the technology behind the recent explosive growth of gen AI. Loosely modeling the [ways neurons interact in the human brain](/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-applications-and-value-of-deep-learning), neural networks ingest data and process it through multiple iterations that learn increasingly complex features of the data. The neural network can then make determinations about the data, learn whether a determination is correct, and use what it has learned to make determinations about new data. For example, once it “learns” what an object looks like, it can recognize the object in a new image.\\n\\n  Neural networks were first proposed in 1943 in an academic paper by neurophysiologist Warren McCulloch and logician Walter Pitts. Decades later, in 1969, two MIT researchers mathematically demonstrated that neural networks could perform only very basic tasks. In 1986, there was another reversal, when computer scientist and cognitive psychologist Geoffrey Hinton and colleagues solved the neural network problem presented by the MIT researchers. In the 1990s, computer scientist Yann LeCun made major advancements in neural networks’ use in computer vision, while Jürgen Schmidhuber advanced the application of recurrent neural networks as used in language processing.\\n\\n  In 2012, Hinton and two of his students highlighted the power of deep learning. They applied Hinton’s algorithm to neural networks with many more layers than was typical, sparking a new focus on deep neural networks. These have been the main AI approaches of recent years.\\n* *Traditional robotics (1968).* During the first few decades of AI, researchers built robots to advance research. Some robots were mobile, moving around on wheels, while others were fixed, with articulated arms. Robots used the earliest attempts at computer vision to identify and navigate through their environments or to understand the geometry of objects and maneuver them. This could include moving around blocks of various shapes and colors. Most of these robots, just like the ones that have been used in factories for decades, rely on highly controlled environments with thoroughly scripted behaviors that they perform repeatedly. They have not contributed significantly to the advancement of AI itself.\\n\\n  But traditional robotics did have significant impact in one area, through a process called “simultaneous localization and mapping” (SLAM). SLAM algorithms helped contribute to self-driving cars and are used in consumer products like vacuum cleaning robots and quadcopter drones. Today, this work has evolved into behavior-based robotics, also referred to as haptic technology because it responds to human touch.\\n* *Behavior-based robotics (1985).* In the real world, there aren’t always clear instructions for navigation, decision making, or problem-solving. Insects, researchers observed, navigate very well (and are evolutionarily very successful) with few neurons. Behavior-based robotics researchers took inspiration from this, looking for ways robots could solve problems with partial knowledge and conflicting instructions. These behavior-based robots are embedded with neural networks.\\n\\n*Learn more about\\xa0*[QuantumBlack, AI by McKinsey](/capabilities/quantumblack/how-we-help-clients)*.*\\n\\n## What is artificial general intelligence?\\n\\nThe term “artificial general intelligence” (AGI) was coined to describe AI systems that possess [capabilities comparable to those of a human](/capabilities/operations/our-insights/an-executive-primer-on-artificial-general-intelligence). In theory, AGI could someday replicate human-like cognitive abilities including reasoning, problem-solving, perception, learning, and language comprehension. But let’s not get ahead of ourselves: the key word here is “someday.” Most researchers and academics believe we are decades away from realizing AGI; some even predict we won’t see AGI this century, or ever. Rodney Brooks, an MIT roboticist and cofounder of iRobot, doesn’t believe AGI will arrive until [the year 2300](/capabilities/operations/our-insights/an-executive-primer-on-artificial-general-intelligence).\\n\\nThe timing of AGI’s emergence may be uncertain. But when it does emerge—and it likely will—it’s going to be a very big deal, in every aspect of our lives. Executives should begin working to understand the path to machines achieving human-level intelligence now and making the transition to a more automated world.\\n\\nFor more on AGI, including the four previous attempts at AGI, read our *[Explainer](/featured-insights/mckinsey-explainers/what-is-artificial-general-intelligence-agi)*.\\n\\n## What is narrow AI?\\n\\nNarrow AI is the application of AI techniques to a specific and well-defined problem, such as chatbots like ChatGPT, algorithms that spot fraud in credit card transactions, and natural-language-processing engines that quickly process thousands of legal documents. Most current AI applications fall into the category of narrow AI. AGI is, by contrast, AI that’s intelligent enough to perform a broad range of tasks.\\n\\n*Learn more about *[QuantumBlack, AI by McKinsey](/capabilities/quantumblack/how-we-help-clients)*.*\\n\\n## How is the use of AI expanding?\\n\\nAI is a big story for all kinds of businesses, but some companies are clearly moving [ahead of the pack](/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review). Our state of AI in 2022 survey showed that adoption of AI models has more than doubled since 2017—and investment has increased apace. What’s more, the specific areas in which companies see value from AI have evolved, from manufacturing and risk to the following:\\n\\n* marketing and sales\\n* product and service development\\n* strategy and corporate finance\\n\\nOne group of companies is pulling ahead of its competitors. Leaders of these organizations consistently make larger investments in AI, level up their practices to scale faster, and hire and upskill the best AI talent. More specifically, they link AI strategy to business outcomes and “[industrialize](/capabilities/quantumblack/our-insights/power-up-how-southeast-asias-largest-bank-is-becoming-ai-fueled)” AI operations by designing modular data architecture that can quickly accommodate new applications.\\n\\n## What are the limitations of AI models? How can these potentially be overcome?\\n\\nWe have yet to see the longtail effect of gen AI models. This means there are some inherent risks involved in using them—both known and unknown.\\n\\nThe outputs gen AI models produce may often sound extremely convincing. This is by design. But sometimes the information they generate is just plain wrong. Worse, sometimes it’s biased (because it’s built on the gender, racial, and other biases of the internet and society more generally).\\n\\nIt can also be manipulated to enable unethical or criminal activity. Since gen AI models burst onto the scene, organizations have become aware of users trying to “jailbreak” the models—that means trying to get them to break their own rules and deliver biased, harmful, misleading, or even illegal content. Gen AI organizations are responding to this threat in two ways: for one thing, they’re collecting feedback from users on inappropriate content. They’re also combing through their databases, identifying prompts that led to inappropriate content, and training the model against these types of generations.\\n\\nBut awareness and even action don’t guarantee that harmful content won’t slip the dragnet. Organizations that rely on gen AI models should be aware of the reputational and legal risks involved in unintentionally publishing biased, offensive, or copyrighted content.\\n\\nThese risks can be mitigated, however, in a few ways. “Whenever you use a model,” says McKinsey partner Marie El Hoyek, “you need to be able to [counter biases](/capabilities/operations/our-insights/generative-ai-in-operations-capturing-the-value)\\xa0and instruct it not to use inappropriate or flawed sources, or things you don’t trust.” How? For one thing, it’s crucial to carefully select the initial data used to train these models to avoid including toxic or biased content. Next, rather than employing an off-the-shelf gen AI model, organizations could consider using smaller, specialized models. Organizations with more resources could also customize a general model based on their own data to fit their needs and minimize biases.\\n\\nIt’s also important to keep a human in the loop (that is, to make sure a real human checks the output of a gen AI model before it is published or used) and avoid using gen AI models for critical decisions, such as those involving significant resources or human welfare.\\n\\nIt can’t be emphasized enough that this is a new field. The landscape of risks and opportunities is likely to continue to change rapidly in the coming years. As gen AI becomes increasingly incorporated into business, society, and our personal lives, we can also expect a new regulatory climate to take shape. As organizations experiment—and create value—with these tools, leaders will do well to keep a finger on the pulse of regulation and risk.\\n\\n*Learn more about *[QuantumBlack, AI by McKinsey](/capabilities/quantumblack/how-we-help-clients)*.*\\n\\n## What is the AI Bill of Rights?\\n\\nThe Blueprint for an AI Bill of Rights, prepared by the US government in 2022, provides a framework for how government, technology companies, and citizens can collectively ensure more accountable AI. As AI has become more ubiquitous, [concerns have surfaced](/capabilities/risk-and-resilience/our-insights/as-gen-ai-advances-regulators-and-risk-functions-rush-to-keep-pace)\\xa0about a potential lack of transparency surrounding the functioning of gen AI systems, the data used to train them, issues of bias and fairness, potential intellectual property infringements, privacy violations, and more. The Blueprint comprises five principles that [the White House says](https://www.whitehouse.gov/ostp/ai-bill-of-rights/#discrimination) should “guide the design, use, and deployment of automated systems to protect [users] in the age of artificial intelligence.” They are as follows:\\n\\n* *The right to safe and effective systems.* Systems should undergo predeployment testing, risk identification and mitigation, and ongoing monitoring to demonstrate that they are adhering to their intended use.\\n* *Protections against discrimination by algorithms.* Algorithmic discrimination is when automated systems contribute to unjustified different treatment of people based on their race, color, ethnicity, sex, religion, age, and more.\\n* *Protections against abusive data practices,* via built-in safeguards. Users should also have agency over how their data is used.\\n* *The right to know that an automated system is being used,* and a clear explanation of how and why it contributes to outcomes that affect the user.\\n* *The right to opt out,* and access to a human who can quickly consider and fix problems.\\n\\nAt present, more than 60 countries or blocs have national strategies governing the responsible use of AI\\xa0(Exhibit 2). These include Brazil, China, the European Union, Singapore, South Korea, and the United States. The approaches taken vary from guidelines-based approaches, such as the Blueprint for an AI Bill of Rights in the United States, to comprehensive AI regulations that align with existing data protection and cybersecurity regulations, such as the EU’s AI Act, due in 2024.\\n\\nExhibit 2\\n\\nWe strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: [McKinsey\\\\_Website\\\\_Accessibility@mckinsey.com](mailto:McKinsey_Website_Accessibility@mckinsey.com)\\n\\nThere are also collaborative efforts between countries to set out standards for AI use. The US–EU Trade and Technology Council is working toward greater alignment between Europe and the United States. The Global Partnership on Artificial Intelligence, formed in 2020, has 29 members including Brazil, Canada, Japan, the United States, and several European countries.\\n\\nEven though AI regulations are still being developed, organizations should act now to avoid legal, reputational, organizational, and financial risks. In an environment of public concern, a misstep could be costly. Here are four no-regrets, preemptive actions organizations can implement today:\\n\\n* *Transparency.* Create an inventory of models, classifying them in accordance with regulation, and record all usage across the organization that is clear to those inside and outside the organization.\\n* *Governance.* Implement a governance structure for AI and gen AI that ensures sufficient oversight, authority, and accountability both within the organization and with third parties and regulators.\\n* *Data, model, and technology management.*\\n  + *Data management.* Proper data management includes awareness of data sources, data classification, data quality and lineage, intellectual property, and privacy management.\\n  + *Model management.* Organizations should establish principles and guardrails for AI development and use them to ensure all AI models uphold fairness and bias controls.\\n  + *Cybersecurity and technology management.* Establish strong cybersecurity and technology to ensure a secure environment where unauthorized access or misuse is prevented.\\n* *Individual rights.* Make users aware when they are interacting with an AI system, and provide clear instructions for use.\\n\\n## How can organizations scale up their AI efforts from ad hoc projects to full integration?\\n\\nMost organizations are dipping a toe into the AI pool—not cannonballing. Slow progress toward widespread adoption is likely due to cultural and organizational barriers. But leaders who effectively break down these barriers will be best placed to capture the opportunities of the AI era. And—crucially—companies that can’t take full advantage of AI are already being [sidelined](https://hbr.org/2021/05/getting-ai-to-scale) by those that can, in industries like auto manufacturing and financial services.\\n\\nTo scale up AI, organizations can make [three major shifts](https://hbr.org/2019/07/building-the-ai-powered-organization):\\n\\n1. *Move from siloed work to interdisciplinary collaboration.* AI projects shouldn’t be limited to discrete pockets of organizations. Rather, AI has the biggest impact when it’s employed by cross-functional teams with a mix of skills and perspectives, enabling AI to address broad business priorities.\\n2. *Empower frontline data-based [decision making](/featured-insights/mckinsey-explainers/what-is-decision-making).* AI has the potential to enable faster, better decisions at all levels of an organization. But for this to work, people at all levels need to trust the algorithms’ suggestions and feel empowered to make decisions. (Equally, people should be able to override the algorithm or make suggestions for improvement when necessary.)\\n3. *Adopt and bolster an [agile](/featured-insights/mckinsey-explainers/what-is-agile) mindset.* The agile test-and-learn mindset will help reframe mistakes as sources of discovery, allaying the fear of failure and speeding up development.\\n\\n*Learn more about *[QuantumBlack, AI by McKinsey](/capabilities/quantumblack/how-we-help-clients)*, and check out [AI-related job opportunities](https://www.mckinsey.com/careers/search-jobs?query=AI) if you’re interested in working at McKinsey.*\\n\\n## Pop quiz\\n\\n## They grow up so fast\\n\\nBy 2022, adoption of AI had grown by how much since 2017?\\n\\nHow do you measure up? Only 41% of readers got this right.\\n\\n### Sorry, that’s not it.\\n\\nIn 2017, companies using AI saw the most value in manufacturing and risk management. By 2022, they were seeing the most value in marketing and sales, product and service development, and strategy and corporate finance.\\n\\nTake more quizzes\\n\\n[Data Points](/featured-insights/mckinsey-data-points)\\n\\nA - More than 1.5 times\\n\\nB - More than 2 times\\n\\nC - More than 2.5 times\\n\\n## Shifting gears\\n\\nTo scale up AI, organizations can make three major shifts. Which of the following is NOT one of them?\\n\\nHow do you measure up? 52% of readers knew the answer.\\n\\n### Sorry, that’s not it.\\n\\nOrganizations should shift from siloed work to interdisciplinary collaboration. AI is most effective when it’s being used by different teams with a range of varied talents to address broad business priorities.\\n\\nTake more quizzes\\n\\n[Data Points](/featured-insights/mckinsey-data-points)\\n\\nA - Move toward a more direct collaboration between individuals and AI tools.\\n\\nB - Empower frontline, data-based decision making.\\n\\nC - Adopt and bolster an agile mindset.\\n\\n## A new kind of network\\n\\nThere are three types of artificial neural networks used in machine learning. Which of the following is NOT one of them?\\n\\nHow do you measure up? 51% of readers knew the answer.\\n\\n*Articles referenced:*\\n\\n* “[As gen AI advances, regulators—and risk functions—rush to keep pace](/capabilities/risk-and-resilience/our-insights/as-gen-ai-advances-regulators-and-risk-functions-rush-to-keep-pace),” December 21, 2023, Andreas Kremer, [Angela Luget](/our-people/angela-luget), Daniel Mikkelsen, [Henning Soller](/our-people/henning-soller), Malin Strandell-Jansson, and Sheila Zingg\\n* “[What is generative AI?](/featured-insights/mckinsey-explainers/what-is-generative-ai),” January 19, 2023\\n* “[Tech highlights from 2022—in eight charts](/capabilities/tech-and-ai/our-insights/tech-highlights-from-2022-in-eight-charts),” December 22, 2022\\n* “[Generative AI is here: How tools like ChatGPT could change your business](/capabilities/quantumblack/our-insights/generative-ai-is-here-how-tools-like-chatgpt-could-change-your-business),” December 20, 2022, Michael Chui, [Roger Roberts](/our-people/roger-roberts), and [Lareina Yee](/our-people/lareina-yee)\\n* “[The state of AI in 2022—and a half decade in review](/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review),” December 6, 2022, Michael Chui, [Bryce Hall](/our-people/bryce-hall), Helen Mayhew, [Alex Singla](/our-people/alex-singla), and [Alex Sukharevsky](/our-people/alexander-sukharevsky)\\n* “[Why businesses need explainable AI—and how to deliver it](/capabilities/quantumblack/our-insights/why-businesses-need-explainable-ai-and-how-to-deliver-it),” September 29, 2022, Liz Grennan, Andreas Kremer, [Alex Singla](/our-people/alex-singla), and Peter Zipparo\\n* “[Why digital trust truly matters](/capabilities/quantumblack/our-insights/why-digital-trust-truly-matters),” September 12, 2022, [Jim Boehm](/our-people/jim-boehm), Liz Grennan, [Alex Singla](/our-people/alex-singla), and [Kate Smaje](/our-people/kate-smaje)\\n* “[McKinsey Technology Trends Outlook 2023](/capabilities/tech-and-ai/our-insights/the-top-trends-in-tech-2023),” July 20, 2023, Michael Chui, Mena Issler, [Roger Roberts](/our-people/roger-roberts), and [Lareina Yee](/our-people/lareina-yee)\\n* “[An AI power play: Fueling the next wave of innovation in the energy sector](/capabilities/tech-and-ai/how-we-help-clients/an-ai-power-play-fueling-the-next-wave-of-innovation-in-the-energy-sector),” May 12, 2022, Barry Boswell, Sean Buckley, Ben Elliott, [Matias Melero](/our-people/matias-melero), and [Micah Smith](/our-people/micah-smith)\\n* “[Scaling AI like a tech native: The CEO’s role](/capabilities/quantumblack/our-insights/scaling-ai-like-a-tech-native-the-ceos-role),” October 13, 2021, Jacomo Corbo, David Harvey, Nicolas Hohn, [Kia Javanmardian](/our-people/kia-javanmardian), and [Nayur Khan](/our-people/nayur-khan)\\n* “[What the draft European Union AI regulations mean for business](/capabilities/quantumblack/our-insights/what-the-draft-european-union-ai-regulations-mean-for-business),” August 10, 2021, Misha Benjamin, [Kevin Buehler](/our-people/kevin-buehler), Rachel Dooley, and Peter Zipparo\\n* “[Winning with AI is a state of mind](/capabilities/quantumblack/our-insights/winning-with-ai-is-a-state-of-mind),” April 30, 2021, Thomas Meakin, Jeremy Palmer, [Valentina Sartori](/our-people/valentina-sartori), and Jamie Vickers\\n* “[Breaking through data-architecture gridlock to scale AI](/capabilities/tech-and-ai/our-insights/breaking-through-data-architecture-gridlock-to-scale-ai),” January 26, 2021, [Sven Blumberg](/our-people/sven-blumberg), [Jorge Machado](/our-people/jorge-machado), [Henning Soller](/our-people/henning-soller), and [Asin Tavakoli](/our-people/asin-tavakoli)\\n* “[An executive’s guide to AI](/capabilities/quantumblack/our-insights/an-executives-guide-to-ai),” November 17, 2020, Michael Chui, Brian McCarthy, and Vishnu Kamalnath\\n* “[Executive’s guide to developing AI at scale](/capabilities/quantumblack/our-insights/executives-guide-to-developing-ai-at-scale),” October 28, 2020, [Nayur Khan](/our-people/nayur-khan), Brian McCarthy, and Adi Pradhan\\n* “[An executive primer on artificial general intelligence](/capabilities/operations/our-insights/an-executive-primer-on-artificial-general-intelligence),” April 29, 2020, [Federico Berruti](/our-people/federico-berruti), Pieter Nel, and Rob Whiteman\\n* “[The analytics academy: Bridging the gap between human and artificial intelligence](/capabilities/quantumblack/our-insights/the-analytics-academy-bridging-the-gap-between-human-and-artificial-intelligence),” *McKinsey Quarterly*, September 25, 2019, Solly Brown, Darshit Gandhi, Louise Herring, and [Ankur Puri](/our-people/ankur-puri)\\n\\n*This article was updated in April 2024; it was originally published in April 2023.*\\n\\n### Want to know more about AI?\\n\\n[Talk to us](/capabilities/quantumblack/how-we-help-clients)\\n\\n##### How relevant and useful is this article for you?\\n\\n##### Related Articles\\n\\nArticle\\n\\n###### [Ten unsung digital and AI ideas shaping business](/capabilities/tech-and-ai/our-insights/ten-unsung-digital-and-ai-ideas-shaping-business)\\n\\nPodcast\\n\\n###### [Driving innovation with generative AI](/capabilities/strategy-and-corporate-finance/our-insights/driving-innovation-with-generative-ai)\\n\\nArticle\\n\\n###### [As gen AI advances, regulators—and risk functions—rush to keep pace](/capabilities/risk-and-resilience/our-insights/as-gen-ai-advances-regulators-and-risk-functions-rush-to-keep-pace)\\n\\nSign up for our Monthly Highlights'}],\n",
              " 'request_id': '57533688-524a-40e5-84ea-0251bb13cfde'}"
            ]
          }
        }
      ],
      "id": "10bde0d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52btTC1XjAC3",
        "outputId": "d18871ad-42d0-4508-e194-73d081bddd36"
      },
      "source": [
        "# ============================================================================\n",
        "# TEST: LLM decides NOT to use tool (direct answer)\n",
        "# ============================================================================\n",
        "# For simple questions, the LLM may choose to answer directly\n",
        "# without calling any tools\n",
        "\n",
        "print(\"Query: 'what is AI in 1 line'\")\n",
        "print(\"-\" * 50)\n",
        "print(\"This is a simple question - LLM likely answers directly\\n\")\n",
        "\n",
        "response = llm_with_tools.invoke('what is AI in 1 line')\n",
        "\n",
        "# Check if the LLM called any tools\n",
        "if response.tool_calls:\n",
        "    print(f\"LLM decided to call tools: {[tc['name'] for tc in response.tool_calls]}\")\n",
        "else:\n",
        "    print(\"LLM answered directly (no tool calls)\")\n",
        "    print(f\"\\nResponse: {response.content}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Artificial intelligence is the field of computer science that creates systems capable of performing tasks that normally require human intelligence, such as learning, reasoning, and perception.', additional_kwargs={'reasoning_content': 'User asks: \"what is AI in 1 line\". Provide a concise definition. No need for external info. Just answer.'}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 147, 'total_tokens': 213, 'completion_time': 0.139389486, 'completion_tokens_details': {'reasoning_tokens': 27}, 'prompt_time': 0.005622963, 'prompt_tokens_details': None, 'queue_time': 0.055371838, 'total_time': 0.145012449}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_8a618bed98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bdbb0-3a5b-73c2-9fbc-d0dafabdc757-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 147, 'output_tokens': 66, 'total_tokens': 213, 'output_token_details': {'reasoning': 27}})"
            ]
          }
        }
      ],
      "id": "52btTC1XjAC3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjOYMS0rn1CF",
        "outputId": "8fe3b02b-148c-4ea7-c83f-eb9a8b8f6229"
      },
      "source": [
        "# ============================================================================\n",
        "# TEST: LLM decides TO USE tool (needs current info)\n",
        "# ============================================================================\n",
        "# For questions requiring current/real-time information,\n",
        "# the LLM should decide to call the search tool\n",
        "\n",
        "print(\"Query: 'what is the latest news on nvidia'\")\n",
        "print(\"-\" * 50)\n",
        "print(\"This requires current info - LLM should use the search tool\\n\")\n",
        "\n",
        "response = llm_with_tools.invoke('what is the latest news on nvidia')\n",
        "\n",
        "# Check if the LLM called any tools\n",
        "if response.tool_calls:\n",
        "    print(\"LLM decided to call a tool!\")\n",
        "    print(f\"Tool calls: {response.tool_calls}\")\n",
        "    print(\"\\nNote: The response contains tool_calls instead of content\")\n",
        "    print(\"The actual tool execution happens in a ToolNode (next section)\")\n",
        "else:\n",
        "    print(\"LLM answered directly (no tool calls)\")\n",
        "    print(f\"Response: {response.content}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'reasoning_content': 'The user asks: \"what is the latest news on nvidia\". Need up-to-date info. Use web search.', 'tool_calls': [{'id': 'fc_59deb81f-12bd-471c-94af-c8d2c16aaf0e', 'function': {'arguments': '{\"num_results\":10,\"query\":\"latest news Nvidia January 2026\"}', 'name': 'search_web'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 148, 'total_tokens': 214, 'completion_time': 0.142249837, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.00576271, 'prompt_tokens_details': None, 'queue_time': 0.054217539, 'total_time': 0.148012547}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_8a618bed98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bdbb0-3c18-7f13-aa37-3ff54cfe3ef7-0', tool_calls=[{'name': 'search_web', 'args': {'num_results': 10, 'query': 'latest news Nvidia January 2026'}, 'id': 'fc_59deb81f-12bd-471c-94af-c8d2c16aaf0e', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 148, 'output_tokens': 66, 'total_tokens': 214, 'output_token_details': {'reasoning': 25}})"
            ]
          }
        }
      ],
      "id": "wjOYMS0rn1CF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPFD28OWjGQM"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 3: Create the Graph with the Augmented LLM\n",
        "\n",
        "### Key LangGraph Components for Tool Use\n",
        "\n",
        "| Component | Purpose |\n",
        "|-----------|---------|\n",
        "| **ToolNode** | Pre-built node that executes tool calls |\n",
        "| **tools_condition** | Pre-built routing function for tool decisions |\n",
        "\n",
        "### How it Works\n",
        "\n",
        "1. **LLM Node** receives user message and returns:\n",
        "   - Direct response (no tools needed), OR\n",
        "   - Tool call request (tools needed)\n",
        "\n",
        "2. **tools_condition** checks the LLM response:\n",
        "   - If `tool_calls` present → route to ToolNode\n",
        "   - If no `tool_calls` → route to END\n",
        "\n",
        "3. **ToolNode** executes the requested tools and returns results\n",
        "\n",
        "```\n",
        "                    ┌─────────────────┐\n",
        "                    │ tool_calling_llm│\n",
        "                    └────────┬────────┘\n",
        "                             │\n",
        "                    ┌────────▼────────┐\n",
        "                    │ tools_condition │\n",
        "                    └────────┬────────┘\n",
        "               ┌─────────────┴─────────────┐\n",
        "               │                           │\n",
        "               ▼                           ▼\n",
        "         ┌──────────┐                 ┌─────────┐\n",
        "         │  tools   │                 │   END   │\n",
        "         │(ToolNode)│                 │         │\n",
        "         └──────────┘                 └─────────┘\n",
        "```\n",
        "\n",
        "![](https://i.imgur.com/5r015dw.png)"
      ],
      "id": "NPFD28OWjGQM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJvHs_Py3uCV"
      },
      "source": [
        "# ============================================================================\n",
        "# BUILD THE AUGMENTED LLM GRAPH\n",
        "# ============================================================================\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 1: Define the LLM node with tool-calling capability\n",
        "# This node calls our tool-augmented LLM\n",
        "# -----------------------------------------------------------------------------\n",
        "def tool_calling_llm(state: State) -> State:\n",
        "    \"\"\"\n",
        "    Node that calls the tool-augmented LLM.\n",
        "    \n",
        "    The LLM will:\n",
        "    1. Analyze the user's message\n",
        "    2. Decide if tools are needed\n",
        "    3. Return either:\n",
        "       - A direct response (AIMessage with content)\n",
        "       - A tool call request (AIMessage with tool_calls)\n",
        "    \"\"\"\n",
        "    current_messages = state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(current_messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 2: Build the graph\n",
        "# -----------------------------------------------------------------------------\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# Add the LLM node (makes decisions about tool use)\n",
        "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
        "\n",
        "# Add the ToolNode (executes tools when called)\n",
        "# ToolNode is a pre-built node that:\n",
        "# - Extracts tool calls from the AIMessage\n",
        "# - Executes each tool with provided arguments\n",
        "# - Returns ToolMessage(s) with results\n",
        "builder.add_node(\"tools\", ToolNode(tools=tools))\n",
        "\n",
        "# Entry point\n",
        "builder.add_edge(START, \"tool_calling_llm\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 3: Add conditional routing based on tool_calls\n",
        "# tools_condition is a pre-built function that:\n",
        "# - Returns \"tools\" if the LLM response has tool_calls\n",
        "# - Returns END if no tool_calls (direct response)\n",
        "# -----------------------------------------------------------------------------\n",
        "builder.add_conditional_edges(\n",
        "    \"tool_calling_llm\",\n",
        "    tools_condition  # Built-in routing: checks for tool_calls in response\n",
        "    # Automatically routes to \"tools\" or END\n",
        ")\n",
        "\n",
        "# After tools execute, we're done (for this simple example)\n",
        "builder.add_edge(\"tools\", END)\n",
        "\n",
        "# Compile\n",
        "graph = builder.compile()\n",
        "\n",
        "print(\"Augmented LLM graph compiled!\")\n",
        "print(\"Graph structure:\")\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "execution_count": 7,
      "outputs": [],
      "id": "IJvHs_Py3uCV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "JR2L3D5Y3uH9",
        "outputId": "f4b09c6f-e2f8-471f-9b2b-5d1ed8b52500"
      },
      "source": [
        "# ============================================================================\n",
        "# VISUALIZE THE GRAPH\n",
        "# ============================================================================\n",
        "# Notice the conditional edge from tool_calling_llm\n",
        "# It can go to either \"tools\" or \"__end__\"\n",
        "\n",
        "print(\"Graph Visualization:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Flow options:\")\n",
        "print(\"  1. START → tool_calling_llm → END (no tools needed)\")\n",
        "print(\"  2. START → tool_calling_llm → tools → END (tools called)\")\n",
        "print(\"-\" * 50)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x116eaecf0>"
            ]
          }
        }
      ],
      "id": "JR2L3D5Y3uH9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca",
        "outputId": "71b24894-aa5e-492f-c4bf-e007d776ac3d"
      },
      "source": [
        "# ============================================================================\n",
        "# TEST 1: Query that DOESN'T need tools\n",
        "# ============================================================================\n",
        "# Simple factual question - LLM can answer from training data\n",
        "# Expected: Direct response, no tool calls\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST 1: Simple query (no tools needed)\")\n",
        "print(\"Query: 'Explain AI in 2 bullets'\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "user_input = \"Explain AI in 2 bullets\"\n",
        "\n",
        "print(\"\\nStreaming graph execution:\\n\")\n",
        "for event in graph.stream({\"messages\": user_input},\n",
        "                          stream_mode='values'):\n",
        "    event['messages'][-1].pretty_print()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Observation: LLM answered directly without calling any tools\")\n",
        "print(\"=\" * 70)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Explain AI in 2 bullets\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "- **Artificial Intelligence (AI)** is the field of computer science that creates systems capable of performing tasks that normally require human intelligence—such as learning, reasoning, perception, and decision‑making—by using algorithms, data, and computational models (e.g., machine learning, neural networks, symbolic reasoning).  \n",
            "\n",
            "- **AI works by extracting patterns from data (training) and applying those learned patterns to new situations (inference), enabling applications like image/video recognition, natural‑language understanding, recommendation engines, autonomous robots, and many other technologies that automate or augment human capabilities.**\n"
          ]
        }
      ],
      "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-zYQrB6383i",
        "outputId": "5a4d52db-9562-45ce-a68b-cb567a7d85e9"
      },
      "source": [
        "# ============================================================================\n",
        "# TEST 2: Query that NEEDS tools (current information)\n",
        "# ============================================================================\n",
        "# This question requires current/real-time information\n",
        "# Expected: LLM calls search_web tool, results returned\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST 2: Query requiring current information (tools needed)\")\n",
        "print(\"Query: 'What is the latest news on OpenAI product releases'\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "user_input = \"What is the latest news on OpenAI product releases\"\n",
        "\n",
        "print(\"\\nStreaming graph execution:\\n\")\n",
        "for event in graph.stream({\"messages\": user_input},\n",
        "                          stream_mode='values'):\n",
        "    event['messages'][-1].pretty_print()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Observation: LLM decided to use the search_web tool!\")\n",
        "print(\"The flow was: LLM → tool call → ToolNode executes → Results returned\")\n",
        "print(\"=\" * 70)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the latest news on OpenAI product releases\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  search_web (fc_7cc898d1-f73a-4fe4-a6ea-f136d834051f)\n",
            " Call ID: fc_7cc898d1-f73a-4fe4-a6ea-f136d834051f\n",
            "  Args:\n",
            "    num_results: 10\n",
            "    query: latest news OpenAI product releases 2025 2026\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_web\n",
            "\n",
            "{\"query\": \"latest news OpenAI product releases 2025 2026\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://openai.com/news/\", \"title\": \"OpenAI News\", \"content\": \"Image 2: OAI Go Blog ArtCard 1x1\\n\\nIntroducing ChatGPT Go, now available worldwide Product Jan 16, 2026\\n\\nImage 3: OAI Ads Blog ArtCard 1x1\\n\\nOur approach to advertising and expanding access to ChatGPT Company Jan 16, 2026\\n\\nImage 4: OpenAI for Healthcare > Cover Image\\n\\nIntroducing OpenAI for Healthcare Product Jan 8, 2026\\n\\nImage 5: OAI ChatGPT Health ArtCard\\n\\nIntroducing ChatGPT Health Product Jan 7, 2026\\n\\nImage 6: Prompt injection Art Card 1x1\\n\\nContinuously hardening ChatGPT Atlas against prompt injection attacks Security Dec 22, 2025\\n\\nImage 7: CoT Monitorability Art Card 1x1\\n\\nEvaluating chain-of-thought monitorability Research Dec 18, 2025\\n\\nImage 8: AI literacy > Cover Image \\n\\nAI literacy resources for teens and parents Safety Dec 18, 2025\\n\\nImage 9: u18 model spec blog > Cover Image [...] Image 9: u18 model spec blog > Cover Image\\n\\nUpdating our Model Spec with teen protections Safety Dec 18, 2025\\n\\nLoad more\\n\\nOur Research\\n   Research Index\\n   Research Overview\\n   Research Residency\\n   OpenAI for Science\\n\\nLatest Advancements\\n   GPT-5\\n   OpenAI o3\\n   OpenAI o4-mini\\n   GPT-4o\\n   GPT-4o mini\\n   Sora\\n\\nSafety\\n   Safety Approach\\n   Security & Privacy\\n   Trust & Transparency\\n\\nChatGPT\\n   Explore ChatGPT(opens in a new window)\\n   Business\\n   Enterprise\\n   Education\\n   Pricing(opens in a new window)\\n   Download(opens in a new window)\\n\\nSora\\n   Sora Overview\\n   Features\\n   Pricing\\n   Sora log in(opens in a new window)\\n\\nAPI Platform\\n   Platform Overview\\n   Pricing\\n   API log in(opens in a new window)\\n   Documentation(opens in a new window)\\n   Developer Forum(opens in a new window) [...] For Developers\\n\\nBack to main menu  \\n\\n       API Platform\\n       API Pricing\\n       Agents\\n       Codex\\n       Open Models\\n       Community(opens in a new window)\\n\\n   ChatGPT\\n\\nBack to main menu  \\n\\n       Explore ChatGPT\\n       Business\\n       Enterprise\\n       Education\\n       Pricing\\n       Download\\n\\n   Sora\\n   Stories\\n   Company\\n\\nBack to main menu  \\n\\n       About Us\\n       Our Charter\\n       Foundation\\n       Careers\\n       Brand Guidelines\\n\\n   News\\n\\nLog in\\n\\nOpenAI\\n\\nAll\\n\\n   Company\\n   Research\\n   Product\\n   Safety\\n   Engineering\\n   Security\\n   Global Affairs\\n   All\\n\\nFilter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\nImage 1: value of intelligence > card image\\n\\nA business that scales with the value of intelligence Company Jan 18, 2026\", \"score\": 0.90791017, \"raw_content\": \"OpenAI News | OpenAI\\n===============\\n\\n[Skip to main content](https://openai.com/news/#main)\\n\\nLog in\\n\\n[](https://openai.com/)\\n\\nSwitch to\\n\\n*   [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n*   [Sora(opens in a new window)](https://sora.com/)\\n*   [API Platform(opens in a new window)](https://platform.openai.com/)\\n\\n*   [Research](https://openai.com/research/index/) \\n*   [Safety](https://openai.com/safety/) \\n*   [For Business](https://openai.com/business/) \\n*   [For Developers](https://openai.com/api/) \\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true) \\n*   [Sora](https://openai.com/sora/) \\n*   [Stories](https://openai.com/stories/) \\n*   [Company](https://openai.com/about/) \\n*   [News](https://openai.com/news/company-announcements/) \\n\\n*   Research\\n\\nBack to main menu  \\n\\n    *   [Research Index](https://openai.com/research/index/)\\n    *   [Research Overview](https://openai.com/research/)\\n    *   [Research Residency](https://openai.com/residency/)\\n    *   [OpenAI for Science](https://openai.com/science/)\\n    *   Latest Advancements\\n    *   [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)\\n    *   [GPT-5.1](https://openai.com/index/gpt-5-1/)\\n    *   [Sora 2](https://openai.com/index/sora-2/)\\n    *   [GPT-5](https://openai.com/index/introducing-gpt-5/)\\n    *   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n    *   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)\\n\\n*   Safety\\n\\nBack to main menu  \\n\\n    *   [Safety Approach](https://openai.com/safety/)\\n    *   [Security & Privacy](https://openai.com/security-and-privacy/)\\n\\n*   [For Business](https://openai.com/business/)\\n\\nBack to main menu  \\n\\n    *   [Business Overview](https://openai.com/business/)\\n    *   [Solutions](https://openai.com/solutions/)\\n    *   [Learn](https://openai.com/business/learn/)\\n    *   [Startups](https://openai.com/startups/)\\n    *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Contact Sales](https://openai.com/contact-sales/)\\n\\n*   For Developers\\n\\nBack to main menu  \\n\\n    *   [API Platform](https://openai.com/api/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Agents](https://openai.com/agent-platform/)\\n    *   [Codex](https://openai.com/codex/)\\n    *   [Open Models](https://openai.com/open-models/)\\n    *   [Community(opens in a new window)](https://community.openai.com/)\\n\\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n\\nBack to main menu  \\n\\n    *   [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n    *   [Business](https://chatgpt.com/for-business/team?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n    *   [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n    *   [Education](https://chatgpt.com/for-business/education?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n    *   [Pricing](https://chatgpt.com/pricing?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n    *   [Download](https://chatgpt.com/download?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n\\n*   [Sora](https://openai.com/sora/)\\n*   [Stories](https://openai.com/stories/)\\n*   Company\\n\\nBack to main menu  \\n\\n    *   [About Us](https://openai.com/about/)\\n    *   [Our Charter](https://openai.com/charter/)\\n    *   [Foundation](https://openai.com/foundation/)\\n    *   [Careers](https://openai.com/careers/)\\n    *   [Brand Guidelines](https://openai.com/brand/)\\n\\n*   [News](https://openai.com/news/company-announcements/)\\n\\nLog in\\n\\nOpenAI\\n\\nAll\\n---\\n\\n*   [Company](https://openai.com/news/company-announcements/)\\n*   [Research](https://openai.com/news/research/)\\n*   [Product](https://openai.com/news/product-releases/)\\n*   [Safety](https://openai.com/news/safety-alignment/)\\n*   [Engineering](https://openai.com/news/engineering/)\\n*   [Security](https://openai.com/news/security/)\\n*   [Global Affairs](https://openai.com/news/global-affairs/)\\n*   [All](https://openai.com/news/)\\n\\nFilter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\n![Image 1: value of intelligence > card image](https://images.ctfassets.net/kftzwdyauwt9/5FbKILxhG8ChQNiTuo3Z5w/1068ca6739eb82bc631600002ffa8b19/a-business-that-scales-with-the-value-of-intelligence-1_1.png?w=3840&q=90&fm=webp)\\n\\n[A business that scales with the value of intelligence Company Jan 18, 2026](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/)\\n\\n![Image 2: OAI Go Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/6VqoFRZtqjJVLA9k1zrVkl/7064d5a2ff89f48f03737b88ecc42f32/OAI_Go_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Go, now available worldwide Product Jan 16, 2026](https://openai.com/index/introducing-chatgpt-go/)\\n\\n![Image 3: OAI Ads Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/41z4Qn4f0i948wZMLWB9lH/f3961891b0e0274306ea19fe368c95d7/OAI_Ads_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Our approach to advertising and expanding access to ChatGPT Company Jan 16, 2026](https://openai.com/index/our-approach-to-advertising-and-expanding-access/)\\n\\n![Image 4: OpenAI for Healthcare > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/4oQtNGNaY29dDxIKJBVphg/18314fd6a66f31249a5f95ec238272de/OAI_forHealth_ArtCard_1-1_C.png?w=3840&q=90&fm=webp)\\n\\n[Introducing OpenAI for Healthcare Product Jan 8, 2026](https://openai.com/index/openai-for-healthcare/)\\n\\n![Image 5: OAI ChatGPT Health ArtCard](https://images.ctfassets.net/kftzwdyauwt9/3hnWarC0m5jJPEoEU3HZGw/59c55e915ebc3dcf4d49efab8e166a19/OAI_ChatGPT_Health_ArtCard.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Health Product Jan 7, 2026](https://openai.com/index/introducing-chatgpt-health/)\\n\\n![Image 6: Prompt injection Art Card 1x1](https://images.ctfassets.net/kftzwdyauwt9/6klpmFj71I12NG6dndGPbX/5f1326142606c5c25401afad6f69ea02/Prompt_injection_Art_Card_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Continuously hardening ChatGPT Atlas against prompt injection attacks Security Dec 22, 2025](https://openai.com/index/hardening-atlas-against-prompt-injection/)\\n\\n![Image 7: CoT Monitorability Art Card 1x1](https://images.ctfassets.net/kftzwdyauwt9/2OSRVNZMsrZJxKL5BHDMMN/29f625e30531a21102fd35fe1d1e63ba/CoT_Monitorability_Art_Card_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Evaluating chain-of-thought monitorability Research Dec 18, 2025](https://openai.com/index/evaluating-chain-of-thought-monitorability/)\\n\\n![Image 8: AI literacy > Cover Image ](https://images.ctfassets.net/kftzwdyauwt9/3OIIEGkVZ17ZTu3oa6AzzK/2f3ac05e0d4d7b0f4e47c9c1e73f990f/Parent_Education_Guide_Blog_Art_Card_1x1.png?w=3840&q=90&fm=webp)\\n\\n[AI literacy resources for teens and parents Safety Dec 18, 2025](https://openai.com/index/ai-literacy-resources-for-teens-and-parents/)\\n\\n![Image 9: u18 model spec blog > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/7btzsyFGza0WHgwkDj2Qbi/b1e6ccb2edab7933f42c786cc4447249/u18_Blog_Art_Card_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Updating our Model Spec with teen protections Safety Dec 18, 2025](https://openai.com/index/updating-model-spec-with-teen-protections/)\\n\\nLoad more\\n\\nOur Research\\n*   [Research Index](https://openai.com/research/index/)\\n*   [Research Overview](https://openai.com/research/)\\n*   [Research Residency](https://openai.com/residency/)\\n*   [OpenAI for Science](https://openai.com/science/)\\n\\nLatest Advancements\\n*   [GPT-5](https://openai.com/gpt-5/)\\n*   [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\\n*   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)\\n*   [Sora](https://openai.com/index/sora-system-card/)\\n\\nSafety\\n*   [Safety Approach](https://openai.com/safety/)\\n*   [Security & Privacy](https://openai.com/security-and-privacy/)\\n*   [Trust & Transparency](https://openai.com/trust-and-transparency/)\\n\\nChatGPT\\n*   [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n*   [Business](https://chatgpt.com/business/business-plan?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n*   [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n*   [Education](https://chatgpt.com/business/education?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n*   [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n*   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=972ca3fe-9154-42fe-83c5-53239677aeef&openaicom_referred=true)\\n\\nSora\\n*   [Sora Overview](https://openai.com/sora/)\\n*   [Features](https://openai.com/sora/#features)\\n*   [Pricing](https://openai.com/sora/#pricing)\\n*   [Sora log in(opens in a new window)](https://sora.com/)\\n\\nAPI Platform\\n*   [Platform Overview](https://openai.com/api/)\\n*   [Pricing](https://openai.com/api/pricing/)\\n*   [API log in(opens in a new window)](https://platform.openai.com/login)\\n*   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)\\n*   [Developer Forum(opens in a new window)](https://community.openai.com/)\\n\\nFor Business\\n*   [Business Overview](https://openai.com/business/)\\n*   [Solutions](https://openai.com/solutions/)\\n*   [Contact Sales](https://openai.com/contact-sales/)\\n\\nCompany\\n*   [About Us](https://openai.com/about/)\\n*   [Our Charter](https://openai.com/charter/)\\n*   [Foundation](https://openai.com/foundation/)\\n*   [Careers](https://openai.com/careers/)\\n*   [Brand](https://openai.com/brand/)\\n\\nSupport\\n*   [Help Center(opens in a new window)](https://help.openai.com/)\\n\\nMore\\n*   [News](https://openai.com/news/)\\n*   [Stories](https://openai.com/stories/)\\n*   [Livestreams](https://openai.com/live/)\\n*   [Podcast](https://openai.com/podcast/)\\n*   [RSS](https://openai.com/news/rss.xml)\\n\\nTerms & Policies\\n*   [Terms of Use](https://openai.com/policies/terms-of-use/)\\n*   [Privacy Policy](https://openai.com/policies/privacy-policy/)\\n*   [Other Policies](https://openai.com/policies/)\\n\\n[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)\\n\\nOpenAI © 2015–2026 Manage Cookies\\n\\nEnglish United States\"}, {\"url\": \"https://openai.com/news/company-announcements/\", \"title\": \"OpenAI Newsroom | Recent news\", \"content\": \"Introducing ChatGPT Health Product Jan 7, 2026\\n\\nImage 10: u18 model spec blog > Cover Image\\n\\nUpdating our Model Spec with teen protections Safety Dec 18, 2025\\n\\nImage 11: GPT-5.2-Codex blog 1x1\\n\\nIntroducing GPT-5.2-Codex Product Dec 18, 2025\\n\\nImage 12: AppsEcosystem-SEO-ArtCard-1x1\\n\\nDevelopers can now submit apps to ChatGPT Product Dec 17, 2025\\n\\nImage 13: 1 x 1\\n\\nHow we used Codex to build Sora for Android in 28 days Engineering Dec 12, 2025\\n\\nImage 14: 5.2 math and science > Cover image\\n\\nAdvancing science and math with GPT-5.2 Publication Dec 11, 2025\\n\\nLoad more\\n\\nOur Research\\n   Research Index\\n   Research Overview\\n   Research Residency\\n   OpenAI for Science\\n\\nLatest Advancements\\n   GPT-5\\n   OpenAI o3\\n   OpenAI o4-mini\\n   GPT-4o\\n   GPT-4o mini\\n   Sora [...] Image 2: ChatGPT Health\\n\\nIntroducing ChatGPT Health Product Jan 7, 2026\\n\\nImage 3: OAI Go Blog ArtCard 1x1\\n\\nIntroducing ChatGPT Go, now available worldwide Product 3 min read\\n\\nImage 4: Image Gen Blog Art Card 1x1\\n\\nThe new ChatGPT Images is here Product Dec 16, 2025\\n\\nImage 5: GPT-5.2-Codex blog 1x1\\n\\nIntroducing GPT-5.2-Codex Product 5 min read\\n\\nImage 6: value of intelligence > card image\\n\\nA business that scales with the value of intelligence Company Jan 18, 2026\\n\\nImage 7: OAI Ads Blog ArtCard 1x1\\n\\nOur approach to advertising and expanding access to ChatGPT Company Jan 16, 2026\\n\\nImage 8: OpenAI for Healthcare > Cover Image\\n\\nIntroducing OpenAI for Healthcare Product Jan 8, 2026\\n\\nImage 9: OAI ChatGPT Health ArtCard\\n\\nIntroducing ChatGPT Health Product Jan 7, 2026 [...] For Developers\\n\\nBack to main menu  \\n\\n       API Platform\\n       API Pricing\\n       Agents\\n       Codex\\n       Open Models\\n       Community(opens in a new window)\\n\\n   ChatGPT\\n\\nBack to main menu  \\n\\n       Explore ChatGPT\\n       Business\\n       Enterprise\\n       Education\\n       Pricing\\n       Download\\n\\n   Sora\\n   Stories\\n   Company\\n\\nBack to main menu  \\n\\n       About Us\\n       Our Charter\\n       Foundation\\n       Careers\\n       Brand Guidelines\\n\\n   News\\n\\nLog in\\n\\nOpenAI\\n\\nRecent news\\n\\n   Company\\n   Research\\n   Product\\n   Safety\\n   Engineering\\n   Security\\n   Global Affairs\\n   All\\n\\nFilter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\nImage 1: ChatGPT Health\\n\\nIntroducing ChatGPT Health Product Jan 7, 2026\\n\\nImage 2: ChatGPT Health\", \"score\": 0.9037116, \"raw_content\": \"OpenAI Newsroom | Recent news | OpenAI\\n===============\\n\\n[Skip to main content](https://openai.com/news/company-announcements/#main)\\n\\nLog in\\n\\n[](https://openai.com/)\\n\\nSwitch to\\n\\n*   [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n*   [Sora(opens in a new window)](https://sora.com/)\\n*   [API Platform(opens in a new window)](https://platform.openai.com/)\\n\\n*   [Research](https://openai.com/research/index/) \\n*   [Safety](https://openai.com/safety/) \\n*   [For Business](https://openai.com/business/) \\n*   [For Developers](https://openai.com/api/) \\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true) \\n*   [Sora](https://openai.com/sora/) \\n*   [Stories](https://openai.com/stories/) \\n*   [Company](https://openai.com/about/) \\n*   [News](https://openai.com/news/company-announcements/) \\n\\n*   Research\\n\\nBack to main menu  \\n\\n    *   [Research Index](https://openai.com/research/index/)\\n    *   [Research Overview](https://openai.com/research/)\\n    *   [Research Residency](https://openai.com/residency/)\\n    *   [OpenAI for Science](https://openai.com/science/)\\n    *   Latest Advancements\\n    *   [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)\\n    *   [GPT-5.1](https://openai.com/index/gpt-5-1/)\\n    *   [Sora 2](https://openai.com/index/sora-2/)\\n    *   [GPT-5](https://openai.com/index/introducing-gpt-5/)\\n    *   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n    *   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)\\n\\n*   Safety\\n\\nBack to main menu  \\n\\n    *   [Safety Approach](https://openai.com/safety/)\\n    *   [Security & Privacy](https://openai.com/security-and-privacy/)\\n\\n*   [For Business](https://openai.com/business/)\\n\\nBack to main menu  \\n\\n    *   [Business Overview](https://openai.com/business/)\\n    *   [Solutions](https://openai.com/solutions/)\\n    *   [Learn](https://openai.com/business/learn/)\\n    *   [Startups](https://openai.com/startups/)\\n    *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Contact Sales](https://openai.com/contact-sales/)\\n\\n*   For Developers\\n\\nBack to main menu  \\n\\n    *   [API Platform](https://openai.com/api/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Agents](https://openai.com/agent-platform/)\\n    *   [Codex](https://openai.com/codex/)\\n    *   [Open Models](https://openai.com/open-models/)\\n    *   [Community(opens in a new window)](https://community.openai.com/)\\n\\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n\\nBack to main menu  \\n\\n    *   [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n    *   [Business](https://chatgpt.com/for-business/team?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n    *   [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n    *   [Education](https://chatgpt.com/for-business/education?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n    *   [Pricing](https://chatgpt.com/pricing?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n    *   [Download](https://chatgpt.com/download?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n\\n*   [Sora](https://openai.com/sora/)\\n*   [Stories](https://openai.com/stories/)\\n*   Company\\n\\nBack to main menu  \\n\\n    *   [About Us](https://openai.com/about/)\\n    *   [Our Charter](https://openai.com/charter/)\\n    *   [Foundation](https://openai.com/foundation/)\\n    *   [Careers](https://openai.com/careers/)\\n    *   [Brand Guidelines](https://openai.com/brand/)\\n\\n*   [News](https://openai.com/news/company-announcements/)\\n\\nLog in\\n\\nOpenAI\\n\\nRecent news\\n-----------\\n\\n*   [Company](https://openai.com/news/company-announcements/)\\n*   [Research](https://openai.com/news/research/)\\n*   [Product](https://openai.com/news/product-releases/)\\n*   [Safety](https://openai.com/news/safety-alignment/)\\n*   [Engineering](https://openai.com/news/engineering/)\\n*   [Security](https://openai.com/news/security/)\\n*   [Global Affairs](https://openai.com/news/global-affairs/)\\n*   [All](https://openai.com/news/)\\n\\nFilter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\n![Image 1: ChatGPT Health](https://images.ctfassets.net/kftzwdyauwt9/2zlj1v5fup8IPQFeD0HI8j/908a1aafec67c13ee67a62163e3c3c35/OAI_ChatGPT_Health_SEO.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Health Product Jan 7, 2026](https://openai.com/index/introducing-chatgpt-health/)\\n\\n![Image 2: ChatGPT Health](https://images.ctfassets.net/kftzwdyauwt9/2zlj1v5fup8IPQFeD0HI8j/908a1aafec67c13ee67a62163e3c3c35/OAI_ChatGPT_Health_SEO.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Health Product Jan 7, 2026](https://openai.com/index/introducing-chatgpt-health/)\\n\\n![Image 3: OAI Go Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/6VqoFRZtqjJVLA9k1zrVkl/7064d5a2ff89f48f03737b88ecc42f32/OAI_Go_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Go, now available worldwide Product 3 min read](https://openai.com/index/introducing-chatgpt-go/)\\n\\n![Image 4: Image Gen Blog Art Card 1x1](https://images.ctfassets.net/kftzwdyauwt9/3ITYCyFN8IYXpM19fump1e/435c595475f13fe38258e394cd7e0330/Image_Gen_Blog_Art_Card_1x1.png?w=3840&q=90&fm=webp)\\n\\n[The new ChatGPT Images is here Product Dec 16, 2025](https://openai.com/index/new-chatgpt-images-is-here/)\\n\\n![Image 5: GPT-5.2-Codex blog 1x1](https://images.ctfassets.net/kftzwdyauwt9/7MS110rihMT7s5O8mXuCpT/5c376f0c3ab7850a11cd1756c242d3fa/OAI_GPT-5.2-Codex_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing GPT-5.2-Codex Product 5 min read](https://openai.com/index/introducing-gpt-5-2-codex/)\\n\\n![Image 6: value of intelligence > card image](https://images.ctfassets.net/kftzwdyauwt9/5FbKILxhG8ChQNiTuo3Z5w/1068ca6739eb82bc631600002ffa8b19/a-business-that-scales-with-the-value-of-intelligence-1_1.png?w=3840&q=90&fm=webp)\\n\\n[A business that scales with the value of intelligence Company Jan 18, 2026](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/)\\n\\n![Image 7: OAI Ads Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/41z4Qn4f0i948wZMLWB9lH/f3961891b0e0274306ea19fe368c95d7/OAI_Ads_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Our approach to advertising and expanding access to ChatGPT Company Jan 16, 2026](https://openai.com/index/our-approach-to-advertising-and-expanding-access/)\\n\\n![Image 8: OpenAI for Healthcare > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/4oQtNGNaY29dDxIKJBVphg/18314fd6a66f31249a5f95ec238272de/OAI_forHealth_ArtCard_1-1_C.png?w=3840&q=90&fm=webp)\\n\\n[Introducing OpenAI for Healthcare Product Jan 8, 2026](https://openai.com/index/openai-for-healthcare/)\\n\\n![Image 9: OAI ChatGPT Health ArtCard](https://images.ctfassets.net/kftzwdyauwt9/3hnWarC0m5jJPEoEU3HZGw/59c55e915ebc3dcf4d49efab8e166a19/OAI_ChatGPT_Health_ArtCard.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Health Product Jan 7, 2026](https://openai.com/index/introducing-chatgpt-health/)\\n\\n![Image 10: u18 model spec blog > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/7btzsyFGza0WHgwkDj2Qbi/b1e6ccb2edab7933f42c786cc4447249/u18_Blog_Art_Card_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Updating our Model Spec with teen protections Safety Dec 18, 2025](https://openai.com/index/updating-model-spec-with-teen-protections/)\\n\\n![Image 11: GPT-5.2-Codex blog 1x1](https://images.ctfassets.net/kftzwdyauwt9/7MS110rihMT7s5O8mXuCpT/5c376f0c3ab7850a11cd1756c242d3fa/OAI_GPT-5.2-Codex_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing GPT-5.2-Codex Product Dec 18, 2025](https://openai.com/index/introducing-gpt-5-2-codex/)\\n\\n![Image 12: AppsEcosystem-SEO-ArtCard-1x1](https://images.ctfassets.net/kftzwdyauwt9/7MOcpj3xffkBaaLfDbL2pv/f5b01f66adce6dd2bb08c95d696d4347/AppsEcosystem-SEO-ArtCard-1x1.png?w=3840&q=90&fm=webp)\\n\\n[Developers can now submit apps to ChatGPT Product Dec 17, 2025](https://openai.com/index/developers-can-now-submit-apps-to-chatgpt/)\\n\\n![Image 13: 1 x 1](https://images.ctfassets.net/kftzwdyauwt9/38dcecW4JVMBEDqex7AmLJ/4dd8e32fc9e06a82c20310d1f83645f3/OpenAI_SoraAndroid_1x1.png?w=3840&q=90&fm=webp)\\n\\n[How we used Codex to build Sora for Android in 28 days Engineering Dec 12, 2025](https://openai.com/index/shipping-sora-for-android-with-codex/)\\n\\n![Image 14: 5.2 math and science > Cover image](https://images.ctfassets.net/kftzwdyauwt9/6181tZAk7ZeAC4bU0QsSDL/ce50a1b724dc999d7e066f5bb423d517/GPT-5.2_MathScience_1x1__1_.png?w=3840&q=90&fm=webp)\\n\\n[Advancing science and math with GPT-5.2 Publication Dec 11, 2025](https://openai.com/index/gpt-5-2-for-science-and-math/)\\n\\nLoad more\\n\\nOur Research\\n*   [Research Index](https://openai.com/research/index/)\\n*   [Research Overview](https://openai.com/research/)\\n*   [Research Residency](https://openai.com/residency/)\\n*   [OpenAI for Science](https://openai.com/science/)\\n\\nLatest Advancements\\n*   [GPT-5](https://openai.com/gpt-5/)\\n*   [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\\n*   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)\\n*   [Sora](https://openai.com/index/sora-system-card/)\\n\\nSafety\\n*   [Safety Approach](https://openai.com/safety/)\\n*   [Security & Privacy](https://openai.com/security-and-privacy/)\\n*   [Trust & Transparency](https://openai.com/trust-and-transparency/)\\n\\nChatGPT\\n*   [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n*   [Business](https://chatgpt.com/business/business-plan?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n*   [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n*   [Education](https://chatgpt.com/business/education?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n*   [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n*   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=6d2f119a-0a28-46e5-b590-ac081c60d1dd&openaicom_referred=true)\\n\\nSora\\n*   [Sora Overview](https://openai.com/sora/)\\n*   [Features](https://openai.com/sora/#features)\\n*   [Pricing](https://openai.com/sora/#pricing)\\n*   [Sora log in(opens in a new window)](https://sora.com/)\\n\\nAPI Platform\\n*   [Platform Overview](https://openai.com/api/)\\n*   [Pricing](https://openai.com/api/pricing/)\\n*   [API log in(opens in a new window)](https://platform.openai.com/login)\\n*   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)\\n*   [Developer Forum(opens in a new window)](https://community.openai.com/)\\n\\nFor Business\\n*   [Business Overview](https://openai.com/business/)\\n*   [Solutions](https://openai.com/solutions/)\\n*   [Contact Sales](https://openai.com/contact-sales/)\\n\\nCompany\\n*   [About Us](https://openai.com/about/)\\n*   [Our Charter](https://openai.com/charter/)\\n*   [Foundation](https://openai.com/foundation/)\\n*   [Careers](https://openai.com/careers/)\\n*   [Brand](https://openai.com/brand/)\\n\\nSupport\\n*   [Help Center(opens in a new window)](https://help.openai.com/)\\n\\nMore\\n*   [News](https://openai.com/news/)\\n*   [Stories](https://openai.com/stories/)\\n*   [Livestreams](https://openai.com/live/)\\n*   [Podcast](https://openai.com/podcast/)\\n*   [RSS](https://openai.com/news/rss.xml)\\n\\nTerms & Policies\\n*   [Terms of Use](https://openai.com/policies/terms-of-use/)\\n*   [Privacy Policy](https://openai.com/policies/privacy-policy/)\\n*   [Other Policies](https://openai.com/policies/)\\n\\n[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)\\n\\nOpenAI © 2015–2026 Manage Cookies\\n\\nEnglish United States\"}, {\"url\": \"https://openai.com/news/product-releases/\", \"title\": \"OpenAI Newsroom | Product\", \"content\": \"Image 2: OAI Ads Blog ArtCard 1x1\\n\\nOur approach to advertising and expanding access to ChatGPT Company Jan 16, 2026\\n\\nImage 3: OpenAI for Healthcare > Cover Image\\n\\nIntroducing OpenAI for Healthcare Product Jan 8, 2026\\n\\nImage 4: OAI ChatGPT Health ArtCard\\n\\nIntroducing ChatGPT Health Product Jan 7, 2026\\n\\nImage 5: GPT-5.2-Codex blog 1x1\\n\\nIntroducing GPT-5.2-Codex Product Dec 18, 2025\\n\\nImage 6: AppsEcosystem-SEO-ArtCard-1x1\\n\\nDevelopers can now submit apps to ChatGPT Product Dec 17, 2025\\n\\nImage 7: Image Gen Blog Art Card 1x1\\n\\nThe new ChatGPT Images is here Product Dec 16, 2025\\n\\nImage 8: 5.2 math and science > Cover image\\n\\nAdvancing science and math with GPT-5.2 Publication Dec 11, 2025\\n\\nImage 9: 5.2-Blog-1x1\\n\\nIntroducing GPT-5.2 Product Dec 11, 2025\\n\\nLoad more [...] Introducing GPT-5.2 Product Dec 11, 2025\\n\\nLoad more\\n\\nOur Research\\n   Research Index\\n   Research Overview\\n   Research Residency\\n   OpenAI for Science\\n\\nLatest Advancements\\n   GPT-5\\n   OpenAI o3\\n   OpenAI o4-mini\\n   GPT-4o\\n   GPT-4o mini\\n   Sora\\n\\nSafety\\n   Safety Approach\\n   Security & Privacy\\n   Trust & Transparency\\n\\nChatGPT\\n   Explore ChatGPT(opens in a new window)\\n   Business\\n   Enterprise\\n   Education\\n   Pricing(opens in a new window)\\n   Download(opens in a new window)\\n\\nSora\\n   Sora Overview\\n   Features\\n   Pricing\\n   Sora log in(opens in a new window)\\n\\nAPI Platform\\n   Platform Overview\\n   Pricing\\n   API log in(opens in a new window)\\n   Documentation(opens in a new window)\\n   Developer Forum(opens in a new window)\\n\\nFor Business\\n   Business Overview\\n   Solutions\\n   Contact Sales [...] For Developers\\n\\nBack to main menu  \\n\\n       API Platform\\n       API Pricing\\n       Agents\\n       Codex\\n       Open Models\\n       Community(opens in a new window)\\n\\n   ChatGPT\\n\\nBack to main menu  \\n\\n       Explore ChatGPT\\n       Business\\n       Enterprise\\n       Education\\n       Pricing\\n       Download\\n\\n   Sora\\n   Stories\\n   Company\\n\\nBack to main menu  \\n\\n       About Us\\n       Our Charter\\n       Foundation\\n       Careers\\n       Brand Guidelines\\n\\n   News\\n\\nLog in\\n\\nOpenAI Newsroom | Product | OpenAI\\n\\nProduct\\n\\n   Company\\n   Research\\n   Product\\n   Safety\\n   Engineering\\n   Security\\n   Global Affairs\\n   All\\n\\nFilter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\nImage 1: OAI Go Blog ArtCard 1x1\\n\\nIntroducing ChatGPT Go, now available worldwide Product Jan 16, 2026\", \"score\": 0.8947989, \"raw_content\": \"OpenAI Newsroom | Product | OpenAI\\n===============\\n\\n[Skip to main content](https://openai.com/news/product-releases/#main)\\n\\nLog in\\n\\n[](https://openai.com/)\\n\\nSwitch to\\n\\n*   [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n*   [Sora(opens in a new window)](https://sora.com/)\\n*   [API Platform(opens in a new window)](https://platform.openai.com/)\\n\\n*   [Research](https://openai.com/research/index/) \\n*   [Safety](https://openai.com/safety/) \\n*   [For Business](https://openai.com/business/) \\n*   [For Developers](https://openai.com/api/) \\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true) \\n*   [Sora](https://openai.com/sora/) \\n*   [Stories](https://openai.com/stories/) \\n*   [Company](https://openai.com/about/) \\n*   [News](https://openai.com/news/company-announcements/) \\n\\n*   Research\\n\\nBack to main menu  \\n\\n    *   [Research Index](https://openai.com/research/index/)\\n    *   [Research Overview](https://openai.com/research/)\\n    *   [Research Residency](https://openai.com/residency/)\\n    *   [OpenAI for Science](https://openai.com/science/)\\n    *   Latest Advancements\\n    *   [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)\\n    *   [GPT-5.1](https://openai.com/index/gpt-5-1/)\\n    *   [Sora 2](https://openai.com/index/sora-2/)\\n    *   [GPT-5](https://openai.com/index/introducing-gpt-5/)\\n    *   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n    *   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)\\n\\n*   Safety\\n\\nBack to main menu  \\n\\n    *   [Safety Approach](https://openai.com/safety/)\\n    *   [Security & Privacy](https://openai.com/security-and-privacy/)\\n\\n*   [For Business](https://openai.com/business/)\\n\\nBack to main menu  \\n\\n    *   [Business Overview](https://openai.com/business/)\\n    *   [Solutions](https://openai.com/solutions/)\\n    *   [Learn](https://openai.com/business/learn/)\\n    *   [Startups](https://openai.com/startups/)\\n    *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Contact Sales](https://openai.com/contact-sales/)\\n\\n*   For Developers\\n\\nBack to main menu  \\n\\n    *   [API Platform](https://openai.com/api/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Agents](https://openai.com/agent-platform/)\\n    *   [Codex](https://openai.com/codex/)\\n    *   [Open Models](https://openai.com/open-models/)\\n    *   [Community(opens in a new window)](https://community.openai.com/)\\n\\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n\\nBack to main menu  \\n\\n    *   [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n    *   [Business](https://chatgpt.com/for-business/team?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n    *   [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n    *   [Education](https://chatgpt.com/for-business/education?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n    *   [Pricing](https://chatgpt.com/pricing?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n    *   [Download](https://chatgpt.com/download?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n\\n*   [Sora](https://openai.com/sora/)\\n*   [Stories](https://openai.com/stories/)\\n*   Company\\n\\nBack to main menu  \\n\\n    *   [About Us](https://openai.com/about/)\\n    *   [Our Charter](https://openai.com/charter/)\\n    *   [Foundation](https://openai.com/foundation/)\\n    *   [Careers](https://openai.com/careers/)\\n    *   [Brand Guidelines](https://openai.com/brand/)\\n\\n*   [News](https://openai.com/news/company-announcements/)\\n\\nLog in\\n\\nOpenAI Newsroom | Product | OpenAI\\n\\nProduct\\n-------\\n\\n*   [Company](https://openai.com/news/company-announcements/)\\n*   [Research](https://openai.com/news/research/)\\n*   [Product](https://openai.com/news/product-releases/)\\n*   [Safety](https://openai.com/news/safety-alignment/)\\n*   [Engineering](https://openai.com/news/engineering/)\\n*   [Security](https://openai.com/news/security/)\\n*   [Global Affairs](https://openai.com/news/global-affairs/)\\n*   [All](https://openai.com/news/)\\n\\nFilter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\n![Image 1: OAI Go Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/6VqoFRZtqjJVLA9k1zrVkl/7064d5a2ff89f48f03737b88ecc42f32/OAI_Go_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Go, now available worldwide Product Jan 16, 2026](https://openai.com/index/introducing-chatgpt-go/)\\n\\n![Image 2: OAI Ads Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/41z4Qn4f0i948wZMLWB9lH/f3961891b0e0274306ea19fe368c95d7/OAI_Ads_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Our approach to advertising and expanding access to ChatGPT Company Jan 16, 2026](https://openai.com/index/our-approach-to-advertising-and-expanding-access/)\\n\\n![Image 3: OpenAI for Healthcare > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/4oQtNGNaY29dDxIKJBVphg/18314fd6a66f31249a5f95ec238272de/OAI_forHealth_ArtCard_1-1_C.png?w=3840&q=90&fm=webp)\\n\\n[Introducing OpenAI for Healthcare Product Jan 8, 2026](https://openai.com/index/openai-for-healthcare/)\\n\\n![Image 4: OAI ChatGPT Health ArtCard](https://images.ctfassets.net/kftzwdyauwt9/3hnWarC0m5jJPEoEU3HZGw/59c55e915ebc3dcf4d49efab8e166a19/OAI_ChatGPT_Health_ArtCard.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Health Product Jan 7, 2026](https://openai.com/index/introducing-chatgpt-health/)\\n\\n![Image 5: GPT-5.2-Codex blog 1x1](https://images.ctfassets.net/kftzwdyauwt9/7MS110rihMT7s5O8mXuCpT/5c376f0c3ab7850a11cd1756c242d3fa/OAI_GPT-5.2-Codex_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing GPT-5.2-Codex Product Dec 18, 2025](https://openai.com/index/introducing-gpt-5-2-codex/)\\n\\n![Image 6: AppsEcosystem-SEO-ArtCard-1x1](https://images.ctfassets.net/kftzwdyauwt9/7MOcpj3xffkBaaLfDbL2pv/f5b01f66adce6dd2bb08c95d696d4347/AppsEcosystem-SEO-ArtCard-1x1.png?w=3840&q=90&fm=webp)\\n\\n[Developers can now submit apps to ChatGPT Product Dec 17, 2025](https://openai.com/index/developers-can-now-submit-apps-to-chatgpt/)\\n\\n![Image 7: Image Gen Blog Art Card 1x1](https://images.ctfassets.net/kftzwdyauwt9/3ITYCyFN8IYXpM19fump1e/435c595475f13fe38258e394cd7e0330/Image_Gen_Blog_Art_Card_1x1.png?w=3840&q=90&fm=webp)\\n\\n[The new ChatGPT Images is here Product Dec 16, 2025](https://openai.com/index/new-chatgpt-images-is-here/)\\n\\n![Image 8: 5.2 math and science > Cover image](https://images.ctfassets.net/kftzwdyauwt9/6181tZAk7ZeAC4bU0QsSDL/ce50a1b724dc999d7e066f5bb423d517/GPT-5.2_MathScience_1x1__1_.png?w=3840&q=90&fm=webp)\\n\\n[Advancing science and math with GPT-5.2 Publication Dec 11, 2025](https://openai.com/index/gpt-5-2-for-science-and-math/)\\n\\n![Image 9: 5.2-Blog-1x1](https://images.ctfassets.net/kftzwdyauwt9/1Tc0kBv3H0HRXf7SsizFfA/1a8b076fa71453ac7e822e30756fc066/5.2-Blog-1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing GPT-5.2 Product Dec 11, 2025](https://openai.com/index/introducing-gpt-5-2/)\\n\\nLoad more\\n\\nOur Research\\n*   [Research Index](https://openai.com/research/index/)\\n*   [Research Overview](https://openai.com/research/)\\n*   [Research Residency](https://openai.com/residency/)\\n*   [OpenAI for Science](https://openai.com/science/)\\n\\nLatest Advancements\\n*   [GPT-5](https://openai.com/gpt-5/)\\n*   [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\\n*   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)\\n*   [Sora](https://openai.com/index/sora-system-card/)\\n\\nSafety\\n*   [Safety Approach](https://openai.com/safety/)\\n*   [Security & Privacy](https://openai.com/security-and-privacy/)\\n*   [Trust & Transparency](https://openai.com/trust-and-transparency/)\\n\\nChatGPT\\n*   [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n*   [Business](https://chatgpt.com/business/business-plan?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n*   [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n*   [Education](https://chatgpt.com/business/education?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n*   [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n*   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=5c1a4893-4883-4614-a17d-fbeaf689fe20&openaicom_referred=true)\\n\\nSora\\n*   [Sora Overview](https://openai.com/sora/)\\n*   [Features](https://openai.com/sora/#features)\\n*   [Pricing](https://openai.com/sora/#pricing)\\n*   [Sora log in(opens in a new window)](https://sora.com/)\\n\\nAPI Platform\\n*   [Platform Overview](https://openai.com/api/)\\n*   [Pricing](https://openai.com/api/pricing/)\\n*   [API log in(opens in a new window)](https://platform.openai.com/login)\\n*   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)\\n*   [Developer Forum(opens in a new window)](https://community.openai.com/)\\n\\nFor Business\\n*   [Business Overview](https://openai.com/business/)\\n*   [Solutions](https://openai.com/solutions/)\\n*   [Contact Sales](https://openai.com/contact-sales/)\\n\\nCompany\\n*   [About Us](https://openai.com/about/)\\n*   [Our Charter](https://openai.com/charter/)\\n*   [Foundation](https://openai.com/foundation/)\\n*   [Careers](https://openai.com/careers/)\\n*   [Brand](https://openai.com/brand/)\\n\\nSupport\\n*   [Help Center(opens in a new window)](https://help.openai.com/)\\n\\nMore\\n*   [News](https://openai.com/news/)\\n*   [Stories](https://openai.com/stories/)\\n*   [Livestreams](https://openai.com/live/)\\n*   [Podcast](https://openai.com/podcast/)\\n*   [RSS](https://openai.com/news/rss.xml)\\n\\nTerms & Policies\\n*   [Terms of Use](https://openai.com/policies/terms-of-use/)\\n*   [Privacy Policy](https://openai.com/policies/privacy-policy/)\\n*   [Other Policies](https://openai.com/policies/)\\n\\n[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)\\n\\nOpenAI © 2015–2026 Manage Cookies\\n\\nEnglish United States\"}, {\"url\": \"https://openai.com/research/index/release/\", \"title\": \"OpenAI Research | Release\", \"content\": \"Filter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\nProduct\\n\\nDec 18, 2025\\n\\nIntroducing GPT-5.2-Codex The most advanced agentic coding model for professional software engineering and defensive cybersecurity.\\n\\nProduct\\n\\nDec 16, 2025\\n\\nThe new ChatGPT Images is here The new ChatGPT Images is powered by our flagship image generation model, delivering more precise edits, consistent details, and image generation up to 4× faster. The upgraded model is rolling out to all ChatGPT users today and is also available in the API as GPT-Image-1.5.\\n\\nProduct\\n\\nDec 11, 2025\\n\\nIntroducing GPT-5.2 The most advanced frontier model for professional work and long-running agents.\\n\\nProduct\\n\\nNov 19, 2025 [...] Product\\n\\nNov 19, 2025\\n\\nBuilding more with GPT-5.1-Codex-Max Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.\\n\\nProduct\\n\\nNov 12, 2025\\n\\nGPT-5.1: A smarter, more conversational ChatGPT We’re upgrading GPT-5 while making it easier to customize ChatGPT. Starting to roll out today to everyone, beginning with paid users.\\n\\nResearch\\n\\nNov 3, 2025\\n\\nIntroducing IndQA A new benchmark for evaluating AI systems on Indian culture and languages.\\n\\nSecurity\\n\\nOct 30, 2025\\n\\nIntroducing Aardvark: OpenAI’s agentic security researcher Now in private beta: an AI agent that thinks like a security researcher and scales to meet the demands of modern software.\\n\\nSafety [...] Safety\\n\\nOct 29, 2025\\n\\ngpt-oss-safeguard technical report Performance and baseline evaluations of gpt-oss-safeguard-120b and gpt-oss-safeguard-20b\\n\\nProduct\\n\\nOct 29, 2025\\n\\nIntroducing gpt-oss-safeguard New open safety reasoning models (120b and 20b) that support custom safety policies.\\n\\nLoad more\\n\\nOur Research\\n   Research Index\\n   Research Overview\\n   Research Residency\\n   OpenAI for Science\\n\\nLatest Advancements\\n   GPT-5\\n   OpenAI o3\\n   OpenAI o4-mini\\n   GPT-4o\\n   GPT-4o mini\\n   Sora\\n\\nSafety\\n   Safety Approach\\n   Security & Privacy\\n   Trust & Transparency\\n\\nChatGPT\\n   Explore ChatGPT(opens in a new window)\\n   Business\\n   Enterprise\\n   Education\\n   Pricing(opens in a new window)\\n   Download(opens in a new window)\", \"score\": 0.89302075, \"raw_content\": \"OpenAI Research | Release | OpenAI\\n===============\\n\\n[Skip to main content](https://openai.com/research/index/release/#main)\\n\\nLog in\\n\\n[](https://openai.com/)\\n\\nSwitch to\\n\\n*   [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n*   [Sora(opens in a new window)](https://sora.com/)\\n*   [API Platform(opens in a new window)](https://platform.openai.com/)\\n\\n[Home](https://openai.com/)\\n*   [Research Index](https://openai.com/research/index/) \\n*   [Research Overview](https://openai.com/research/) \\n*   [Research Residency](https://openai.com/residency/) \\n*   [OpenAI for Science](https://openai.com/science/) \\n\\nLatest Advancements\\n\\n*   [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/) \\n*   [GPT-5.1](https://openai.com/index/gpt-5-1/) \\n*   [Sora 2](https://openai.com/index/sora-2/) \\n*   [GPT-5](https://openai.com/index/introducing-gpt-5/) \\n*   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/) \\n*   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/) \\n\\n*   Research\\n\\nBack to main menu  \\n\\n    *   [Research Index](https://openai.com/research/index/)\\n    *   [Research Overview](https://openai.com/research/)\\n    *   [Research Residency](https://openai.com/residency/)\\n    *   [OpenAI for Science](https://openai.com/science/)\\n    *   Latest Advancements\\n    *   [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)\\n    *   [GPT-5.1](https://openai.com/index/gpt-5-1/)\\n    *   [Sora 2](https://openai.com/index/sora-2/)\\n    *   [GPT-5](https://openai.com/index/introducing-gpt-5/)\\n    *   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n    *   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)\\n\\n*   Safety\\n\\nBack to main menu  \\n\\n    *   [Safety Approach](https://openai.com/safety/)\\n    *   [Security & Privacy](https://openai.com/security-and-privacy/)\\n\\n*   [For Business](https://openai.com/business/)\\n\\nBack to main menu  \\n\\n    *   [Business Overview](https://openai.com/business/)\\n    *   [Solutions](https://openai.com/solutions/)\\n    *   [Learn](https://openai.com/business/learn/)\\n    *   [Startups](https://openai.com/startups/)\\n    *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Contact Sales](https://openai.com/contact-sales/)\\n\\n*   For Developers\\n\\nBack to main menu  \\n\\n    *   [API Platform](https://openai.com/api/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Agents](https://openai.com/agent-platform/)\\n    *   [Codex](https://openai.com/codex/)\\n    *   [Open Models](https://openai.com/open-models/)\\n    *   [Community(opens in a new window)](https://community.openai.com/)\\n\\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n\\nBack to main menu  \\n\\n    *   [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n    *   [Business](https://chatgpt.com/for-business/team?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n    *   [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n    *   [Education](https://chatgpt.com/for-business/education?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n    *   [Pricing](https://chatgpt.com/pricing?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n    *   [Download](https://chatgpt.com/download?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n\\n*   [Sora](https://openai.com/sora/)\\n*   [Stories](https://openai.com/stories/)\\n*   Company\\n\\nBack to main menu  \\n\\n    *   [About Us](https://openai.com/about/)\\n    *   [Our Charter](https://openai.com/charter/)\\n    *   [Foundation](https://openai.com/foundation/)\\n    *   [Careers](https://openai.com/careers/)\\n    *   [Brand Guidelines](https://openai.com/brand/)\\n\\n*   [News](https://openai.com/news/company-announcements/)\\n\\nLog in\\n\\nOpenAI Research | Release | OpenAI\\n\\nResearch\\n--------\\n\\n*   [All](https://openai.com/research/index/)\\n*   [Publication](https://openai.com/research/index/publication/)\\n*   [Conclusion](https://openai.com/research/index/conclusion/)\\n*   [Milestone](https://openai.com/research/index/milestone/)\\n*   [Release](https://openai.com/research/index/release/)\\n\\nFilter Sort\\n\\nSwitch cards to show Media\\n\\n \\n\\nSwitch cards to hide Media\\n\\n \\n\\nProduct\\n\\nDec 18, 2025\\n\\n[Introducing GPT-5.2-Codex The most advanced agentic coding model for professional software engineering and defensive cybersecurity.](https://openai.com/index/introducing-gpt-5-2-codex/)\\n\\nProduct\\n\\nDec 16, 2025\\n\\n[The new ChatGPT Images is here The new ChatGPT Images is powered by our flagship image generation model, delivering more precise edits, consistent details, and image generation up to 4× faster. The upgraded model is rolling out to all ChatGPT users today and is also available in the API as GPT-Image-1.5.](https://openai.com/index/new-chatgpt-images-is-here/)\\n\\nProduct\\n\\nDec 11, 2025\\n\\n[Introducing GPT-5.2 The most advanced frontier model for professional work and long-running agents.](https://openai.com/index/introducing-gpt-5-2/)\\n\\nProduct\\n\\nNov 19, 2025\\n\\n[Building more with GPT-5.1-Codex-Max Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.](https://openai.com/index/gpt-5-1-codex-max/)\\n\\nProduct\\n\\nNov 12, 2025\\n\\n[GPT-5.1: A smarter, more conversational ChatGPT We’re upgrading GPT-5 while making it easier to customize ChatGPT. Starting to roll out today to everyone, beginning with paid users.](https://openai.com/index/gpt-5-1/)\\n\\nResearch\\n\\nNov 3, 2025\\n\\n[Introducing IndQA A new benchmark for evaluating AI systems on Indian culture and languages.](https://openai.com/index/introducing-indqa/)\\n\\nSecurity\\n\\nOct 30, 2025\\n\\n[Introducing Aardvark: OpenAI’s agentic security researcher Now in private beta: an AI agent that thinks like a security researcher and scales to meet the demands of modern software.](https://openai.com/index/introducing-aardvark/)\\n\\nSafety\\n\\nOct 29, 2025\\n\\n[gpt-oss-safeguard technical report Performance and baseline evaluations of gpt-oss-safeguard-120b and gpt-oss-safeguard-20b](https://openai.com/index/gpt-oss-safeguard-technical-report/)\\n\\nProduct\\n\\nOct 29, 2025\\n\\n[Introducing gpt-oss-safeguard New open safety reasoning models (120b and 20b) that support custom safety policies.](https://openai.com/index/introducing-gpt-oss-safeguard/)\\n\\nLoad more\\n\\nOur Research\\n*   [Research Index](https://openai.com/research/index/)\\n*   [Research Overview](https://openai.com/research/)\\n*   [Research Residency](https://openai.com/residency/)\\n*   [OpenAI for Science](https://openai.com/science/)\\n\\nLatest Advancements\\n*   [GPT-5](https://openai.com/gpt-5/)\\n*   [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\\n*   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)\\n*   [Sora](https://openai.com/index/sora-system-card/)\\n\\nSafety\\n*   [Safety Approach](https://openai.com/safety/)\\n*   [Security & Privacy](https://openai.com/security-and-privacy/)\\n*   [Trust & Transparency](https://openai.com/trust-and-transparency/)\\n\\nChatGPT\\n*   [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n*   [Business](https://chatgpt.com/business/business-plan?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n*   [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n*   [Education](https://chatgpt.com/business/education?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n*   [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n*   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=7b7b00d8-c417-4f9c-82a0-2e643fef02c9&openaicom_referred=true)\\n\\nSora\\n*   [Sora Overview](https://openai.com/sora/)\\n*   [Features](https://openai.com/sora/#features)\\n*   [Pricing](https://openai.com/sora/#pricing)\\n*   [Sora log in(opens in a new window)](https://sora.com/)\\n\\nAPI Platform\\n*   [Platform Overview](https://openai.com/api/)\\n*   [Pricing](https://openai.com/api/pricing/)\\n*   [API log in(opens in a new window)](https://platform.openai.com/login)\\n*   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)\\n*   [Developer Forum(opens in a new window)](https://community.openai.com/)\\n\\nFor Business\\n*   [Business Overview](https://openai.com/business/)\\n*   [Solutions](https://openai.com/solutions/)\\n*   [Contact Sales](https://openai.com/contact-sales/)\\n\\nCompany\\n*   [About Us](https://openai.com/about/)\\n*   [Our Charter](https://openai.com/charter/)\\n*   [Foundation](https://openai.com/foundation/)\\n*   [Careers](https://openai.com/careers/)\\n*   [Brand](https://openai.com/brand/)\\n\\nSupport\\n*   [Help Center(opens in a new window)](https://help.openai.com/)\\n\\nMore\\n*   [News](https://openai.com/news/)\\n*   [Stories](https://openai.com/stories/)\\n*   [Livestreams](https://openai.com/live/)\\n*   [Podcast](https://openai.com/podcast/)\\n*   [RSS](https://openai.com/news/rss.xml)\\n\\nTerms & Policies\\n*   [Terms of Use](https://openai.com/policies/terms-of-use/)\\n*   [Privacy Policy](https://openai.com/policies/privacy-policy/)\\n*   [Other Policies](https://openai.com/policies/)\\n\\n[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)\\n\\nOpenAI © 2015–2026 Manage Cookies\\n\\nEnglish United States\"}, {\"url\": \"https://m.economictimes.com/us/science-tech/openai-plans-late-2026-launch-of-first-ai-hardware-device-designed-with-jony-ive-will-it-survive-where-others-struggled/articleshow/126769816.cms\", \"title\": \"OpenAI plans late-2026 launch of first AI hardware device, designed ...\", \"content\": \"OpenAI is officially planning to unveil its first consumer hardware device in the second half of 2026, marking a major strategic expansion from its core software offerings like ChatGPT into the AI hardware market. The announcement came from OpenAI Chief Global Affairs Officer Chris Lehane speaking at Axios House Davos 2026, where he confirmed that the company’s long-rumored hardware project, designed in collaboration with former Apple design chief Jony Ive, is progressing and targeted for a late-2026 reveal.  \\n  \\nOpenAI’s hardware initiative reflects a broader push to create dedicated AI-powered devices that offer more seamless human-AI interaction beyond smartphones, tablets, and PCs. [...] Timeline: OpenAI is targeting a second half of 2026 announcement or reveal, with exact launch dates yet to be confirmed.\\n Design Vision: The product is anticipated to be small, innovative, and potentially unconventional relative to traditional hardware categories. Some speculation based on leaked prototypes hints at a screen-less companion device that interacts with users via voice rather than a traditional display.\\n Team and Talent: The development effort has been bolstered by the hiring of former Apple engineers experienced in hardware design and user interface technologies, underscoring the depth of design expertise behind the project. [...] SECTIONS\\n\\nOpenAI plans late-2026 launch of first AI hardware device, designed with Jony Ive: Will it survive where others struggled\\n\\nBy\\n\\nMaitreyee Thakkar\\n\\n, Global Desk\\n\\nRate Story\\n\\nFollow us\\n\\nShare\\n\\nFont Size\\n\\nAbcSmall\\n\\nAbcMedium\\n\\nAbcLarge\\n\\nSave\\n\\nPrint\\n\\nComment\\n\\nSynopsis\\n\\nOpenAI is set to launch its first consumer hardware device in late 2026, a significant move into AI hardware. Collaborating with former Apple design chief Jony Ive, the company aims for a seamless human-AI interaction beyond current devices. Details remain scarce, but it's expected to be a small, innovative, possibly screen-less companion device, leveraging deep AI and design expertise.\", \"score\": 0.8687491, \"raw_content\": \"[Nifty](https://economictimes.indiatimes.com/markets/indices/nifty-50)25,418.20-167.3\\n\\n[FEATURED FUNDS\\n\\nMotilal Oswal Midcap Fund Direct-Growth\\n\\n5Y Return\\n\\n27.87 %\\n\\nInvest Now](https://www.motilaloswalmf.com/mutual-funds/motilal-oswal-midcap-fund?utm_campaign=midcap&utm_source=et&utm_medium=invest_now_cta&utm_creative=cpc&utm_device=paid)[FEATURED FUNDS\\n\\n★★★★★\\n\\nHSBC Large Cap Fund Direct-Growth\\n\\n5Y Return\\n\\n13.93 %\\n\\nInvest Now](https://www.assetmanagement.hsbc.co.in/en/mutual-funds/investment-expertise/equity-funds/hsbc-large-cap-fund?cid=HBIN:ANILP:123:D1:AMG:L6:GO)\\n\\n[US](https://economictimes.indiatimes.com/us \\\"US\\\")\\n\\nEnglish EditionEnglish Edition[हिन्दी](https://hindi.economictimes.com/)[ગુજરાતી](https://gujarati.economictimes.com/)[मराठी](https://marathi.economictimes.com/)[বাংলা](https://bengali.economictimes.com/)[ಕನ್ನಡ](https://kannada.economictimes.com/)[മലയാളം](https://malayalam.economictimes.com/)[தமிழ்](https://tamil.economictimes.com/)[తెలుగు](https://telugu.economictimes.com/)\\n\\n | [Today's ePaper](https://epaper.indiatimes.com/timesepaper/publication-the-economic-times,city-delhi.cms)\\n\\n[My Watchlist](https://economictimes.indiatimes.com/watchlist?source=homepage&medium=header&campaign=watchlist) [Subscribe](javascript:cdpGoToPlan())\\n\\n[Sign In](javascript:objUser.login())\\n\\n[Business News](https://economictimes.indiatimes.com \\\"The Economic Times\\\")›[US](https://economictimes.indiatimes.com/us \\\"US\\\")›[Science & Technology](https://economictimes.indiatimes.com/us/science-tech \\\"Science & Technology\\\")›OpenAI plans late-2026 launch of first AI hardware device, designed with Jony Ive: Will it survive where others struggled\\n\\n##### The Economic Times daily newspaper is available online now.\\n\\n[Read Today's Paper](/print_edition.cms)\\n\\n# OpenAI plans late-2026 launch of first AI hardware device, designed with Jony Ive: Will it survive where others struggled\\n\\nSECTIONS\\n\\nOpenAI plans late-2026 launch of first AI hardware device, designed with Jony Ive: Will it survive where others struggled\\n\\nBy\\n\\nMaitreyee Thakkar\\n\\n, Global Desk\\n\\nRate Story\\n\\n[Follow us](https://whatsapp.com/channel/0029Vb6dOI1EKyZPPqpH7I0y)\\n\\nShare\\n\\nFont Size\\n\\nAbcSmall\\n\\nAbcMedium\\n\\nAbcLarge\\n\\nSave\\n\\n[Print](/us/science-tech/openai-plans-late-2026-launch-of-first-ai-hardware-device-designed-with-jony-ive-will-it-survive-where-others-struggled/printarticle/126769816.cms)\\n\\nComment\\n\\nSynopsis\\n\\nOpenAI is set to launch its first consumer hardware device in late 2026, a significant move into AI hardware. Collaborating with former Apple design chief Jony Ive, the company aims for a seamless human-AI interaction beyond current devices. Details remain scarce, but it's expected to be a small, innovative, possibly screen-less companion device, leveraging deep AI and design expertise.\\n\\n[OpenAI](/topic/openai) is officially planning to unveil its first consumer hardware device in the second half of 2026, marking a major strategic expansion from its core software offerings like [ChatGPT](/topic/chatgpt) into the AI hardware market. The announcement came from OpenAI Chief Global Affairs Officer [Chris Lehane](/topic/chris-lehane) speaking at Axios House Davos 2026, where he confirmed that the company’s long-rumored hardware project, designed in collaboration with former [Apple](/topic/apple) design chief [Jony Ive](/topic/jony-ive), is progressing and targeted for a late-2026 reveal.  \\n  \\nOpenAI’s hardware initiative reflects a broader push to create dedicated AI-powered devices that offer more seamless human-AI interaction beyond smartphones, tablets, and [PCs](/pcs-technology-ltd/stocks/companyid-13318.cms).   \\n  \\nWhile details about the product itself remain largely under wraps, observers note the significance of combining OpenAI’s cutting-edge AI technologies with Ive’s expertise in industrial design, which previously shaped iconic Apple products.\\n  \\n  \\nThe partnership stems from OpenAI’s 2025 acquisition of Jony Ive’s AI hardware startup io Products, a move that integrated Ive’s team and design vision into OpenAI’s broader hardware ambitions.   \\n  \\nIve’s design philosophy emphasizes simplicity, intuitive user experiences, and elegant form factors, traits that both he and OpenAI CEO [Sam Altman](/topic/sam-altman) have described as central to the product’s development.  \\n\\n### Live Events\\n\\n## What we know about the device\\n\\nAt this stage, OpenAI and its partners have not publicly disclosed the official name, design, form factor, or functionality of the forthcoming AI device. However, multiple reports and industry-level insights suggest several defining characteristics:  \\n  \\n\\n* Timeline: OpenAI is targeting a second half of 2026 announcement or reveal, with exact launch dates yet to be confirmed.\\n* Design Vision: The product is anticipated to be small, innovative, and potentially unconventional relative to traditional hardware categories. Some speculation based on leaked prototypes hints at a screen-less companion device that interacts with users via voice rather than a traditional display.\\n* Team and Talent: The development effort has been bolstered by the hiring of former Apple engineers experienced in hardware design and user interface technologies, underscoring the depth of design expertise behind the project.\\n\\nHistorically, similar efforts by other companies have faced obstacles. For example, [Humane’s AI Pin](/topic/humane%E2%80%99s-ai-pin), a clip-on wearable AI companion, struggled commercially after its 2024 launch, illustrating the difficulty of driving adoption for new classes of devices.   \\n  \\nOpenAI’s project, backed by Ive’s design pedigree and deep AI expertise, may be better positioned but still must contend with technical refinement, market education, and consumer expectations ahead of its 2026 debut.  \\n  \\n  \\n  \\n\\nAdd as a Reliable and Trusted News Source\\n\\n[Add Now!](https://www.google.com/preferences/source?q=economictimes)\\n\\nRead More News on\\n\\n[OpenAI AI hardware device](/topic/openai-ai-hardware-device)[OpenAI](/topic/openai)[sam altman](/topic/sam-altman)[ChatGPT](/topic/chatgpt)[Chris Lehane](/topic/chris-lehane)[Jony Ive](/topic/jony-ive)[humane’s ai pin](/topic/humane%E2%80%99s-ai-pin)[AI device announcement](/topic/ai-device-announcement)[Apple](/topic/apple)[pcs](/pcs/stocks/companyid-13318.cms)\\n\\nRead More News on\\n\\n[OpenAI AI hardware device](/topic/openai-ai-hardware-device)[OpenAI](/topic/openai)[sam altman](/topic/sam-altman)[ChatGPT](/topic/chatgpt)[Chris Lehane](/topic/chris-lehane)[Jony Ive](/topic/jony-ive)[humane’s ai pin](/topic/humane%E2%80%99s-ai-pin)[AI device announcement](/topic/ai-device-announcement)[Apple](/topic/apple)[pcs](/pcs/stocks/companyid-13318.cms)\\n\\nPrime Exclusives[Investment Ideas](/prime/investment-ideas?source=homepage&medium=investment_ideas&campaign=prime_discovery)[Stock Report Plus](/markets/benefits/stockreportsplus?source=freearticleshow&medium=sr_plus&campaign=prime_discovery)[ePaper](https://epaper.indiatimes.com/timesepaper/publication-the-economic-times,city-delhi.cms?source=freearticleshow&medium=epaper_pdf&campaign=prime_discovery)[Wealth Edition](https://epaper.indiatimes.com/wealth_edition.cms?source=freearticleshow&medium=wealth_edition&campaign=prime_discovery)\\n\\n* [Why IndiGo got away with peanuts penalty after causing misery](https://economictimes.indiatimes.com/prime/transportation/inr22-cr-fine-on-inr80k-cr-revenue-airline-what-indigos-record-penalty-really-means/primearticleshow/126678082.cms \\\"title | stname\\\")\\n* [Can this IPO-bound company step out of Flipkart’s shadow?](https://economictimes.indiatimes.com/prime/economy-and-policy/after-delhivery-can-shadowfax-crack-the-logistics-ipo-code/primearticleshow/126674977.cms \\\"title | stname\\\")\\n* [For a future, Hindustan Copper is reviving what it junked in past](https://economictimes.indiatimes.com/prime/economy-and-policy/hindustan-coppers-turnaround-from-persistent-losses-to-a-bid-for-structural-revival/primearticleshow/126544618.cms \\\"title | stname\\\")\\n* [RBI is easing, but India’s long-term rates tell a different story](https://economictimes.indiatimes.com/prime/economy-and-policy/rbi-is-easing-but-indias-long-term-rates-tell-a-different-story/primearticleshow/126525439.cms \\\"title | stname\\\")\\n* [Stock Radar: SBI hits fresh record high in January 2026; time to buy or book profits?](https://economictimes.indiatimes.com/markets/stocks/news/stock-radar-sbi-hits-fresh-record-high-in-january-2026-time-to-buy-or-book-profits/articleshow/126674769.cms \\\"title | stname\\\")\\n* [Stock picks of the week: 5 stocks with consistent score improvement and upside potential up to 35%](https://economictimes.indiatimes.com/markets/stocks/news/stock-picks-of-the-week-5-stocks-with-consistent-score-improvement-and-upside-potential-up-to-35/articleshow/126672024.cms \\\"title | stname\\\")\\n\\n* 1\\n* 2\\n* 3\\n\\n[View all Stories](/prime)\\n\\nStories you might be interested in\\n\\nSubscribe to ourET Investment Opportunities\"}, {\"url\": \"https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026\", \"title\": \"OpenAI looks set to unveil first physical device in H2 2026\", \"content\": \"Speaking at Axios House on the fringes of Davos yesterday, OpenAI chief global affairs officer Chris Lehane gave the strongest indication yet that 2026 will be the year we see the long-mooted consumer hardware from the ChatGPT creator. He said OpenAI was on track to unveil its first such device in the second half of this year.\\n\\nSpeculation has been rife in recent months, with many pointing to an AI pen of sorts being the likely first release in a suite of consumer devices, but last week a leak on X from closely followed electronics blogger Weibo suggested the first device might be a wearable – a variation on earbuds that sit behind the ear and are powered by AI. He even cited a code name for the buds – Sweetpea. [...] It certainly fits with longstanding reports that OpenAI’s Sam Altman has headphones on his radar when acquiring Io back in May 2025, the AI start-up founded by former Apple design chief Jony Ive and other former Apple engineers Scott Cannon, Evans Hankey and Tang Tan. At Apple, Ive famously led the design of iconic products like the iMac, iPod, iPhone, iPad and Apple Watch.\\n\\nIve and his design firm LoveFrom began quietly collaborating with OpenAI a few years ago, ablogposton the company’s website read. Ive and his former colleagues subsequently set up Io – a hardware company – with the aim of building a new family of devices and projects for OpenAI. [...] Altman has previously shown interest in AI consumer devices. He invested in Humane, a start-up that failed to catch on with its less than functional AI pin.\\n\\nWhile Ives did not join OpenAI, he and his LoveFrom team were said to be working “intimately” with the OpenAI’s research, engineering and product teams. Dozens of Io engineers, software developers and experts, including other Io co-founders, did join OpenAI as part of the acquisition.\\n\\nReports at the time of the acquisition said Altman and LoveFrom previously considered headphones and other devices with cameras, and products would appear in 2026. Could Sweetpea be the sweet spot for OpenAI’s first hardware endeavour this year?\\n\\n_Sam Altman in 2022. Image: Village Global/Flickr (CC BY 2.0)_\", \"score\": 0.8619225, \"raw_content\": \"OpenAI looks set to unveil first physical device in H2 2026\\n===============\\n\\n*   [Home](https://www.siliconrepublic.com/)\\n*   [Technology](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026#)\\n    *   [Business](https://www.siliconrepublic.com/business/)\\n    *   [Enterprise](https://www.siliconrepublic.com/enterprise/)\\n    *   [Comms](https://www.siliconrepublic.com/comms/)\\n    *   [Start-ups](https://www.siliconrepublic.com/start-ups/)\\n    *   [All](https://www.siliconrepublic.com/technology/)\\n\\n*   [Science](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026#)\\n    *   [Innovation](https://www.siliconrepublic.com/innovation/)\\n    *   [Machines](https://www.siliconrepublic.com/machines/)\\n    *   [Climate](https://www.siliconrepublic.com/climate/)\\n    *   [All](https://www.siliconrepublic.com/science/)\\n\\n*   [Careers](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026#)\\n    *   [Advice](https://www.siliconrepublic.com/advice/)\\n    *   [People](https://www.siliconrepublic.com/people/)\\n    *   [Employers](https://www.siliconrepublic.com/employers/)\\n    *   [Jobs News](https://www.siliconrepublic.com/jobs-news/)\\n    *   [All](https://www.siliconrepublic.com/careers/)\\n\\n*   [AI](https://www.siliconrepublic.com/ai/)\\n*   [More](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026#)\\n    *   [AI Policy](https://www.siliconrepublic.com/ai-usage-policy/)\\n    *   [Advertise](https://www.siliconrepublic.com/advertise/)\\n    *   [Follow Us](https://www.siliconrepublic.com/follow-us/)\\n    *   [Contact us](https://www.siliconrepublic.com/contact/)\\n    *   [About](https://www.siliconrepublic.com/about/)\\n    *   [Cookie & Privacy Policy](https://www.siliconrepublic.com/privacy/)\\n\\n[![Image 1: Silicon Republic](https://www.siliconrepublic.com/wp-content/themes/silicon/img/logoblack.png)](https://www.siliconrepublic.com/)\\n\\nLogin\\n\\n[](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026#)\\n\\n*   [TECHNOLOGY](https://www.siliconrepublic.com/technology/)[BUSINESS](https://www.siliconrepublic.com/business/)[ENTERPRISE](https://www.siliconrepublic.com/enterprise/)[COMMS](https://www.siliconrepublic.com/comms/)[START-UPS](https://www.siliconrepublic.com/start-ups/)[ALL](https://www.siliconrepublic.com/technology/)   \\n*   [SCIENCE](https://www.siliconrepublic.com/science/)[INNOVATION](https://www.siliconrepublic.com/innovation/)[MACHINES](https://www.siliconrepublic.com/machines/)[CLIMATE](https://www.siliconrepublic.com/climate/)[ALL](https://www.siliconrepublic.com/science/)   \\n*   [CAREERS](https://www.siliconrepublic.com/careers/)[ADVICE](https://www.siliconrepublic.com/advice/)[PEOPLE](https://www.siliconrepublic.com/people/)[EMPLOYERS](https://www.siliconrepublic.com/employers/)[JOBS NEWS](https://www.siliconrepublic.com/jobs-news/)[ALL](https://www.siliconrepublic.com/careers/)   \\n*   [AI](https://www.siliconrepublic.com/ai/)   \\n*   [MORE](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026#)[AI POLICY](https://www.siliconrepublic.com/ai-usage-policy/)[ADVERTISE](https://www.siliconrepublic.com/advertise/)[FOLLOW US](https://www.siliconrepublic.com/follow-us/)[CONTACT](https://www.siliconrepublic.com/contact/)[ABOUT](https://www.siliconrepublic.com/about/)[COOKIE & PRIVACY POLICY](https://www.siliconrepublic.com/privacy/)   \\n\\nLogin Subscribe\\n\\n[](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026#)\\n\\n[INNOVATION](https://www.siliconrepublic.com/innovation/)[MACHINES](https://www.siliconrepublic.com/machines/)[CLIMATE](https://www.siliconrepublic.com/climate/)[ALL](https://www.siliconrepublic.com/science/)\\n\\n[MACHINES](https://www.siliconrepublic.com/machines/)\\n\\nOpenAI looks set to unveil first physical device in H2 2026\\n===========================================================\\n\\n[by Ann O’Dea](https://www.siliconrepublic.com/author/aodea/)\\n\\n20 Jan 2026\\n\\nSave article\\n\\n[](http://www.linkedin.com/shareArticle?mini=true&url=https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](https://bsky.app/intent/compose?text=OpenAI+looks+set+to+unveil+first+physical+device+in+H2+2026+https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](http://twitter.com/share?url=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&text=OpenAI+looks+set+to+unveil+first+physical+device+in+H2+2026&via=siliconrepublic)[](https://www.threads.net/intent/post?url=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&text=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026)[](mailto:?subject=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026&body=https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](whatsapp://send?text=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026%20-%20https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](https://t.me/share/url?url=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&text=OpenAI+looks+set+to+unveil+first+physical+device+in+H2+2026)[](https://www.facebook.com/dialog/share?app_id=287597001601476&display=popup&href=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&redirect_uri=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](http://reddit.com/submit?url=https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&title=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026)\\n\\n![Image 2: Headshot of OpenAI CEO Sam Altman wearing a grey jumper and seated in an outdoor space with yellow chairs on grass.](https://www.siliconrepublic.com/wp-content/uploads/2023/07/a-8-718x523.jpg)\\n\\nSam Altman in 2022. Image: Village Global/Flickr (CC BY 2.0)\\n\\nIt had been a question of when, rather than if, OpenAI launches physical devices since acquiring former Apple design guru Jony Ive’s start-up Io last year.\\n\\nSpeaking at Axios House on the fringes of Davos yesterday, OpenAI chief global affairs officer Chris Lehane gave the strongest indication yet that 2026 will be the year we see the long-mooted consumer hardware from the ChatGPT creator. He said [OpenAI was on track](https://www.axios.com/2026/01/19/openai-device-2026-lehane-jony-ive) to unveil its first such device in the second half of this year.\\n\\nSpeculation has been rife in recent months, with many pointing to an AI pen of sorts being the likely first release in a suite of consumer devices, but last week a leak on X from closely followed electronics blogger [Weibo](https://x.com/zhihuipikachu/status/2010745618734759946) suggested the first device might be a wearable – a variation on earbuds that sit behind the ear and are powered by AI. He even cited a code name for the buds – Sweetpea.\\n\\nIt certainly fits with longstanding reports that OpenAI’s Sam Altman has headphones on his radar when acquiring [Io back in May 2025](https://www.siliconrepublic.com/business/openai-io-sam-altman-jony-ive), the AI start-up founded by former Apple design chief Jony Ive and other former Apple engineers Scott Cannon, Evans Hankey and Tang Tan. At Apple, Ive famously led the design of iconic products like the iMac, iPod, iPhone, iPad and Apple Watch.\\n\\nIve and his design firm LoveFrom began quietly collaborating with OpenAI a few years ago, a[blogpost](https://openai.com/sam-and-jony/)on the company’s website read. Ive and his former colleagues subsequently set up Io – a hardware company – with the aim of building a new family of devices and projects for OpenAI.\\n\\nAltman has previously shown interest in AI consumer devices. He invested in Humane, a start-up that failed to catch on with its [less than functional AI pin](https://www.siliconrepublic.com/machines/humane-ai-pin-reviews-wearables).\\n\\nWhile Ives did not join OpenAI, he and his LoveFrom team were said to be working “intimately” with the OpenAI’s research, engineering and product teams. Dozens of Io engineers, software developers and experts, including other Io co-founders, did join OpenAI as part of the acquisition.\\n\\nReports at the time of the acquisition said Altman and LoveFrom previously considered headphones and other devices with cameras, and products would appear in 2026. Could Sweetpea be the sweet spot for OpenAI’s first hardware endeavour this year?\\n\\n_[Sam Altman in 2022](https://www.flickr.com/photos/188046830@N04/52530764101). Image: Village Global/Flickr ([CC BY 2.0](https://creativecommons.org/licenses/by/2.0/))_\\n\\n**_Don’t miss out on the knowledge you need to succeed. Sign up for the_**[**_Daily Brief_**](http://eepurl.com/hIdNrT)**_, Silicon Republic’s digest of need-to-know sci-tech news._**\\n\\n[](http://www.linkedin.com/shareArticle?mini=true&url=https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](https://bsky.app/intent/compose?text=OpenAI+looks+set+to+unveil+first+physical+device+in+H2+2026+https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](http://twitter.com/share?url=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&text=OpenAI+looks+set+to+unveil+first+physical+device+in+H2+2026&via=siliconrepublic)[](https://www.threads.net/intent/post?url=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&text=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026)[](mailto:?subject=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026&body=https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](whatsapp://send?text=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026%20-%20https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](https://t.me/share/url?url=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&text=OpenAI+looks+set+to+unveil+first+physical+device+in+H2+2026)[](https://www.facebook.com/dialog/share?app_id=287597001601476&display=popup&href=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&redirect_uri=https%3A%2F%2Fwww.siliconrepublic.com%2Fmachines%2Fopen-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)[](http://reddit.com/submit?url=https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026&title=OpenAI%20looks%20set%20to%20unveil%20first%20physical%20device%20in%20H2%202026)\\n\\nRelated: [Sam Altman](https://www.siliconrepublic.com/topics/sam-altman/), [iPhone](https://www.siliconrepublic.com/topics/iphone/), [Apple](https://www.siliconrepublic.com/topics/apple/), [OpenAI](https://www.siliconrepublic.com/topics/openai/)\\n\\n[![Image 3](https://img.resized.co/siliconrepublic/eyJkYXRhIjoie1widXJsXCI6XCJodHRwczpcXFwvXFxcL3d3dy5zaWxpY29ucmVwdWJsaWMuY29tXFxcL3dwLWNvbnRlbnRcXFwvdXBsb2Fkc1xcXC8yMDE1XFxcLzAyXFxcL2Fubi1vZGVhLmpwZ1wiLFwid2lkdGhcIjoxMDAsXCJoZWlnaHRcIjoxMDAsXCJkZWZhdWx0XCI6XCJodHRwczpcXFwvXFxcL3d3dy5zaWxpY29ucmVwdWJsaWMuY29tXFxcL3dwLWNvbnRlbnRcXFwvdXBsb2Fkc1xcXC8yMDE0XFxcLzEyXFxcLzIwMTMwMlxcXC9wdXp6bGUuanBnXCIsXCJvcHRpb25zXCI6e1wib3V0cHV0XCI6XCJhdmlmXCIsXCJxdWFsaXR5XCI6XCI2NVwifX0iLCJoYXNoIjoiMzliMDI3MzVhNDNhZWFmZDc2N2M0NjkxZmMzMGI1NTBkZjdmMzMwMiJ9/ann-odea.jpg)](https://www.siliconrepublic.com/author/aodea/)\\n\\nAnn O’Dea is the CEO, co-founder and editor-in-chief of Silicon Republic\\n\\n[editorial@siliconrepublic.com](mailto:editorial@siliconrepublic.com)\\n\\n*   [](https://twitter.com/annodeasr)\\n\\n### You May Also Like\\n\\n### You May Also Like\\n\\n[![Image 4: New ChatGPT version will let users generate sexual content](https://www.siliconrepublic.com/wp-content/uploads/2025/10/chatgpt-330x251.jpeg)](https://www.siliconrepublic.com/machines/openai-chatgpt-ai-adult-content-sam-altman-chatbot)\\n\\n[Machines](https://www.siliconrepublic.com/machines/)\\n\\n[### New ChatGPT version will let users generate sexual content](https://www.siliconrepublic.com/machines/openai-chatgpt-ai-adult-content-sam-altman-chatbot)\\n15 Oct 2025\\n\\n[![Image 5: OpenAI buys Mac AI interface builder Software Applications Incorporated](https://www.siliconrepublic.com/wp-content/uploads/2025/02/OpenAI-330x251.jpeg)](https://www.siliconrepublic.com/business/openai-software-applications-incorporated-sky-acquisition-mac-ai)\\n\\n[Business](https://www.siliconrepublic.com/business/)\\n\\n[### OpenAI buys Mac AI interface builder Software Applications Incorporated](https://www.siliconrepublic.com/business/openai-software-applications-incorporated-sky-acquisition-mac-ai)\\n24 Oct 2025\\n\\n[![Image 6: Reports: OpenAI hits $500bn valuation after share sale](https://www.siliconrepublic.com/wp-content/uploads/2025/05/AdobeStock_564087424_Editorial_Use_Only-330x251.jpeg)](https://www.siliconrepublic.com/business/openai-500bn-valuation-share-sale-softbank-ai-reports)\\n\\n[Business](https://www.siliconrepublic.com/business/)\\n\\n[### Reports: OpenAI hits $500bn valuation after share sale](https://www.siliconrepublic.com/business/openai-500bn-valuation-share-sale-softbank-ai-reports)\\n3 Oct 2025\\n\\n[![Image 7: Scrap Digital Markets Act, Apple tells EU](https://www.siliconrepublic.com/wp-content/uploads/2025/09/Apple-store-UK-330x251.jpeg)](https://www.siliconrepublic.com/business/apple-european-union-commission-digital-markets-act-legislation)\\n\\n[Business](https://www.siliconrepublic.com/business/)\\n\\n[### Scrap Digital Markets Act, Apple tells EU](https://www.siliconrepublic.com/business/apple-european-union-commission-digital-markets-act-legislation)\\n25 Sep 2025\\n\\n[![Image 8: OpenAI inks AI chips deal with Nvidia challenger Cerebras](https://www.siliconrepublic.com/wp-content/uploads/2023/11/AdobeStock_564087424_Editorial_Use_Only-330x251.jpeg)](https://www.siliconrepublic.com/business/openai-cerebras-ai-chip-nvidia-inference-10bn-funding)\\n\\n[Business](https://www.siliconrepublic.com/business/)\\n\\n[### OpenAI inks AI chips deal with Nvidia challenger Cerebras](https://www.siliconrepublic.com/business/openai-cerebras-ai-chip-nvidia-inference-10bn-funding)\\n15 Jan 2026\\n\\n[![Image 9: OpenAI buys health-tech Torch for $100m](https://www.siliconrepublic.com/wp-content/uploads/2026/01/openai-330x251.jpeg)](https://www.siliconrepublic.com/business/openai-torch-acquisition-100m-health-tech-healthcare-medicine-ai)\\n\\n[Business](https://www.siliconrepublic.com/business/)\\n\\n[### OpenAI buys health-tech Torch for $100m](https://www.siliconrepublic.com/business/openai-torch-acquisition-100m-health-tech-healthcare-medicine-ai)\\n13 Jan 2026\\n\\n* * *\\n\\nLatest News\\n-----------\\n\\n*   [![Image 10: OpenAI looks set to unveil first physical device in H2 2026](https://www.siliconrepublic.com/wp-content/uploads/2023/07/a-8-70x70.jpg)](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026) [OpenAI looks set to unveil first physical device in H2 2026 20 Jan 2026](https://www.siliconrepublic.com/machines/open-ai-looks-set-to-unveil-first-physical-device-in-h2-2026)  \\n*   [![Image 11: UK government considering social media ban for under-16s](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Social-Media-Ban-70x70.jpeg)](https://www.siliconrepublic.com/business/uk-government-social-media-ban-danger-online-safety-policy) [UK government considering social media ban for under-16s 20 Jan 2026](https://www.siliconrepublic.com/business/uk-government-social-media-ban-danger-online-safety-policy)  \\n*   [![Image 12: Three Ireland parent in talks to sell mobile operator to Liberty Global](https://www.siliconrepublic.com/wp-content/uploads/2026/01/threeukdisplay-70x70.jpg)](https://www.siliconrepublic.com/comms/three-ireland-ck-hutchison-mobile-operator-liberty-global-sale) [Three Ireland parent in talks to sell mobile operator to Liberty Global 20 Jan 2026](https://www.siliconrepublic.com/comms/three-ireland-ck-hutchison-mobile-operator-liberty-global-sale)  \\n*   [![Image 13: Irish entrepreneur launches ‘chief artificial officer’ for SMEs](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Troy_Armour_Juno_Patral-70x70.jpg)](https://www.siliconrepublic.com/machines/ai-cao-ireland-sme-patral-juno) [Irish entrepreneur launches ‘chief artificial officer’ for SMEs 20 Jan 2026](https://www.siliconrepublic.com/machines/ai-cao-ireland-sme-patral-juno)  \\n*    Follow Us [](https://www.linkedin.com/company/siliconrepublic-com/posts)[](https://bsky.app/profile/siliconrepublic.bsky.social)[](https://www.facebook.com/siliconrepublic)[](https://www.youtube.com/@siliconrepublic)[](https://www.threads.net/@siliconrepublic)   \\n*   [![Image 14: Ireland’s employment market ‘stable’, as employers narrow focus](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Trayc-Keevans-Global-FDI-Director-Morgan-McKinley-Ireland-70x70.jpg)](https://www.siliconrepublic.com/careers/ireland-employment-market-stable-employers-narrow-focus-report) [Ireland’s employment market ‘stable’, as employers narrow focus 19 Jan 2026](https://www.siliconrepublic.com/careers/ireland-employment-market-stable-employers-narrow-focus-report)  \\n*   [![Image 15: Belfast sports-tech TeamFeePay bags £9m, plans 75 jobs](https://www.siliconrepublic.com/wp-content/uploads/2026/01/teamfeepay_funding_1016-70x70.jpg)](https://www.siliconrepublic.com/jobs-news/belfast-sports-tech-teamfeepay-bags-9m-plans-75-jobs) [Belfast sports-tech TeamFeePay bags £9m, plans 75 jobs 19 Jan 2026](https://www.siliconrepublic.com/jobs-news/belfast-sports-tech-teamfeepay-bags-9m-plans-75-jobs)  \\n*   [![Image 16: Is workplace AI moving into a managerial position?](https://www.siliconrepublic.com/wp-content/uploads/2026/01/AI-manager-image-70x70.jpeg)](https://www.siliconrepublic.com/careers/ai-moving-managerial-position-skills-working-life-artificial-intelligence) [Is workplace AI moving into a managerial position? 19 Jan 2026](https://www.siliconrepublic.com/careers/ai-moving-managerial-position-skills-working-life-artificial-intelligence)  \\n*   [![Image 17: Revolut, Google to enable shopping directly via AI chatbots in Europe](https://www.siliconrepublic.com/wp-content/uploads/2026/01/phone_atm_card-70x70.jpeg)](https://www.siliconrepublic.com/machines/revolut-agentic-ai-commerce-google-ap2) [Revolut, Google to enable shopping directly via AI chatbots in Europe 19 Jan 2026](https://www.siliconrepublic.com/machines/revolut-agentic-ai-commerce-google-ap2)  \\n*   [![Image 18: €41m to be invested in Ireland’s higher education institutions](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Education-funding-70x70.jpeg)](https://www.siliconrepublic.com/innovation/41m-invested-irelands-higher-education-institutions-funding-upgrades) [€41m to be invested in Ireland’s higher education institutions 19 Jan 2026](https://www.siliconrepublic.com/innovation/41m-invested-irelands-higher-education-institutions-funding-upgrades)  \\n*   [![Image 19: Sequoia Capital planning ‘big investment’ in Anthropic – FT](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Sequoia-on-smart-screen-2026-70x70.jpeg)](https://www.siliconrepublic.com/business/sequoia-capital-planning-big-investment-in-anthropic-ft) [Sequoia Capital planning ‘big investment’ in Anthropic – FT 19 Jan 2026](https://www.siliconrepublic.com/business/sequoia-capital-planning-big-investment-in-anthropic-ft)  \\n*     \\n*   [![Image 20: Dublin’s PRM Assist bags €500,000 to improve airport accessibility](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Conor-Halpin-70x70.jpg)](https://www.siliconrepublic.com/start-ups/prm-assist-e500000-funding-dublin-enterprise-ireland-airport-accessibility) [Dublin’s PRM Assist bags €500,000 to improve airport accessibility 19 Jan 2026](https://www.siliconrepublic.com/start-ups/prm-assist-e500000-funding-dublin-enterprise-ireland-airport-accessibility)  \\n*   [![Image 21: ‘My curiosity always pulled me toward a more global horizon’](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Deepali-Futane-Image-70x70.png)](https://www.siliconrepublic.com/people/curiosity-pulled-toward-global-horizon-rent-the-runway-skills) [‘My curiosity always pulled me toward a more global horizon’ 16 Jan 2026](https://www.siliconrepublic.com/people/curiosity-pulled-toward-global-horizon-rent-the-runway-skills)  \\n*   [![Image 22: ‘There’s a skills gap, but the real problem is mindset,’ says tech expert](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Tara-Headshot-Landscape-70x70.png)](https://www.siliconrepublic.com/careers/skills-gap-real-problem-mindset-tech-expert-technovation) [‘There’s a skills gap, but the real problem is mindset,’ says tech expert 16 Jan 2026](https://www.siliconrepublic.com/careers/skills-gap-real-problem-mindset-tech-expert-technovation)  \\n*   [![Image 23: Qualcomm to invest €125m in Cork facility, adding 300 jobs](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Qualcomm_cork-70x70.jpg)](https://www.siliconrepublic.com/jobs-news/qualcomm-e125m-cork-creating-300-jobs) [Qualcomm to invest €125m in Cork facility, adding 300 jobs 16 Jan 2026](https://www.siliconrepublic.com/jobs-news/qualcomm-e125m-cork-creating-300-jobs)  \\n*   [![Image 24: ASML becomes third in Europe to cross $500bn market cap](https://www.siliconrepublic.com/wp-content/uploads/2026/01/asml-building-netherlands-70x70.png)](https://www.siliconrepublic.com/business/asml-third-in-europe-to-cross-500bn-market-cap-tsmc-taiwan-semiconductor) [ASML becomes third in Europe to cross $500bn market cap 16 Jan 2026](https://www.siliconrepublic.com/business/asml-third-in-europe-to-cross-500bn-market-cap-tsmc-taiwan-semiconductor)  \\n*   [![Image 25: German agentic AI start-up Parloa triples valuation to $3bn](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Parloa_co-founders_headshot-70x70.jpg)](https://www.siliconrepublic.com/start-ups/german-agentic-ai-parloa-triples-valuation-berlin-funding-investment) [German agentic AI start-up Parloa triples valuation to $3bn 16 Jan 2026](https://www.siliconrepublic.com/start-ups/german-agentic-ai-parloa-triples-valuation-berlin-funding-investment)  \\n*   [![Image 26: US, Taiwan agree to slash tariffs, boost US chip investments by $250bn](https://www.siliconrepublic.com/wp-content/uploads/2026/01/tsmcarizona-70x70.jpg)](https://www.siliconrepublic.com/business/us-taiwan-slash-tariffs-boost-us-chip-investments-250bn) [US, Taiwan agree to slash tariffs, boost US chip investments by $250bn 16 Jan 2026](https://www.siliconrepublic.com/business/us-taiwan-slash-tariffs-boost-us-chip-investments-250bn)  \\n*   [![Image 27: Minister Smyth says laws adequate to tackle non-consensual Grok AI images](https://www.siliconrepublic.com/wp-content/uploads/2026/01/X-Headquarters-California-2026-70x70.jpeg)](https://www.siliconrepublic.com/machines/minister-smyth-says-laws-adequate-to-tackle-non-consensual-grok-ai-images) [Minister Smyth says laws adequate to tackle non-consensual Grok AI images 16 Jan 2026](https://www.siliconrepublic.com/machines/minister-smyth-says-laws-adequate-to-tackle-non-consensual-grok-ai-images)  \\n*     \\n*   [![Image 28: BioInnovate on the look out for Irish medtech innovators](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Prof-O-Halloran-Bioinnovate-2026-70x70.jpg)](https://www.siliconrepublic.com/start-ups/bioinnovate-on-the-look-out-for-irish-medtech-innovators) [BioInnovate on the look out for Irish medtech innovators 16 Jan 2026](https://www.siliconrepublic.com/start-ups/bioinnovate-on-the-look-out-for-irish-medtech-innovators)  \\n*   [![Image 29: Irish edtech ‘creating global standard’ for AI skills secures €1m](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Ian-Dodson-70x70.jpg)](https://www.siliconrepublic.com/start-ups/irish-edtech-creating-global-standard-ai-skills-secures-funding) [Irish edtech ‘creating global standard’ for AI skills secures €1m 15 Jan 2026](https://www.siliconrepublic.com/start-ups/irish-edtech-creating-global-standard-ai-skills-secures-funding)  \\n*   [![Image 30: Ireland third-best European country to hire in, says report](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Europe-jobs-report-70x70.jpeg)](https://www.siliconrepublic.com/careers/ireland-top-3-european-countries-hire-report-skills-regulation-working-life) [Ireland third-best European country to hire in, says report 15 Jan 2026](https://www.siliconrepublic.com/careers/ireland-top-3-european-countries-hire-report-skills-regulation-working-life)  \\n*   [![Image 31: Dublin’s Luna bags €1.5m to bring its AI safety camera to market](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Luna-Systems_Andrew-Fleury-CEO-Maria-Diviney-COO-70x70.jpg)](https://www.siliconrepublic.com/start-ups/luna-systems-dublin-cycle-safety-ai-camera-cv) [Dublin’s Luna bags €1.5m to bring its AI safety camera to market 15 Jan 2026](https://www.siliconrepublic.com/start-ups/luna-systems-dublin-cycle-safety-ai-camera-cv)  \\n*   [![Image 32: Irish start-up Equal1 raises $60m to deploy its quantum tech](https://www.siliconrepublic.com/wp-content/uploads/2025/05/Jason-Lynch-CEO-Equal1-landscape-70x70.jpg)](https://www.siliconrepublic.com/start-ups/equal1-quantum-computing-ireland-isif-atlantic-enterprise-ireland) [Irish start-up Equal1 raises $60m to deploy its quantum tech 15 Jan 2026](https://www.siliconrepublic.com/start-ups/equal1-quantum-computing-ireland-isif-atlantic-enterprise-ireland)  \\n*   [![Image 33: Musk’s xAI bows to pressure and blocks Grok from ‘nudifying’ images](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Grok-icon-smartphone-2026-70x70.jpg)](https://www.siliconrepublic.com/machines/musks-xai-bows-to-pressure-and-blocks-grok-from-nudifying-images) [Musk’s xAI bows to pressure and blocks Grok from ‘nudifying’ images 15 Jan 2026](https://www.siliconrepublic.com/machines/musks-xai-bows-to-pressure-and-blocks-grok-from-nudifying-images)  \\n*     \\n\\n### More from Science\\n\\nLatest News\\n-----------\\n\\n*   [![Image 34: The North Pole keeps moving – how does that affect Santa’s travel and yours?](https://www.siliconrepublic.com/wp-content/uploads/2025/12/North-Pole-70x70.jpeg)](https://www.siliconrepublic.com/machines/north-pole-santas-travel-geolocation-navigation-gis) [The North Pole keeps moving – how does that affect Santa’s travel and yours? 23 Dec 2025](https://www.siliconrepublic.com/machines/north-pole-santas-travel-geolocation-navigation-gis)  \\n*   [![Image 35: ‘Sorting signal from noise’: Academic podcasting in an age of excess](https://www.siliconrepublic.com/wp-content/uploads/2025/12/rob_o_connor_setu-70x70.jpg)](https://www.siliconrepublic.com/innovation/setu-academic-podcasting-research-ai-data-framework-tech-science-communication) [‘Sorting signal from noise’: Academic podcasting in an age of excess 23 Dec 2025](https://www.siliconrepublic.com/innovation/setu-academic-podcasting-research-ai-data-framework-tech-science-communication)  \\n*   [![Image 36: Seven industry-focused Irish projects get €5.7m equipment boost](https://www.siliconrepublic.com/wp-content/uploads/2024/12/chip-manufacturing-70x70.jpeg)](https://www.siliconrepublic.com/innovation/ireland-capital-equipment-call-2025-technology-gateway-enterprise-ireland) [Seven industry-focused Irish projects get €5.7m equipment boost 23 Dec 2025](https://www.siliconrepublic.com/innovation/ireland-capital-equipment-call-2025-technology-gateway-enterprise-ireland)  \\n*   [![Image 37: ‘Damhán Alla’: Spider-like feature on Jupiter’s moon gets an Irish name](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Manann%C3%A1n-crater-70x70.jpg)](https://www.siliconrepublic.com/innovation/damhan-alla-spider-like-feature-on-jupiters-moon-europa-ireland) [‘Damhán Alla’: Spider-like feature on Jupiter’s moon gets an Irish name 23 Dec 2025](https://www.siliconrepublic.com/innovation/damhan-alla-spider-like-feature-on-jupiters-moon-europa-ireland)  \\n*   [![Image 38: Here’s a holly jolly list of unsung heroes of science](https://www.siliconrepublic.com/wp-content/uploads/2025/12/christmas_chihuahua_glasses-70x70.jpeg)](https://www.siliconrepublic.com/innovation/unsung-heroes-of-science-list-research-innovation-galois-fenyman-kelsey) [Here’s a holly jolly list of unsung heroes of science 23 Dec 2025](https://www.siliconrepublic.com/innovation/unsung-heroes-of-science-list-research-innovation-galois-fenyman-kelsey)  \\n*   [![Image 39: This Irish teen racer is driving for an Esports Olympics](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Kamto_profile-70x70.jpg)](https://www.siliconrepublic.com/innovation/irish-teen-sim-racing-driving-esports-olympics-gaming-nec-cork) [This Irish teen racer is driving for an Esports Olympics 19 Dec 2025](https://www.siliconrepublic.com/innovation/irish-teen-sim-racing-driving-esports-olympics-gaming-nec-cork)  \\n*   [![Image 40: Six more projects win €8m in prizes from national challenge fund](https://www.siliconrepublic.com/wp-content/uploads/2025/12/ResearchIrelandNationalChallengeFund-70x70.jpg)](https://www.siliconrepublic.com/innovation/national-challenge-fund-december-2025-renew-stopflood4ie-grosafe-traceless) [Six more projects win €8m in prizes from national challenge fund 19 Dec 2025](https://www.siliconrepublic.com/innovation/national-challenge-fund-december-2025-renew-stopflood4ie-grosafe-traceless)  \\n*   [![Image 41: Anatomy of an elf: How Santa’s helpers are adapted to their work](https://www.siliconrepublic.com/wp-content/uploads/2025/12/three_elves_christmas-70x70.jpeg)](https://www.siliconrepublic.com/innovation/anatomy-elf-santa-helpers-work-adaptation-anatomy-science-christmas-presents) [Anatomy of an elf: How Santa’s helpers are adapted to their work 19 Dec 2025](https://www.siliconrepublic.com/innovation/anatomy-elf-santa-helpers-work-adaptation-anatomy-science-christmas-presents)  \\n*   [![Image 42: Eric Schmidt among donors pledging $1bn to CERN’s Future Circular Collider](https://www.siliconrepublic.com/wp-content/uploads/2017/12/eric-schmidt-alphabet-shutterstock-70x70.jpg)](https://www.siliconrepublic.com/innovation/eric-schmidt-among-donors-pledging-1bn-to-cerns-future-circular-collider-physics) [Eric Schmidt among donors pledging $1bn to CERN’s Future Circular Collider 19 Dec 2025](https://www.siliconrepublic.com/innovation/eric-schmidt-among-donors-pledging-1bn-to-cerns-future-circular-collider-physics)  \\n*     \\n*   [![Image 43: At the end of 2025, what is the state of the current deep-tech landscape?](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Deep-tech-image-1-70x70.jpeg)](https://www.siliconrepublic.com/machines/nearing-end-2025-current-deep-tech-landscape-skills-ai) [At the end of 2025, what is the state of the current deep-tech landscape? 17 Dec 2025](https://www.siliconrepublic.com/machines/nearing-end-2025-current-deep-tech-landscape-skills-ai)  \\n*   [![Image 44: Pioneering materials science team at UL wins award for Nobel collaboration](https://www.siliconrepublic.com/wp-content/uploads/2025/12/ul_sspc_nobel_collaboration_award-70x70.jpg)](https://www.siliconrepublic.com/innovation/materials-science-mof-ul-sspc-award-nobel-collaboration-kitagawa-kyoto) [Pioneering materials science team at UL wins award for Nobel collaboration 17 Dec 2025](https://www.siliconrepublic.com/innovation/materials-science-mof-ul-sspc-award-nobel-collaboration-kitagawa-kyoto)  \\n*   [![Image 45: Ireland cutting emissions, but more needs to be done to meet 2030 goals](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Climate-Goal-image-70x70.jpeg)](https://www.siliconrepublic.com/innovation/ireland-cutting-emissions-2030-goals-sustainable-renewable) [Ireland cutting emissions, but more needs to be done to meet 2030 goals 17 Dec 2025](https://www.siliconrepublic.com/innovation/ireland-cutting-emissions-2030-goals-sustainable-renewable)  \\n*   [![Image 46: How to make the ‘engine of medical progress’ more diverse](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Dr-Eimear-Morrissey-70x70.jpg)](https://www.siliconrepublic.com/innovation/how-to-engine-of-medical-progress-diverse-clinical-trials-research-galway) [How to make the ‘engine of medical progress’ more diverse 16 Dec 2025](https://www.siliconrepublic.com/innovation/how-to-engine-of-medical-progress-diverse-clinical-trials-research-galway)  \\n*   [![Image 47: Opinion: ‘Tis the season for AI predictions – 2026 bots unwrapped](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Christmas_robots-70x70.jpeg)](https://www.siliconrepublic.com/machines/opinion-ai-predictions-2026-unwrapped-microsoft-google-slop-avatars-openai-security) [Opinion: ‘Tis the season for AI predictions – 2026 bots unwrapped 12 Dec 2025](https://www.siliconrepublic.com/machines/opinion-ai-predictions-2026-unwrapped-microsoft-google-slop-avatars-openai-security)  \\n*   [![Image 48: Google DeepMind to open UK research lab for discovery of new materials](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Google-DeepMind-Logo-70x70.jpeg)](https://www.siliconrepublic.com/machines/google-deepmind-open-first-research-lab-discovering-new-materials) [Google DeepMind to open UK research lab for discovery of new materials 11 Dec 2025](https://www.siliconrepublic.com/machines/google-deepmind-open-first-research-lab-discovering-new-materials)  \\n*   [![Image 49: Six Irish research projects among winners of €728m ERC awards](https://www.siliconrepublic.com/wp-content/uploads/2025/12/UCC-Eugene-Costello-70x70.jpg)](https://www.siliconrepublic.com/innovation/six-irish-researchers-winners-e728m-erc-consolidator-grants-tcd-ucc-ucd-rcsi) [Six Irish research projects among winners of €728m ERC awards 9 Dec 2025](https://www.siliconrepublic.com/innovation/six-irish-researchers-winners-e728m-erc-consolidator-grants-tcd-ucc-ucd-rcsi)  \\n*   [![Image 50: New cross-border health research project launched in Belfast](https://www.siliconrepublic.com/wp-content/uploads/2025/12/onehealth_project_launch-70x70.jpg)](https://www.siliconrepublic.com/innovation/onehealth-ireland-belfast-health-research-cross-border) [New cross-border health research project launched in Belfast 9 Dec 2025](https://www.siliconrepublic.com/innovation/onehealth-ireland-belfast-health-research-cross-border)  \\n*   [![Image 51: Seven new DTIF projects take total awarded in latest call to €159m](https://www.siliconrepublic.com/wp-content/uploads/2025/12/DTIF-december-2025--70x70.jpg)](https://www.siliconrepublic.com/innovation/disruptive-technologies-innovation-fund-ireland-call-7-funding-december-2025-159m) [Seven new DTIF projects take total awarded in latest call to €159m 8 Dec 2025](https://www.siliconrepublic.com/innovation/disruptive-technologies-innovation-fund-ireland-call-7-funding-december-2025-159m)  \\n*     \\n*   [![Image 52: ATU team develops process to make smartphone batteries safer and cheaper](https://www.siliconrepublic.com/wp-content/uploads/2025/12/sirengo-and-pillai-70x70.jpg)](https://www.siliconrepublic.com/innovation/atu-research-smartphone-batteries-safer-cheaper-lithium-ion-fire) [ATU team develops process to make smartphone batteries safer and cheaper 8 Dec 2025](https://www.siliconrepublic.com/innovation/atu-research-smartphone-batteries-safer-cheaper-lithium-ion-fire)  \\n*   [![Image 53: €4.55bn investment plan aims to boost Ireland’s research competitiveness](https://www.siliconrepublic.com/wp-content/uploads/2025/12/microscope_closeup_research-70x70.jpeg)](https://www.siliconrepublic.com/innovation/ireland-research-investment-education-innovation) [€4.55bn investment plan aims to boost Ireland’s research competitiveness 5 Dec 2025](https://www.siliconrepublic.com/innovation/ireland-research-investment-education-innovation)  \\n\\nMore\\n\\n*   [![Image 54: After OpenAI, Anthropic launches Claude for Healthcare](https://www.siliconrepublic.com/wp-content/uploads/2024/05/AdobeStock_807147210_Editorial_Use_Only-330x251.jpeg)](https://www.siliconrepublic.com/machines/anthropic-claude-healthcare-tools-ai-openai-data-privacy)[Machines](https://www.siliconrepublic.com/machines) [### After OpenAI, Anthropic launches Claude for Healthcare](https://www.siliconrepublic.com/machines/anthropic-claude-healthcare-tools-ai-openai-data-privacy)\\n12 Jan 2026  \\n*   [![Image 55: Kerry student wins Stripe YSTE with brain cancer diagnosis tool](https://www.siliconrepublic.com/wp-content/uploads/2026/01/StripeYSTE_winner_2026-330x251.jpg)](https://www.siliconrepublic.com/innovation/aoibheann-daly-stripe-yste-2026-brain-cancer-winner)[Innovation](https://www.siliconrepublic.com/innovation) [### Kerry student wins Stripe YSTE with brain cancer diagnosis tool](https://www.siliconrepublic.com/innovation/aoibheann-daly-stripe-yste-2026-brain-cancer-winner)\\n9 Jan 2026  \\n*   [![Image 56: Opinion: 2026 will be the year when AI transforms business value](https://www.siliconrepublic.com/wp-content/uploads/2026/01/AI-profit-illustration-2026-330x251.jpeg)](https://www.siliconrepublic.com/machines/pwc-ai-tech-trends-opinion-business-tech)[Machines](https://www.siliconrepublic.com/machines) [### Opinion: 2026 will be the year when AI transforms business value](https://www.siliconrepublic.com/machines/pwc-ai-tech-trends-opinion-business-tech)\\n9 Jan 2026  \\n*      \\n*   [![Image 57: Grok image editing limited on X after users prompt AI deepfakes](https://www.siliconrepublic.com/wp-content/uploads/2023/12/AdobeStock_626862185_Editorial_Use_Only-330x251.jpeg)](https://www.siliconrepublic.com/machines/x-xai-grok-legal-eu-ireland-premium-users)[Machines](https://www.siliconrepublic.com/machines) [### Grok image editing limited on X after users prompt AI deepfakes](https://www.siliconrepublic.com/machines/x-xai-grok-legal-eu-ireland-premium-users)\\n9 Jan 2026  \\n*   [![Image 58: Ireland’s national AI centre given €5.7m to advance European digital initiative](https://www.siliconrepublic.com/wp-content/uploads/2026/01/CeADARs-Management-330x251.jpg)](https://www.siliconrepublic.com/innovation/irelands-national-ai-centre-advance-european-digital-initiative)[Innovation](https://www.siliconrepublic.com/innovation) [### Ireland’s national AI centre given €5.7m to advance European digital initiative](https://www.siliconrepublic.com/innovation/irelands-national-ai-centre-advance-european-digital-initiative)\\n9 Jan 2026  \\n*   [![Image 59: Opinion: In light of the Grok horror show, is it time we demand better?](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Grok-icon-smartphone-2026-330x251.jpg)](https://www.siliconrepublic.com/machines/opinion-grok-csam-ai-x-elon-musk)[Machines](https://www.siliconrepublic.com/machines) [### Opinion: In light of the Grok horror show, is it time we demand better?](https://www.siliconrepublic.com/machines/opinion-grok-csam-ai-x-elon-musk)\\n9 Jan 2026  \\n*   [![Image 60: ‘2026 should be a year of delivery, not greenwashing’](https://www.siliconrepublic.com/wp-content/uploads/2026/01/plant_in_keyboard_sustainability-330x251.jpeg)](https://www.siliconrepublic.com/machines/kyndryl-sustainability-tech-ai-reports)[Machines](https://www.siliconrepublic.com/machines) [### ‘2026 should be a year of delivery, not greenwashing’](https://www.siliconrepublic.com/machines/kyndryl-sustainability-tech-ai-reports)\\n8 Jan 2026  \\n*      \\n*   [![Image 61: OpenAI launches dedicated health feature for ChatGPT](https://www.siliconrepublic.com/wp-content/uploads/2026/01/AI-doctor-330x251.jpeg)](https://www.siliconrepublic.com/machines/openai-tries-tackling-privacy-concerns-with-new-chatgpt-health)[Machines](https://www.siliconrepublic.com/machines) [### OpenAI launches dedicated health feature for ChatGPT](https://www.siliconrepublic.com/machines/openai-tries-tackling-privacy-concerns-with-new-chatgpt-health)\\n8 Jan 2026  \\n*   [![Image 62: Universal Music enters into Nvidia deal to expand AI capabilities](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Nvidia-Image-330x251.jpeg)](https://www.siliconrepublic.com/machines/universal-music-nvidia-expand-ai-capabilities-copyright)[Machines](https://www.siliconrepublic.com/machines) [### Universal Music enters into Nvidia deal to expand AI capabilities](https://www.siliconrepublic.com/machines/universal-music-nvidia-expand-ai-capabilities-copyright)\\n7 Jan 2026  \\n*   [![Image 63: Thousands expected to attend as YSTE’26 kicks off with Stripe at helm](https://www.siliconrepublic.com/wp-content/uploads/2026/01/StripeYSTE26-330x251.jpg)](https://www.siliconrepublic.com/innovation/stripe-young-scientist-technology-exhibition-2026-dublin)[Innovation](https://www.siliconrepublic.com/innovation) [### Thousands expected to attend as YSTE’26 kicks off with Stripe at helm](https://www.siliconrepublic.com/innovation/stripe-young-scientist-technology-exhibition-2026-dublin)\\n7 Jan 2026  \\n*   [![Image 64: ‘Done well, data and AI improves accountability – done badly, they amplify risk’](https://www.siliconrepublic.com/wp-content/uploads/2026/01/Julie-Collison-Image-Awards-330x251.png)](https://www.siliconrepublic.com/machines/data-ai-improves-accountability-amplify-risk-women-invent)[Machines](https://www.siliconrepublic.com/machines) [### ‘Done well, data and AI improves accountability – done badly, they amplify risk’](https://www.siliconrepublic.com/machines/data-ai-improves-accountability-amplify-risk-women-invent)\\n7 Jan 2026  \\n*      \\n*   [![Image 65: Nvidia unveils open-source AI models for next-gen self-driving vehicles](https://www.siliconrepublic.com/wp-content/uploads/2026/01/nvidia-live-with-ceo-jensen-huang-330x251.jpg)](https://www.siliconrepublic.com/machines/nvidia-ai-autonomous-vehicle-technology-artificial-intelligence-alpamayo)[Machines](https://www.siliconrepublic.com/machines) [### Nvidia unveils open-source AI models for next-gen self-driving vehicles](https://www.siliconrepublic.com/machines/nvidia-ai-autonomous-vehicle-technology-artificial-intelligence-alpamayo)\\n6 Jan 2026  \\n*   [![Image 66: €23m boost for Irish innovation hubs as EU programme enters second leg](https://www.siliconrepublic.com/wp-content/uploads/2023/01/AdobeStock_512461846-330x251.jpeg)](https://www.siliconrepublic.com/innovation/ireland-digital-innovation-hub-europe-ceadar-factoryxchange-entire-data2sustain-23m)[Innovation](https://www.siliconrepublic.com/innovation) [### €23m boost for Irish innovation hubs as EU programme enters second leg](https://www.siliconrepublic.com/innovation/ireland-digital-innovation-hub-europe-ceadar-factoryxchange-entire-data2sustain-23m)\\n5 Jan 2026  \\n*   [![Image 67: Opinion: Why Ireland needs human-AI drone defence](https://www.siliconrepublic.com/wp-content/uploads/2025/12/drone_blue_sky-330x251.jpeg)](https://www.siliconrepublic.com/machines/opinion-ireland-needs-human-ai-drone-defence-ucc-northwestern)[Machines](https://www.siliconrepublic.com/machines) [### Opinion: Why Ireland needs human-AI drone defence](https://www.siliconrepublic.com/machines/opinion-ireland-needs-human-ai-drone-defence-ucc-northwestern)\\n5 Jan 2026  \\n*   [![Image 68: The North Pole keeps moving – how does that affect Santa’s travel and yours?](https://www.siliconrepublic.com/wp-content/uploads/2025/12/North-Pole-330x251.jpeg)](https://www.siliconrepublic.com/machines/north-pole-santas-travel-geolocation-navigation-gis)[Machines](https://www.siliconrepublic.com/machines) [### The North Pole keeps moving – how does that affect Santa’s travel and yours?](https://www.siliconrepublic.com/machines/north-pole-santas-travel-geolocation-navigation-gis)\\n23 Dec 2025  \\n*      \\n*   [![Image 69: ‘Sorting signal from noise’: Academic podcasting in an age of excess](https://www.siliconrepublic.com/wp-content/uploads/2025/12/rob_o_connor_setu-330x251.jpg)](https://www.siliconrepublic.com/innovation/setu-academic-podcasting-research-ai-data-framework-tech-science-communication)[Innovation](https://www.siliconrepublic.com/innovation) [### ‘Sorting signal from noise’: Academic podcasting in an age of excess](https://www.siliconrepublic.com/innovation/setu-academic-podcasting-research-ai-data-framework-tech-science-communication)\\n23 Dec 2025  \\n*   [![Image 70: Seven industry-focused Irish projects get €5.7m equipment boost](https://www.siliconrepublic.com/wp-content/uploads/2024/12/chip-manufacturing-330x251.jpeg)](https://www.siliconrepublic.com/innovation/ireland-capital-equipment-call-2025-technology-gateway-enterprise-ireland)[Innovation](https://www.siliconrepublic.com/innovation) [### Seven industry-focused Irish projects get €5.7m equipment boost](https://www.siliconrepublic.com/innovation/ireland-capital-equipment-call-2025-technology-gateway-enterprise-ireland)\\n23 Dec 2025  \\n*   [![Image 71: ‘Damhán Alla’: Spider-like feature on Jupiter’s moon gets an Irish name](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Manann%C3%A1n-crater-330x251.jpg)](https://www.siliconrepublic.com/innovation/damhan-alla-spider-like-feature-on-jupiters-moon-europa-ireland)[Innovation](https://www.siliconrepublic.com/innovation) [### ‘Damhán Alla’: Spider-like feature on Jupiter’s moon gets an Irish name](https://www.siliconrepublic.com/innovation/damhan-alla-spider-like-feature-on-jupiters-moon-europa-ireland)\\n23 Dec 2025  \\n*   [![Image 72: Here’s a holly jolly list of unsung heroes of science](https://www.siliconrepublic.com/wp-content/uploads/2025/12/christmas_chihuahua_glasses-330x251.jpeg)](https://www.siliconrepublic.com/innovation/unsung-heroes-of-science-list-research-innovation-galois-fenyman-kelsey)[Innovation](https://www.siliconrepublic.com/innovation) [### Here’s a holly jolly list of unsung heroes of science](https://www.siliconrepublic.com/innovation/unsung-heroes-of-science-list-research-innovation-galois-fenyman-kelsey)\\n23 Dec 2025  \\n*      \\n*   [![Image 73: This Irish teen racer is driving for an Esports Olympics](https://www.siliconrepublic.com/wp-content/uploads/2025/12/Kamto_profile-330x251.jpg)](https://www.siliconrepublic.com/innovation/irish-teen-sim-racing-driving-esports-olympics-gaming-nec-cork)[Innovation](https://www.siliconrepublic.com/innovation) [### This Irish teen racer is driving for an Esports Olympics](https://www.siliconrepublic.com/innovation/irish-teen-sim-racing-driving-esports-olympics-gaming-nec-cork)\\n19 Dec 2025  \\n\\nMore\\n\\n[![Image 74: Silicon Republic](https://www.siliconrepublic.com/wp-content/themes/silicon/img/footerlogo.png)](https://www.siliconrepublic.com/)\\n\\n*   [](https://www.facebook.com/siliconrepublic)\\n*   [](https://www.linkedin.com/groups?mostPopular=&gid=2910996)\\n*   [](https://bsky.app/profile/siliconrepublic.bsky.social)\\n*   [](https://www.youtube.com/user/siliconrepublic)\\n*   [](https://www.siliconrepublic.com/feed)\\n\\n* * *\\n\\n*   [Home](https://www.siliconrepublic.com/)\\n*   [About](https://www.siliconrepublic.com/about)\\n*   [Contact](https://www.siliconrepublic.com/contact)\\n\\n*   [Advertise](https://www.siliconrepublic.com/advertise)\\n*   [Subscribe](https://www.siliconrepublic.com/subscribe)\\n*   [Privacy Policy](https://www.siliconrepublic.com/privacy)\\n*   [Privacy Settings](javascript:Optanon.ToggleInfoDisplay();)\\n\\n*   [](https://www.facebook.com/siliconrepublic)\\n*   [](https://www.linkedin.com/groups?mostPopular=&gid=2910996)\\n*   [](https://bsky.app/profile/siliconrepublic.bsky.social)\\n*   [](https://www.youtube.com/user/siliconrepublic)\\n*   [](https://www.siliconrepublic.com/feed)\\n\\n* * *\\n\\nAll content copyright 2002-2026 Silicon Republic Knowledge & Events Management Ltd. Reproduction without explicit permission is prohibited. All rights reserved.\\n\\n Website by [Square1.io](https://www.square1.io/)\\n\\nBy clicking “Accept All Cookies”, you agree to the storing of cookies on your device to enhance site navigation, analyze site usage, and assist in our marketing efforts. \\n\\nCookies Settings Reject All Accept All Cookies\\n\\n![Image 75: Company Logo](https://cdn.cookielaw.org/logos/static/ot_company_logo.png)\\n\\nPrivacy Preference Center\\n-------------------------\\n\\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer. \\n\\n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\\n\\nAllow All\\n### Manage Consent Preferences\\n\\n#### Strictly Necessary Cookies\\n\\nAlways Active\\n\\nThese cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\\n\\n#### Targeting Cookies\\n\\n- [x] Targeting Cookies \\n\\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\\n\\n#### Performance Cookies\\n\\n- [x] Performance Cookies \\n\\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\\n\\n#### Functional Cookies\\n\\n- [x] Functional Cookies \\n\\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.\\n\\n### Cookie List\\n\\nClear\\n\\n- [x] checkbox label label\\n\\nApply Cancel\\n\\nConsent Leg.Interest\\n\\n- [x] checkbox label label\\n\\n- [x] checkbox label label\\n\\n- [x] checkbox label label\\n\\nReject All Confirm My Choices\\n\\n[![Image 76: Powered by Onetrust](https://cdn.cookielaw.org/logos/static/powered_by_logo.svg)](https://www.onetrust.com/products/cookie-consent/)\"}, {\"url\": \"https://openai.com/index/introducing-apps-in-chatgpt/\", \"title\": \"Introducing apps in ChatGPT and the new Apps SDK - OpenAI\", \"content\": \"We’ll also share details on monetization soon, including support for the new Agentic Commerce Protocol⁠, an open standard that enables instant checkout in ChatGPT.\\n\\nThis is just the start of apps in ChatGPT, bringing new utility to users and new opportunities for developers.\\n\\n   2025\\n   DevDay\\n\\nAuthor\\n\\nOpenAI\\n\\nKeep reading\\n\\nView all\\n\\nImage 3: OAI Go Blog ArtCard 1x1\\n\\nIntroducing ChatGPT Go, now available worldwide Product Jan 16, 2026\\n\\nImage 4: OAI Ads Blog ArtCard 1x1\\n\\nOur approach to advertising and expanding access to ChatGPT Company Jan 16, 2026\\n\\nImage 5: OpenAI for Healthcare > Cover Image\\n\\nIntroducing OpenAI for Healthcare Product Jan 8, 2026\\n\\nOur Research\\n   Research Index\\n   Research Overview\\n   Research Residency\\n   OpenAI for Science [...] Product\\n\\nIntroducing apps in ChatGPT and the new Apps SDK\\n\\nA new generation of apps you can chat with and the tools for developers to build them.\\n\\nTry in ChatGPT(opens in a new window)Start building apps(opens in a new window)\\n\\n00:00 01:09\\n\\nListen to article\\n\\nShare\\n\\n_Update on November 13, 2025__: Apps are now available in preview to ChatGPT Business, Enterprise and Edu customers._\\n\\nToday we’re introducing a new generation of apps you can chat with, right inside ChatGPT. Developers can start building them today with the new Apps SDK, available in preview.\", \"score\": 0.8184036, \"raw_content\": \"Introducing apps in ChatGPT and the new Apps SDK | OpenAI\\n===============\\n\\n[Skip to main content](https://openai.com/index/introducing-apps-in-chatgpt/#main)\\n\\nLog in\\n\\n[](https://openai.com/)\\n\\nSwitch to\\n\\n*   [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n*   [Sora(opens in a new window)](https://sora.com/)\\n*   [API Platform(opens in a new window)](https://platform.openai.com/)\\n\\n*   [Research](https://openai.com/research/index/) \\n*   [Safety](https://openai.com/safety/) \\n*   [For Business](https://openai.com/business/) \\n*   [For Developers](https://openai.com/api/) \\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true) \\n*   [Sora](https://openai.com/sora/) \\n*   [Stories](https://openai.com/stories/) \\n*   [Company](https://openai.com/about/) \\n*   [News](https://openai.com/news/company-announcements/) \\n\\n*   Research\\n\\nBack to main menu  \\n\\n    *   [Research Index](https://openai.com/research/index/)\\n    *   [Research Overview](https://openai.com/research/)\\n    *   [Research Residency](https://openai.com/residency/)\\n    *   [OpenAI for Science](https://openai.com/science/)\\n    *   Latest Advancements\\n    *   [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)\\n    *   [GPT-5.1](https://openai.com/index/gpt-5-1/)\\n    *   [Sora 2](https://openai.com/index/sora-2/)\\n    *   [GPT-5](https://openai.com/index/introducing-gpt-5/)\\n    *   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n    *   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)\\n\\n*   Safety\\n\\nBack to main menu  \\n\\n    *   [Safety Approach](https://openai.com/safety/)\\n    *   [Security & Privacy](https://openai.com/security-and-privacy/)\\n\\n*   [For Business](https://openai.com/business/)\\n\\nBack to main menu  \\n\\n    *   [Business Overview](https://openai.com/business/)\\n    *   [Solutions](https://openai.com/solutions/)\\n    *   [Learn](https://openai.com/business/learn/)\\n    *   [Startups](https://openai.com/startups/)\\n    *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Contact Sales](https://openai.com/contact-sales/)\\n\\n*   For Developers\\n\\nBack to main menu  \\n\\n    *   [API Platform](https://openai.com/api/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Agents](https://openai.com/agent-platform/)\\n    *   [Codex](https://openai.com/codex/)\\n    *   [Open Models](https://openai.com/open-models/)\\n    *   [Community(opens in a new window)](https://community.openai.com/)\\n\\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n\\nBack to main menu  \\n\\n    *   [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n    *   [Business](https://chatgpt.com/for-business/team?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n    *   [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n    *   [Education](https://chatgpt.com/for-business/education?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n    *   [Pricing](https://chatgpt.com/pricing?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n    *   [Download](https://chatgpt.com/download?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n\\n*   [Sora](https://openai.com/sora/)\\n*   [Stories](https://openai.com/stories/)\\n*   Company\\n\\nBack to main menu  \\n\\n    *   [About Us](https://openai.com/about/)\\n    *   [Our Charter](https://openai.com/charter/)\\n    *   [Foundation](https://openai.com/foundation/)\\n    *   [Careers](https://openai.com/careers/)\\n    *   [Brand Guidelines](https://openai.com/brand/)\\n\\n*   [News](https://openai.com/news/company-announcements/)\\n\\nLog in\\n\\nIntroducing apps in ChatGPT and the new Apps SDK | OpenAI\\n\\nTable of contents\\n\\n*   [How to use apps in ChatGPT](https://openai.com/index/introducing-apps-in-chatgpt/#how-to-use-apps-in-chatgpt)\\n*   [Apps available today](https://openai.com/index/introducing-apps-in-chatgpt/#apps-available-today)\\n*   [Apps coming soon](https://openai.com/index/introducing-apps-in-chatgpt/#apps-coming-soon)\\n*   [How to build with the Apps SDK](https://openai.com/index/introducing-apps-in-chatgpt/#how-to-build-with-the-apps-sdk)\\n*   [Safety and privacy](https://openai.com/index/introducing-apps-in-chatgpt/#safety-and-privacy)\\n*   [What’s next](https://openai.com/index/introducing-apps-in-chatgpt/#whats-next)\\n\\nOctober 6, 2025\\n\\n[Product](https://openai.com/news/product-releases/)\\n\\nIntroducing apps in ChatGPT and the new Apps SDK\\n================================================\\n\\nA new generation of apps you can chat with and the tools for developers to build them.\\n\\n[Try in ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)[Start building apps(opens in a new window)](https://developers.openai.com/apps-sdk)\\n\\n00:00 01:09\\n\\nListen to article\\n\\nShare\\n\\n**_Update on November 13, 2025_**_: Apps are now available in preview to ChatGPT Business, Enterprise and Edu customers._\\n\\nToday we’re introducing a new generation of apps you can chat with, right inside ChatGPT. Developers can start building them today with the new Apps SDK, available in preview.\\n\\nApps in ChatGPT fit naturally into conversation. You can discover them when ChatGPT suggests one at the right time, or by calling them by name. Apps respond to natural language and include interactive interfaces you can use right in the chat.\\n\\nFor ChatGPT users, apps meet you in the chat and adapt to your context to help you create, learn, and do more. For developers, building with the Apps SDK makes it possible to reach over 800 million ChatGPT users at just the right time.\\n\\nApps will be available today to all logged-in ChatGPT users outside of the European Economic Area, Switzerland, and the United Kingdom on Free, Go, Plus and Pro plans. Our pilot partners–Booking.com, Canva, Coursera, Figma, Expedia, Spotify and Zillow are also available today in markets where their services are offered starting in English. More pilot partners will launch later this year and we expect to bring apps to EU users soon.\\n\\nDevelopers can start building and testing apps today with the new Apps SDK preview, which we’re releasing as an open standard built on the [Model Context Protocol⁠(opens in a new window)](https://modelcontextprotocol.io/docs/getting-started/intro) (MCP). To start building, visit our [documentation⁠(opens in a new window)](https://developers.openai.com/apps-sdk) for guidelines and example apps, and then test your apps using Developer Mode in ChatGPT.\\n\\nLater this year, we’ll begin accepting app submissions for review and publication and will share more details on how developers can monetize their apps.\\n\\nHow to use apps in ChatGPT\\n--------------------------\\n\\nWhen you start a message to ChatGPT with the name of an available app, like “Spotify, make a playlist for my party this Friday,” ChatGPT can automatically surface the app in your chat and use relevant context to help. The first time you use an app, ChatGPT will prompt you to connect so you know what data may be shared with the app.\\n\\nChatGPT can also suggest apps when they’re relevant to the conversation. For example, if you’re talking about buying a new home, ChatGPT can surface the Zillow app as a suggestion so you can browse listings that match your budget on an interactive map right inside ChatGPT.\\n\\nThe magic of this new generation of apps in ChatGPT is how they blend familiar interactive elements–like maps, playlists and presentations–with new ways of interacting through conversation. You can start with an outline and ask Canva to transform it into a slide deck, or take a course with Coursera and ask ChatGPT to elaborate on something in the video as you watch.\\n\\nAs more developers build with the Apps SDK, the list of what’s possible will keep growing. Because these apps appear naturally in your chats, you’ll find them when they’re most likely to be useful.\\n\\nApps available today\\n--------------------\\n\\nWe worked with a small group of early partners to launch the first set of apps, available in ChatGPT today. Their feedback helped shape the Apps SDK preview available to developers now.\\n\\nBooking.com Canva Coursera Expedia Figma Spotify Zillow\\n\\n![Image 1: Mobile screen showing a ChatGPT conversation with a Booking.com integration. The user asks to ‘find me a hotel in Paris for two adults between 11/21–11/24 with parking facilities.’ Below, Booking.com displays search results for Zoku Paris and Le Meurice hotels with photos, prices, and amenities such as Wi-Fi, parking, and pool.](https://images.ctfassets.net/kftzwdyauwt9/2vKwAh34bawGmCw0ozfjg/191c1d3488fb6f331f935830008ce021/Booking_16x9__3_.png?w=3840&q=90&fm=webp)\\n\\nZillow Spotify\\n\\n> \\\"The Zillow app in ChatGPT shows the power of AI to make real estate feel more human. Together with OpenAI, we’re bringing a first-of-its-kind experience to millions — a conversational guide that makes finding a home faster, easier, and more intuitive.\\\"\\n\\n— Josh Weisberg, Head of AI at Zillow\\n\\nApps coming soon\\n----------------\\n\\nWe’re also excited to welcome 11 more partners and their apps later this year.\\n\\n![Image 2: Image showing a horizontal lineup of brand logos on a white background, including AllTrails, Peloton, OpenTable, Target, theFork, Uber, and others, representing companies with upcoming app integrations.](https://images.ctfassets.net/kftzwdyauwt9/5S5EXkN2l8xcXFsCZepKDn/113d980416b9c7dc135046387aff146c/apps-coming-soon_desktop__2_.png?w=3840&q=90&fm=webp)\\n\\nHow to build with the Apps SDK\\n------------------------------\\n\\nApps in ChatGPT are powered by the Apps SDK, available in preview for developers starting today. The Apps SDK builds on the Model Context Protocol (MCP), the open standard that lets ChatGPT connect to external tools and data. It extends MCP so developers can design both the logic and interface of their apps. We’ve made the Apps SDK open source so that apps built with it can run anywhere that adopts this standard.\\n\\nDevelopers can use their own code to define the app’s interface and chat logic, and connect directly with their backend so their existing customers can log in or access premium features.\\n\\nWe’ve published documentation including design guidelines and an open-source repo of examples to help developers design experiences that blend interaction and conversation.\\n\\nOur goal with today’s preview is to get these tools into developers’ hands, gather feedback, and build this new generation of apps together. More reusable components and faster dev tooling are coming soon.\\n\\nSafety and privacy\\n------------------\\n\\nOur policies require that every app in ChatGPT must follow OpenAI’s usage policies, be appropriate for all audiences, and comply with partner rules for any third-party integrations. These standards are designed to help ensure a safe and positive experience for everyone.\\n\\nDevelopers must also include clear privacy policies, collect only the minimum data they need, and be transparent about permissions. The first time a user connects an app, ChatGPT prompts them to connect so they understand what data may be shared with developers. Later this year, we will provide even more granular controls to decide what specific data categories each app can use to personalize results.\\n\\nSo developers know what to expect, we’ve also published a draft of our [developer guidelines⁠(opens in a new window)](http://developers.openai.com/apps-sdk/app-developer-guidelines) outlining the criteria apps must meet to be available in ChatGPT.\\n\\nWhat’s next\\n-----------\\n\\nLater this year, we’ll launch apps to ChatGPT Business, Enterprise and Edu. We’ll also open submissions so developers can publish their apps in ChatGPT, and launch a dedicated directory where users can browse and search for them. Apps that meet the standards provided in our developer guidelines will be eligible to be listed, and those that meet higher design and functionality standards may be featured more prominently—both in the directory and in conversations.\\n\\nWe’ll also share details on monetization soon, including support for the new [Agentic Commerce Protocol⁠](https://openai.com/index/buy-it-in-chatgpt/), an open standard that enables instant checkout in ChatGPT.\\n\\nThis is just the start of apps in ChatGPT, bringing new utility to users and new opportunities for developers.\\n\\n*   [2025](https://openai.com/news/?tags=2025)\\n*   [DevDay](https://openai.com/news/?tags=devday)\\n\\nAuthor\\n------\\n\\n[OpenAI](https://openai.com/news/?author=openai#results)\\n\\nKeep reading\\n------------\\n\\n[View all](https://openai.com/news/product/)\\n\\n![Image 3: OAI Go Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/6VqoFRZtqjJVLA9k1zrVkl/7064d5a2ff89f48f03737b88ecc42f32/OAI_Go_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Go, now available worldwide Product Jan 16, 2026](https://openai.com/index/introducing-chatgpt-go/)\\n\\n![Image 4: OAI Ads Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/41z4Qn4f0i948wZMLWB9lH/f3961891b0e0274306ea19fe368c95d7/OAI_Ads_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Our approach to advertising and expanding access to ChatGPT Company Jan 16, 2026](https://openai.com/index/our-approach-to-advertising-and-expanding-access/)\\n\\n![Image 5: OpenAI for Healthcare > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/4oQtNGNaY29dDxIKJBVphg/18314fd6a66f31249a5f95ec238272de/OAI_forHealth_ArtCard_1-1_C.png?w=3840&q=90&fm=webp)\\n\\n[Introducing OpenAI for Healthcare Product Jan 8, 2026](https://openai.com/index/openai-for-healthcare/)\\n\\nOur Research\\n*   [Research Index](https://openai.com/research/index/)\\n*   [Research Overview](https://openai.com/research/)\\n*   [Research Residency](https://openai.com/residency/)\\n*   [OpenAI for Science](https://openai.com/science/)\\n\\nLatest Advancements\\n*   [GPT-5](https://openai.com/gpt-5/)\\n*   [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\\n*   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)\\n*   [Sora](https://openai.com/index/sora-system-card/)\\n\\nSafety\\n*   [Safety Approach](https://openai.com/safety/)\\n*   [Security & Privacy](https://openai.com/security-and-privacy/)\\n*   [Trust & Transparency](https://openai.com/trust-and-transparency/)\\n\\nChatGPT\\n*   [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n*   [Business](https://chatgpt.com/business/business-plan?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n*   [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n*   [Education](https://chatgpt.com/business/education?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n*   [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n*   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=5265a2b7-b02f-4071-812e-251753cceda0&openaicom_referred=true)\\n\\nSora\\n*   [Sora Overview](https://openai.com/sora/)\\n*   [Features](https://openai.com/sora/#features)\\n*   [Pricing](https://openai.com/sora/#pricing)\\n*   [Sora log in(opens in a new window)](https://sora.com/)\\n\\nAPI Platform\\n*   [Platform Overview](https://openai.com/api/)\\n*   [Pricing](https://openai.com/api/pricing/)\\n*   [API log in(opens in a new window)](https://platform.openai.com/login)\\n*   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)\\n*   [Developer Forum(opens in a new window)](https://community.openai.com/)\\n\\nFor Business\\n*   [Business Overview](https://openai.com/business/)\\n*   [Solutions](https://openai.com/solutions/)\\n*   [Contact Sales](https://openai.com/contact-sales/)\\n\\nCompany\\n*   [About Us](https://openai.com/about/)\\n*   [Our Charter](https://openai.com/charter/)\\n*   [Foundation](https://openai.com/foundation/)\\n*   [Careers](https://openai.com/careers/)\\n*   [Brand](https://openai.com/brand/)\\n\\nSupport\\n*   [Help Center(opens in a new window)](https://help.openai.com/)\\n\\nMore\\n*   [News](https://openai.com/news/)\\n*   [Stories](https://openai.com/stories/)\\n*   [Livestreams](https://openai.com/live/)\\n*   [Podcast](https://openai.com/podcast/)\\n*   [RSS](https://openai.com/news/rss.xml)\\n\\nTerms & Policies\\n*   [Terms of Use](https://openai.com/policies/terms-of-use/)\\n*   [Privacy Policy](https://openai.com/policies/privacy-policy/)\\n*   [Other Policies](https://openai.com/policies/)\\n\\n[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)\\n\\nOpenAI © 2015–2026 Manage Cookies\\n\\nEnglish United States\"}, {\"url\": \"https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited\", \"title\": \"OpenAI's audio-first hardware product could launch this year, and I ...\", \"content\": \"In an interview with Axios, OpenAI's Chief Global Affairs Officer Chris Lehane said that the company is \\\"on track\\\" to reveal its first product in the second half of 2026. The confirmation is the closest thing we've gotten to a timeline for OpenAI hardware. The company, including its CEO Sam Altman, has been teasing an upcoming AI device, but details have been sparse.\\n\\n that mass production of the product was expected to begin in 2027.\\n\\n> My industry research indicates the following regarding the new AI hardware device from Jony Ive's collaboration with OpenAI:1. Mass production is expected to start in 2027.2. Assembly and shipping will occur outside China to reduce geopolitical risks, with Vietnam currently the… pic.twitter.com/5IELYEjNyVMay 22, 2025\\n\\nSee more [...] Leading us to the present day, The Information reported this month that OpenAI is strengthening its audio-based models as it nears closer to building its initial product. The product is expected to ship without displays and instead focus on voice input, explaining the audio focus.\\n\\nBe an expert in 5 minutes\\n\\nGet the latest news from Android Central, your trusted companion in the world of Android\\n\\n- [x] Contact me with news and offers from other Future brands - [x] Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.\\n\\nNow, we know that OpenAI's timeline might be moving up with a late 2026 reveal and the potential for 2027 availability. [...] Trending\\n   CES 2026\\n   AI: Everything you need to know\\n   Galaxy S26\\n   Pixel 10\\n   Pixel 10 Pro Fold\\n   Galaxy Z Fold 7\\n   Galaxy Z Flip 7\\n\\n1.   Apps & Software\\n2.   AI\\n\\nOpenAI's audio-first hardware product could launch this year, and I'm excited\\n\\nFeatures\\n\\n By Brady Snyder published 14 hours ago\\n\\nAn OpenAI executive confirmed the company's first product might be revealed later in 2026.\\n\\nWhen you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.\\n\\nImage 41: ChatGPT app on an Android phone\\n\\n(Image credit: Sanuj Bhatia / Android Central)\\n\\n Share \\n\\nShare by:\\n    Copy link \\n   Facebook\\n   X\\n   Whatsapp\\n   Pinterest\\n   Flipboard\\n\\n Share this article \\n\\n0\\n\\n Join the conversation \\n\\nFollow us\\n\\n Add us as a preferred source on Google\", \"score\": 0.81665546, \"raw_content\": \"OpenAI's audio-first hardware product could launch this year, and I'm excited | Android Central\\n===============\\n[Skip to main content](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited#main)\\n\\nOpen menu\\n\\n[![Image 2: Android Central](https://cdn.mos.cms.futurecdn.net/flexiimages/c8t5znsqpd1648225513.svg)Android Central](https://www.androidcentral.com/)\\n\\nUS Edition![Image 3: US Edition](https://vanilla.futurecdn.net/androidcentral/media/shared/img/flags/nosize/US.svg)\\n\\n[![Image 4: US Edition](https://vanilla.futurecdn.net/androidcentral/media/shared/img/flags/nosize/US.svg)US](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)[![Image 5: UK Edition](https://vanilla.futurecdn.net/androidcentral/media/shared/img/flags/nosize/GB.svg)UK](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)[![Image 6: AU Edition](https://vanilla.futurecdn.net/androidcentral/media/shared/img/flags/nosize/AU.svg)Australia](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)[![Image 7: CA Edition](https://vanilla.futurecdn.net/androidcentral/media/shared/img/flags/nosize/CA.svg)Canada](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)[![Image 8: IN Edition](https://vanilla.futurecdn.net/androidcentral/media/shared/img/flags/nosize/IN.svg)India](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)\\n\\n[](https://www.facebook.com/AndroidCentral/?utm_source=ac&utm_medium=burger&utm_campaign=navigation)[](https://twitter.com/androidcentral?utm_source=ac&utm_medium=burger&utm_campaign=navigation)[](https://www.youtube.com/user/AndroidCentral)[](https://www.instagram.com/androidcentral/?utm_source=ac&utm_medium=burger&utm_campaign=navigation)[](https://flipboard.com/@AndroidCentral)[RSS](https://www.androidcentral.com/feeds.xml)\\n\\nSign in\\n\\n*   View Profile\\n*   Sign out\\n\\n- [x] Search Search Android Central \\n\\n*   [](https://www.androidcentral.com/)\\n*   [CES 2026](https://www.androidcentral.com/tag/ces)\\n*   [Phones](https://www.androidcentral.com/phones)\\n    *    Phone Types \\n        *   [Flagship Phones](https://www.androidcentral.com/tag/flagship)\\n        *   [Foldable Phones](https://www.androidcentral.com/tag/foldable-phones)\\n        *   [Flip Phones](https://www.androidcentral.com/tag/flip-phones)\\n        *   [Unlocked Phones](https://www.androidcentral.com/unlocked-phones)\\n        *   [Budget Phones](https://www.androidcentral.com/tag/budget-phones)\\n\\n    *    Brands \\n        *   [Google Pixel](https://www.androidcentral.com/phones/google-pixel)\\n        *   [Samsung](https://www.androidcentral.com/phones/samsung-galaxy)\\n        *   [Motorola](https://www.androidcentral.com/phones/motorola)\\n        *   [Apple](https://www.androidcentral.com/tag/apple)\\n        *   [Nothing](https://www.androidcentral.com/phones/nothing-phones)\\n        *   [Oneplus](https://www.androidcentral.com/phones/oneplus)\\n        *   [Xiaomi](https://www.androidcentral.com/phones/xiaomi)\\n        *   [OPPO](https://www.androidcentral.com/phones/oppo-phones)\\n        *   [Honor](https://www.androidcentral.com/phones/honor-phones)\\n        *   [Qualcomm](https://www.androidcentral.com/phones/qualcomm)\\n        *   [MediaTek](https://www.androidcentral.com/phones/mediatek)\\n\\n    *   [Phone Accessories](https://www.androidcentral.com/accessories)\\n        *   [Cases & Screen Protectors](https://www.androidcentral.com/accessories/cases-screen-protectors)\\n\\n*   [Wearables](https://www.androidcentral.com/wearables)\\n    *   [Watches](https://www.androidcentral.com/wearables)\\n        *   [Pixel Watch](https://www.androidcentral.com/wearables/google-pixel-watch)\\n        *   [Galaxy Watch](https://www.androidcentral.com/wearables/samsung-galaxy-watch)\\n        *   [Garmin](https://www.androidcentral.com/wearables/garmin)\\n        *   [OnePlus Watch](https://www.androidcentral.com/phones/oneplus)\\n        *   [Coros](https://www.androidcentral.com/wearables/coros)\\n        *   [Polar](https://www.androidcentral.com/wearables/polar)\\n        *   [Amazfit](https://www.androidcentral.com/wearables/amazfit)\\n        *   [Watch Bands](https://www.androidcentral.com/accessories/watch-bands)\\n\\n    *   [Rings](https://www.androidcentral.com/tag/smart-ring)\\n        *   [Oura Ring](https://www.androidcentral.com/wearables/oura-ring)\\n        *   [Galaxy Ring](https://www.androidcentral.com/wearables/samsung-galaxy-ring)\\n        *   [Ringconn](https://www.androidcentral.com/wearables/ringconn)\\n\\n    *   [Glasses](https://www.androidcentral.com/tag/smart-glasses)\\n    *   [VR](https://www.androidcentral.com/gaming/virtual-reality)\\n        *   [Meta Quest](https://www.androidcentral.com/tag/meta-quest)\\n        *   [Galaxy XR](https://www.androidcentral.com/tag/samsung-galaxy-xr)\\n\\n*   [Laptops & Tablets](https://www.androidcentral.com/chromebooks-laptops)\\n    *   [Chromebooks](https://www.androidcentral.com/chromebooks-laptops)\\n        *   [Acer Chromebooks](https://www.androidcentral.com/tag/acer-chromebook)\\n        *   [Samsung Chromebooks](https://www.androidcentral.com/tag/samsung-galaxy-chromebook)\\n        *   [HP Chromebooks](https://www.androidcentral.com/tag/hp-chromebook)\\n\\n    *   [Tablets](https://www.androidcentral.com/tablets)\\n        *   [Samsung Galaxy Tab](https://www.androidcentral.com/tablets/samsung-galaxy-tab)\\n        *   [Fire Tablets](https://www.androidcentral.com/tablets/amazon-fire-tablet)\\n        *   [Google Pixel Tablet](https://www.androidcentral.com/tablets/google-pixel-tablet)\\n        *   [Lenovo](https://www.androidcentral.com/tablets/lenovo)\\n        *   [Boox](https://www.androidcentral.com/tablets/boox)\\n        *   [Kindle](https://www.androidcentral.com/tablets/kindle)\\n\\n*   [Apps & Software](https://www.androidcentral.com/apps-software)\\n    *    OS \\n        *   [Android OS](https://www.androidcentral.com/apps-software/android-os)\\n        *   [Wear OS](https://www.androidcentral.com/apps-software/wear-os)\\n        *   [Android XR](https://www.androidcentral.com/tag/android-xr)\\n\\n    *    Google \\n        *   [Gmail](https://www.androidcentral.com/apps-software/gmail)\\n        *   [Gemini](https://www.androidcentral.com/tag/gemini)\\n        *   [Google Maps](https://www.androidcentral.com/apps-software/google-maps)\\n        *   [Google Pay](https://www.androidcentral.com/apps-software/google-pay)\\n        *   [Google Play Store](https://www.androidcentral.com/apps-software/google-play-store)\\n        *   [Youtube](https://www.androidcentral.com/apps-software/youtube)\\n\\n    *    Software \\n        *   [Meta](https://www.androidcentral.com/apps-software/meta)\\n        *   [Android Auto](https://www.androidcentral.com/apps-software/android-auto)\\n\\n    *   [AI](https://www.androidcentral.com/apps-software/ai)\\n\\n*   [Accessories](https://www.androidcentral.com/accessories)\\n    *   [Smart Home](https://www.androidcentral.com/accessories/smart-home)\\n    *   [Storage](https://www.androidcentral.com/accessories/storage)\\n    *   [Power & Charging](https://www.androidcentral.com/accessories/power-charging)\\n    *   [Cases & Screen Protectors](https://www.androidcentral.com/accessories/cases-screen-protectors)\\n    *   [Watch Bands](https://www.androidcentral.com/accessories/watch-bands)\\n\\n*   [Audio](https://www.androidcentral.com/accessories/audio)\\n    *   [Earbuds](https://www.androidcentral.com/accessories/audio/earbuds)\\n    *   [Headphones](https://www.androidcentral.com/accessories/audio/headphones)\\n\\n*   [Deals](https://www.androidcentral.com/tag/deals)\\n    *    Retailers \\n        *   [Amazon Deals](https://www.androidcentral.com/phones/black-friday-amazon-deals-2025)\\n        *   [Best Buy Deals](https://www.androidcentral.com/phones/best-buy-black-friday-deals-2025)\\n        *   [Walmart Deals](https://www.androidcentral.com/phones/holiday-walmart-android-deals-last-chance-2025)\\n\\n    *    Phones & Tech \\n        *   [Pixel Deals](https://www.androidcentral.com/phones/google-pixel/best-google-pixel-deals-of-the-month-2026)\\n        *   [Motorola Deals](https://www.androidcentral.com/phones/motorola/black-friday-motorola-deals-2025)\\n        *   [Samsung Deals](https://www.androidcentral.com/phones/samsung-galaxy/best-samsung-galaxy-deals-of-the-month-2026)\\n        *   [Chromebook Deals](https://www.androidcentral.com/chromebooks-laptops/best-chromebook-deals-2026)\\n        *   [Garmin Deals](https://www.androidcentral.com/wearables/best-black-friday-garmin-deals-2025)\\n\\n    *    Buying Guides \\n        *   [Best Android Phones](https://www.androidcentral.com/best-android-phones)\\n        *   [Best Android Phones with SD Card Slot](https://www.androidcentral.com/best-android-phones-expandable-storage)\\n        *   [Best Chromebooks](https://www.androidcentral.com/best-chromebook)\\n        *   [Best Cheap Android Tablets](https://www.androidcentral.com/best-cheap-android-tablet)\\n        *   [Best Android Smartwatch](https://www.androidcentral.com/best-android-smartwatch)\\n        *   [Meta Quest 3 & Quest 3 Accessories](https://www.androidcentral.com/gaming/virtual-reality/best-meta-quest-3-accessories)\\n        *   [Best VR Headsets](https://www.androidcentral.com/gaming/virtual-reality/best-vr-headsets)\\n        *   [Best Wireless Earbuds](https://www.androidcentral.com/best-wireless-earbuds)\\n        *   [Best Noise Canceling Headphones](https://www.androidcentral.com/best-noise-canceling-headphones)\\n\\n*    More \\n        *   [](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)\\n\\n    *   [Deals](https://www.androidcentral.com/tag/deals)\\n    *   [About Us](https://www.androidcentral.com/about)\\n    *   [Forums](https://forums.androidcentral.com/)\\n    *   [News](https://www.androidcentral.com/news)\\n    *   [Reviews](https://www.androidcentral.com/reviews)\\n\\n*   [home](https://www.androidcentral.com/)\\n*   [CES 2026](https://www.androidcentral.com/tag/ces)\\n*   [Phones](https://www.androidcentral.com/phones)\\n    *   [View Phones](https://www.androidcentral.com/phones)\\n    *    Phone Types \\n        *   [Flagship Phones](https://www.androidcentral.com/tag/flagship)\\n        *   [Foldable Phones](https://www.androidcentral.com/tag/foldable-phones)\\n        *   [Flip Phones](https://www.androidcentral.com/tag/flip-phones)\\n        *   [Unlocked Phones](https://www.androidcentral.com/unlocked-phones)\\n        *   [Budget Phones](https://www.androidcentral.com/tag/budget-phones)\\n\\n    *    Brands \\n        *   [Google Pixel](https://www.androidcentral.com/phones/google-pixel)\\n        *   [Samsung](https://www.androidcentral.com/phones/samsung-galaxy)\\n        *   [Motorola](https://www.androidcentral.com/phones/motorola)\\n        *   [Apple](https://www.androidcentral.com/tag/apple)\\n        *   [Nothing](https://www.androidcentral.com/phones/nothing-phones)\\n        *   [Oneplus](https://www.androidcentral.com/phones/oneplus)\\n        *   [Xiaomi](https://www.androidcentral.com/phones/xiaomi)\\n        *   [OPPO](https://www.androidcentral.com/phones/oppo-phones)\\n        *   [Honor](https://www.androidcentral.com/phones/honor-phones)\\n        *   [Qualcomm](https://www.androidcentral.com/phones/qualcomm)\\n        *   [MediaTek](https://www.androidcentral.com/phones/mediatek)\\n\\n    *   [Phone Accessories](https://www.androidcentral.com/accessories)\\n        *   [View Phone Accessories](https://www.androidcentral.com/accessories)\\n        *   [Cases & Screen Protectors](https://www.androidcentral.com/accessories/cases-screen-protectors)\\n\\n*   [Wearables](https://www.androidcentral.com/wearables)\\n    *   [View Wearables](https://www.androidcentral.com/wearables)\\n    *   [Watches](https://www.androidcentral.com/wearables)\\n        *   [View Watches](https://www.androidcentral.com/wearables)\\n        *   [Pixel Watch](https://www.androidcentral.com/wearables/google-pixel-watch)\\n        *   [Galaxy Watch](https://www.androidcentral.com/wearables/samsung-galaxy-watch)\\n        *   [Garmin](https://www.androidcentral.com/wearables/garmin)\\n        *   [OnePlus Watch](https://www.androidcentral.com/phones/oneplus)\\n        *   [Coros](https://www.androidcentral.com/wearables/coros)\\n        *   [Polar](https://www.androidcentral.com/wearables/polar)\\n        *   [Amazfit](https://www.androidcentral.com/wearables/amazfit)\\n        *   [Watch Bands](https://www.androidcentral.com/accessories/watch-bands)\\n\\n    *   [Rings](https://www.androidcentral.com/tag/smart-ring)\\n        *   [View Rings](https://www.androidcentral.com/tag/smart-ring)\\n        *   [Oura Ring](https://www.androidcentral.com/wearables/oura-ring)\\n        *   [Galaxy Ring](https://www.androidcentral.com/wearables/samsung-galaxy-ring)\\n        *   [Ringconn](https://www.androidcentral.com/wearables/ringconn)\\n\\n    *   [Glasses](https://www.androidcentral.com/tag/smart-glasses)\\n    *   [VR](https://www.androidcentral.com/gaming/virtual-reality)\\n        *   [View VR](https://www.androidcentral.com/gaming/virtual-reality)\\n        *   [Meta Quest](https://www.androidcentral.com/tag/meta-quest)\\n        *   [Galaxy XR](https://www.androidcentral.com/tag/samsung-galaxy-xr)\\n\\n*   [Laptops & Tablets](https://www.androidcentral.com/chromebooks-laptops)\\n    *   [View Laptops & Tablets](https://www.androidcentral.com/chromebooks-laptops)\\n    *   [Chromebooks](https://www.androidcentral.com/chromebooks-laptops)\\n        *   [View Chromebooks](https://www.androidcentral.com/chromebooks-laptops)\\n        *   [Acer Chromebooks](https://www.androidcentral.com/tag/acer-chromebook)\\n        *   [Samsung Chromebooks](https://www.androidcentral.com/tag/samsung-galaxy-chromebook)\\n        *   [HP Chromebooks](https://www.androidcentral.com/tag/hp-chromebook)\\n\\n    *   [Tablets](https://www.androidcentral.com/tablets)\\n        *   [View Tablets](https://www.androidcentral.com/tablets)\\n        *   [Samsung Galaxy Tab](https://www.androidcentral.com/tablets/samsung-galaxy-tab)\\n        *   [Fire Tablets](https://www.androidcentral.com/tablets/amazon-fire-tablet)\\n        *   [Google Pixel Tablet](https://www.androidcentral.com/tablets/google-pixel-tablet)\\n        *   [Lenovo](https://www.androidcentral.com/tablets/lenovo)\\n        *   [Boox](https://www.androidcentral.com/tablets/boox)\\n        *   [Kindle](https://www.androidcentral.com/tablets/kindle)\\n\\n*   [Apps & Software](https://www.androidcentral.com/apps-software)\\n    *   [View Apps & Software](https://www.androidcentral.com/apps-software)\\n    *    OS \\n        *   [Android OS](https://www.androidcentral.com/apps-software/android-os)\\n        *   [Wear OS](https://www.androidcentral.com/apps-software/wear-os)\\n        *   [Android XR](https://www.androidcentral.com/tag/android-xr)\\n\\n    *    Google \\n        *   [Gmail](https://www.androidcentral.com/apps-software/gmail)\\n        *   [Gemini](https://www.androidcentral.com/tag/gemini)\\n        *   [Google Maps](https://www.androidcentral.com/apps-software/google-maps)\\n        *   [Google Pay](https://www.androidcentral.com/apps-software/google-pay)\\n        *   [Google Play Store](https://www.androidcentral.com/apps-software/google-play-store)\\n        *   [Youtube](https://www.androidcentral.com/apps-software/youtube)\\n\\n    *    Software \\n        *   [Meta](https://www.androidcentral.com/apps-software/meta)\\n        *   [Android Auto](https://www.androidcentral.com/apps-software/android-auto)\\n\\n    *   [AI](https://www.androidcentral.com/apps-software/ai)\\n\\n*   [Accessories](https://www.androidcentral.com/accessories)\\n    *   [View Accessories](https://www.androidcentral.com/accessories)\\n    *   [Smart Home](https://www.androidcentral.com/accessories/smart-home)\\n    *   [Storage](https://www.androidcentral.com/accessories/storage)\\n    *   [Power & Charging](https://www.androidcentral.com/accessories/power-charging)\\n    *   [Cases & Screen Protectors](https://www.androidcentral.com/accessories/cases-screen-protectors)\\n    *   [Watch Bands](https://www.androidcentral.com/accessories/watch-bands)\\n\\n*   [Audio](https://www.androidcentral.com/accessories/audio)\\n    *   [View Audio](https://www.androidcentral.com/accessories/audio)\\n    *   [Earbuds](https://www.androidcentral.com/accessories/audio/earbuds)\\n    *   [Headphones](https://www.androidcentral.com/accessories/audio/headphones)\\n\\n*   [Deals](https://www.androidcentral.com/tag/deals)\\n    *   [View Deals](https://www.androidcentral.com/tag/deals)\\n    *    Retailers \\n        *   [Amazon Deals](https://www.androidcentral.com/phones/black-friday-amazon-deals-2025)\\n        *   [Best Buy Deals](https://www.androidcentral.com/phones/best-buy-black-friday-deals-2025)\\n        *   [Walmart Deals](https://www.androidcentral.com/phones/holiday-walmart-android-deals-last-chance-2025)\\n\\n    *    Phones & Tech \\n        *   [Pixel Deals](https://www.androidcentral.com/phones/google-pixel/best-google-pixel-deals-of-the-month-2026)\\n        *   [Motorola Deals](https://www.androidcentral.com/phones/motorola/black-friday-motorola-deals-2025)\\n        *   [Samsung Deals](https://www.androidcentral.com/phones/samsung-galaxy/best-samsung-galaxy-deals-of-the-month-2026)\\n        *   [Chromebook Deals](https://www.androidcentral.com/chromebooks-laptops/best-chromebook-deals-2026)\\n        *   [Garmin Deals](https://www.androidcentral.com/wearables/best-black-friday-garmin-deals-2025)\\n\\n    *    Buying Guides \\n        *   [Best Android Phones](https://www.androidcentral.com/best-android-phones)\\n        *   [Best Android Phones with SD Card Slot](https://www.androidcentral.com/best-android-phones-expandable-storage)\\n        *   [Best Chromebooks](https://www.androidcentral.com/best-chromebook)\\n        *   [Best Cheap Android Tablets](https://www.androidcentral.com/best-cheap-android-tablet)\\n        *   [Best Android Smartwatch](https://www.androidcentral.com/best-android-smartwatch)\\n        *   [Meta Quest 3 & Quest 3 Accessories](https://www.androidcentral.com/gaming/virtual-reality/best-meta-quest-3-accessories)\\n        *   [Best VR Headsets](https://www.androidcentral.com/gaming/virtual-reality/best-vr-headsets)\\n        *   [Best Wireless Earbuds](https://www.androidcentral.com/best-wireless-earbuds)\\n        *   [Best Noise Canceling Headphones](https://www.androidcentral.com/best-noise-canceling-headphones)\\n\\n*    More \\n    *   [About Us](https://www.androidcentral.com/about)\\n    *   [Forums](https://forums.androidcentral.com/)\\n    *   [News](https://www.androidcentral.com/news)\\n    *   [Reviews](https://www.androidcentral.com/reviews)\\n\\nDon't miss these\\n\\n[![Image 9: Apple&#039;s Chief Design OfficerJony Ive speaks onstage during the 2017 New Yorker TechFest at Cedar Lake on October 6, 2017 in New York City. ](https://cdn.mos.cms.futurecdn.net/XNvMpkCUtke3gWwXK9od5U.jpg)![Image 10](https://www.androidcentral.com/media/shared/img/logos/white/windowscentral.svg) Artificial Intelligence OpenAI is one step closer to launching its next-gen AI hardware](https://www.windowscentral.com/artificial-intelligence/jony-ive-and-sam-altman-confirm-openai-finally-has-a-prototype-for-its-super-secret-ai-device-set-to-launch-in-less-than-2-years \\\"OpenAI is one step closer to launching its next-gen AI hardware\\\")\\n\\n[![Image 11: Jony Ive and Sam Altman](https://cdn.mos.cms.futurecdn.net/o3fZbP7CRSPBqyzSX9nZPW.jpg)![Image 12](https://www.techradar.com/media/img/techradar_logo_v2.svg) ChatGPT 2026 could be the year we move beyond smartphones](https://www.techradar.com/ai-platforms-assistants/chatgpt/2026-could-be-the-year-we-move-beyond-smartphones-led-by-a-sam-altman-and-jony-ive-designed-ai-device \\\"2026 could be the year we move beyond smartphones\\\")\\n\\n[![Image 13: AirPods Pro 3](https://cdn.mos.cms.futurecdn.net/Hfk4whZfbRUQkweEGA87QS.jpg)![Image 14](https://www.tomsguide.com/media/img/TG_logo.svg) AI AirPods killer? OpenAI’s massive hardware leak targets Apple’s earbuds](https://www.tomsguide.com/ai/a-special-audio-product-to-replace-airpod-leak-points-to-openai-developing-ai-powered-audio-earbuds-that-rivals-apples \\\"AirPods killer? OpenAI’s massive hardware leak targets Apple’s earbuds\\\")\\n\\n[![Image 15: OpenAI CEO Sam Altman attends the artificial intelligence(AI) Revolution Forum in Taipei on September 25, 2023. ](https://cdn.mos.cms.futurecdn.net/nhp7GWCzArkmdSZsczRzTS.jpg)![Image 16](https://www.techradar.com/media/img/techradar_logo_v2.svg) AI Platforms & Assistants Sam Altman says his new AI device should feel like a \\\"cabin by a lake\\\"](https://www.techradar.com/ai-platforms-assistants/sam-altman-and-jony-ive-ai-device-is-now-in-its-prototype-phase-and-its-vibe-is-defined \\\"Sam Altman says his new AI device should feel like a \\\\\\\"cabin by a lake\\\\\\\"\\\")\\n\\n[![Image 17: iPod Shuffle](https://cdn.mos.cms.futurecdn.net/6TqgTVRxuDaxceRnFXGP74.jpg)![Image 18](https://www.creativebloq.com/media/img/creativebloq_logo.png) Product Design I already hate OpenAI's 'iPhone killer' device](https://www.creativebloq.com/design/product-design/i-already-hate-openais-iphone-killer-device \\\"I already hate OpenAI's 'iPhone killer' device\\\")\\n\\n[![Image 19: Android XR prototype glasses in front of a Pixel smartphone](https://cdn.mos.cms.futurecdn.net/jLhj4f6aBKDJry7HKGwgh8.jpg) AI What I want to see from AI in 2026, from Samsung glasses to OpenAI hardware](https://www.androidcentral.com/apps-software/ai/ai-in-2025-what-we-expect-want-to-see \\\"What I want to see from AI in 2026, from Samsung glasses to OpenAI hardware\\\")\\n\\n[![Image 20: Rabbit R1](https://cdn.mos.cms.futurecdn.net/QFyX6JydCULDNbUsw9JXGT.jpg)![Image 21](https://www.tomsguide.com/media/img/TG_logo.svg) AI Rabbit's next-gen AI hardware is coming next year to take on OpenAI, and the CEO just teased what to expect](https://www.tomsguide.com/ai/rabbits-next-gen-ai-hardware-is-coming-next-year-to-take-on-openai-and-the-ceo-just-teased-what-to-expect \\\"Rabbit's next-gen AI hardware is coming next year to take on OpenAI, and the CEO just teased what to expect\\\")\\n\\n[![Image 22: Altman and Ive AI device talk](https://cdn.mos.cms.futurecdn.net/yutDmnHiCQt79poxu7x7fQ.png)![Image 23](https://www.androidcentral.com/media/shared/img/logos/white/pcgamer.svg) Hardware Sam Altman says the prototype AI 'thing' he's making with Jony Ive gives the 'vibe' of 'sitting in the most beautiful cabin by a lake in the mountains' and I'm left wondering if he's ever listened to the noises coming out of the hole under his nose](https://www.pcgamer.com/hardware/sam-altman-says-the-prototype-ai-thing-hes-making-with-jony-ive-gives-the-vibe-of-sitting-in-the-most-beautiful-cabin-by-a-lake-in-the-mountains-and-im-left-wondering-if-hes-ever-listened-to-the-noises-coming-out-of-the-hole-under-his-nose \\\"Sam Altman says the prototype AI 'thing' he's making with Jony Ive gives the 'vibe' of 'sitting in the most beautiful cabin by a lake in the mountains' and I'm left wondering if he's ever listened to the noises coming out of the hole under his nose\\\")\\n\\n[![Image 24: Sam Altman](https://cdn.mos.cms.futurecdn.net/msLNQTh5u5KMjbochKRhFM.jpg)![Image 25](https://www.tomsguide.com/media/img/TG_logo.svg) AI OpenAI rivals Elon Musk's Neuralink with planned brain computer interface — here's everything you need to know](https://www.tomsguide.com/ai/openai-is-reportedly-building-a-brain-interface-but-plenty-of-others-have-tried-before \\\"OpenAI rivals Elon Musk's Neuralink with planned brain computer interface — here's everything you need to know\\\")\\n\\n[![Image 26: Sam Altman](https://cdn.mos.cms.futurecdn.net/smrJZqq5RNy4rVJJtkXpdT.jpg)![Image 27](https://www.techradar.com/media/img/techradar_logo_v2.svg) ChatGPT OpenAI roadmap revealed: AI research interns by 2026, full-blown AGI researchers by 2028](https://www.techradar.com/ai-platforms-assistants/chatgpt/openai-roadmap-revealed-ai-research-interns-by-2026-full-blown-agi-researchers-by-2028 \\\"OpenAI roadmap revealed: AI research interns by 2026, full-blown AGI researchers by 2028\\\")\\n\\n[![Image 28: Sam Altman](https://cdn.mos.cms.futurecdn.net/83sSaiTjjFDMm5hGE9NcyL.jpg)![Image 29](https://www.techradar.com/media/img/techradar_logo_v2.svg) OpenAI The ChatGPT AI device could end up being a pen, a new leak says](https://www.techradar.com/ai-platforms-assistants/openai/openais-mysterious-chatgpt-gadget-could-take-the-form-of-an-ai-powered-pen \\\"The ChatGPT AI device could end up being a pen, a new leak says\\\")\\n\\n[![Image 30: Sam Altman at a press conference](https://cdn.mos.cms.futurecdn.net/KGWyF3dyBe4w8auMoitrBA.jpg)![Image 31](https://www.tomsguide.com/media/img/TG_logo.svg) AI OpenAI live blog - Sam Altman hosts AMA: Time, how to watch, and how to submit questions](https://www.tomsguide.com/live/news/openai-event-live-sam-altman-october-ama \\\"OpenAI live blog - Sam Altman hosts AMA: Time, how to watch, and how to submit questions\\\")\\n\\n[![Image 32: Apple AirPods Pro 3 in use](https://cdn.mos.cms.futurecdn.net/FVw528Ueika7ExeLdvZUf.jpg)![Image 33](https://cdn.mos.cms.futurecdn.net/flexiimages/muyd8brflw1729511975.svg) Earbuds Apple AirPods could be getting new rival earbuds from... hold on... ChatGPT owner OpenAI](https://www.t3.com/tech/earbuds/apple-airpods-could-be-getting-new-rival-earbuds-from-hold-on-chatgpt-owner-openai \\\"Apple AirPods could be getting new rival earbuds from... hold on... ChatGPT owner OpenAI\\\")\\n\\n[![Image 34: Apple products against a cream background](https://cdn.mos.cms.futurecdn.net/xPov5ZRp3YhDJtuPnPaBjP.jpg)![Image 35](https://www.techradar.com/media/img/techradar_logo_v2.svg) Phones Apple could have a huge 2026 with these upcoming products – here’s what to expect](https://www.techradar.com/phones/apple-could-have-a-huge-2026-with-these-upcoming-products-heres-what-to-expect \\\"Apple could have a huge 2026 with these upcoming products – here’s what to expect\\\")\\n\\n[![Image 36: Amazon Alexa+ graphic ](https://cdn.mos.cms.futurecdn.net/ENcHRNWoHMSJgLLu7xM6sh.jpg)![Image 37](https://www.tomsguide.com/media/img/TG_logo.svg) AI I asked the VP of Alexa+ about Amazon's AI coming to new smart glasses — 'You’re going to hear things from us in 2026'](https://www.tomsguide.com/ai/i-asked-the-vp-of-alexa-about-amazons-ai-coming-to-new-smart-glasses-youre-going-to-hear-things-from-us-in-2026 \\\"I asked the VP of Alexa+ about Amazon's AI coming to new smart glasses — 'You’re going to hear things from us in 2026'\\\")\\n\\nYOUR NEXT READ:\\n---------------\\n\\n[![Image 38: A photo of the XREAL Project Aura glasses sitting on a plastic pedestal, with dark lenses and a cord connected to a computing device with trackpad.](https://cdn.mos.cms.futurecdn.net/ZMnVe2ZdCf8TYieDQSfoKZ.jpg) 1 ### Sneak peek: Google’s Android XR glasses app shows off AI features, camera, and display options](https://www.androidcentral.com/gaming/virtual-reality/sneak-peek-googles-android-xr-glasses-app-leaks)[![Image 39: A close-up photo of the Meta Ray-Ban Display glasses held facing the camera to show the design, camera cutouts, and lenses.](https://cdn.mos.cms.futurecdn.net/dKQz3aLAYpWp5qsFRU2ebm.jpg) 2 ### What the new Meta Ray-Ban Display features and a delayed international launch tell us about smart display glasses](https://www.androidcentral.com/apps-software/meta/meta-ray-ban-display-updates-ces-2026)[![Image 40: A photo of the XREAL Project Aura glasses sitting on a plastic pedestal, with dark lenses and a cord connected to a computing device with trackpad.](https://cdn.mos.cms.futurecdn.net/ZMnVe2ZdCf8TYieDQSfoKZ.jpg) 3 ### Google is betting on Xreal to make Android XR glasses mainstream](https://www.androidcentral.com/gaming/virtual-reality/google-is-betting-on-xreal-to-make-android-xr-glasses-mainstream)\\n\\nTrending\\n*   [CES 2026](https://www.androidcentral.com/tag/ces)\\n*   [AI: Everything you need to know](https://www.androidcentral.com/apps-software/ai/ai-in-motion-the-road-to-ai-and-the-future-of-mobile)\\n*   [Galaxy S26](https://www.androidcentral.com/phones/samsung-galaxy-s26-your-ultimate-guide)\\n*   [Pixel 10](https://www.androidcentral.com/phones/google-pixel-10)\\n*   [Pixel 10 Pro Fold](https://www.androidcentral.com/phones/google-pixel-10-pro-fold)\\n*   [Galaxy Z Fold 7](https://www.androidcentral.com/phones/samsung-galaxy-z-fold-7-and-z-flip-7-your-ultimate-guide)\\n*   [Galaxy Z Flip 7](https://www.androidcentral.com/phones/samsung-galaxy-z-fold-7-and-z-flip-7-your-ultimate-guide)\\n\\n1.   [Apps & Software](https://www.androidcentral.com/apps-software)\\n2.   [AI](https://www.androidcentral.com/apps-software/ai)\\n\\nOpenAI's audio-first hardware product could launch this year, and I'm excited\\n=============================================================================\\n\\n[Features](https://www.androidcentral.com/features)\\n\\n By [Brady Snyder](https://www.androidcentral.com/author/brady-snyder) published 14 hours ago\\n\\nAn OpenAI executive confirmed the company's first product might be revealed later in 2026.\\n\\nWhen you purchase through links on our site, we may earn an affiliate commission. [Here’s how it works](https://www.androidcentral.com/about).\\n\\n![Image 41: ChatGPT app on an Android phone](https://cdn.mos.cms.futurecdn.net/2dAidsg3greDHeqFxASwSY.jpg)\\n\\n(Image credit: Sanuj Bhatia / Android Central)\\n\\n Share \\n\\nShare by:\\n*    Copy link \\n*   [Facebook](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.androidcentral.com%2Fapps-software%2Fai%2Fopenais-audio-first-hardware-product-could-launch-this-year-and-im-excited)\\n*   [X](https://twitter.com/intent/tweet?text=OpenAI%27s+audio-first+hardware+product+could+launch+this+year%2C+and+I%27m+excited&url=https%3A%2F%2Fwww.androidcentral.com%2Fapps-software%2Fai%2Fopenais-audio-first-hardware-product-could-launch-this-year-and-im-excited)\\n*   [Whatsapp](whatsapp://send?text=OpenAI%27s+audio-first+hardware+product+could+launch+this+year%2C+and+I%27m+excited+https%3A%2F%2Fwww.androidcentral.com%2Fapps-software%2Fai%2Fopenais-audio-first-hardware-product-could-launch-this-year-and-im-excited?fwa)\\n*   [Pinterest](https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fwww.androidcentral.com%2Fapps-software%2Fai%2Fopenais-audio-first-hardware-product-could-launch-this-year-and-im-excited&media=https%3A%2F%2Fcdn.mos.cms.futurecdn.net%2F2dAidsg3greDHeqFxASwSY.jpg)\\n*   [Flipboard](https://share.flipboard.com/bookmarklet/popout?title=OpenAI%27s+audio-first+hardware+product+could+launch+this+year%2C+and+I%27m+excited&url=https%3A%2F%2Fwww.androidcentral.com%2Fapps-software%2Fai%2Fopenais-audio-first-hardware-product-could-launch-this-year-and-im-excited)\\n\\n Share this article \\n\\n[0](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited#viafoura-comments)\\n\\n Join the conversation \\n\\n[Follow us](https://google.com/preferences/source?q=androidcentral.com)\\n\\n Add us as a preferred source on Google \\n\\n[OpenAI](https://www.androidcentral.com/tag/openai) is building up an arsenal of design talent as it develops its first hardware product. The company acquired famed [Apple](https://www.androidcentral.com/tag/apple) designer Jony Ive's startup \\\"io\\\" in a $6.5 billion deal last year. The design lead behind the iPhone and more, plus his entire team, is now under OpenAI's roof working on an innovative hardware product. Now, we have a better idea of when OpenAI actually plans to unveil and release this secretive AI-powered device.\\n\\nIn an interview with [Axios](https://www.axios.com/2026/01/19/openai-device-2026-lehane-jony-ive), OpenAI's Chief Global Affairs Officer Chris Lehane said that the company is \\\"on track\\\" to reveal its first product in the second half of 2026. The confirmation is the closest thing we've gotten to a timeline for OpenAI hardware. The company, including its CEO Sam Altman, has been teasing an upcoming AI device, but details have been sparse.\\n\\n[](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)\\nNotably, Lehane wouldn't commit to OpenAI's hardware product being available for purchase this year — we might see a reveal in 2026 and general availability in 2027. The OpenAI policy leader added that the company was \\\"looking at something in the latter part [of 2026],\\\" per the report.\\n\\nLatest Videos From Android Central\\n\\nOneplus 13 review | Android Central\\n\\nOnePlus got everything right with the OnePlus 13 by fixing old problems and breaking new ground in design, build quality, and cameras.\\n\\n0 seconds of 1 minute, 4 seconds Volume 0%\\n\\nPress shift question mark to access a list of keyboard shortcuts\\n\\nKeyboard Shortcuts Enabled Disabled\\n\\nShortcuts Open/Close/ or ?\\n\\nPlay/Pause SPACE\\n\\nIncrease Volume↑\\n\\nDecrease Volume↓\\n\\nSeek Forward→\\n\\nSeek Backward←\\n\\nCaptions On/Off c\\n\\nFullscreen/Exit Fullscreen f\\n\\nMute/Unmute m\\n\\nDecrease Caption Size-\\n\\nIncrease Caption Size+ or =\\n\\nSeek %0-9\\n\\n facebook x Email\\n\\n Link\\n\\nCopied\\n\\nLive\\n\\n00:00\\n\\n01:04\\n\\n01:04\\n\\n You may like \\n*   [![Image 42: OpenAI rolls out ChatGPT Search to a limited number of users before expanding.](https://cdn.mos.cms.futurecdn.net/DQerZJ88mwuGHLyDbPsqkM-840-80.jpg)OpenAI's first steps into AI hardware leaks, and it looks like a pair of earbuds](https://www.androidcentral.com/accessories/earbuds/openais-first-steps-into-ai-hardware-leaks-and-it-looks-like-a-pair-of-earbuds)\\n*   [![Image 43: Android XR prototype glasses in front of a Pixel smartphone](https://cdn.mos.cms.futurecdn.net/jLhj4f6aBKDJry7HKGwgh8-840-80.jpg)What I want to see from AI in 2026, from Samsung glasses to OpenAI hardware](https://www.androidcentral.com/apps-software/ai/ai-in-2025-what-we-expect-want-to-see)\\n*   [![Image 44: A photo of the Google Logo surrounded by plants at the company&#039;s NYC headquarters building](https://cdn.mos.cms.futurecdn.net/ZQy35xwU77WcDvb9Gkc6AF-840-80.jpg)Google in 2026: From foundational gains to future expectations](https://www.androidcentral.com/phones/google-pixel/google-in-2026-what-we-expect-want-to-see)\\n*   [![Image 45: The Motorola Project Maxwell pin hanging off a necklace, worn by a woman.](https://cdn.mos.cms.futurecdn.net/KPbirBC7ayEAk8MkxNK3AT-840-80.jpg)Tech brands think AI is ready to 'know everything about you.' Is that what we want?](https://www.androidcentral.com/wearables/ces-2026-laid-out-black-mirror-future-of-wearable-ai-thats-always-listening-and-knows-everything-about-you)\\n\\nInformation regarding OpenAI's mysterious entry into consumer hardware products has been slowly trickling out since the May 2025 announcement. The [Wall Street Journal](https://www.wsj.com/tech/ai/what-sam-altman-told-openai-about-the-secret-device-hes-making-with-jony-ive-f1384005?st=RUGPjK&reflink=desktopwebshare_permalink&AID=15734583&PID=6147232&SID=mklr8p92du0023dg0023y&subid=Sovrn+Inc&cjevent=b9c059dbf58811f083a301250a1eba8e&tier_1=affiliate&tier_2=moa&tier_3=Sovrn+Inc&tier_4=2470763&tier_5=https%3A%2F%2Fwww.wsj.com%2Ftech%2Fai%2Fwhat-sam-altman-told-openai-about-the-secret-device-hes-making-with-jony-ive-f1384005%3Fst%3DRUGPjK%26reflink%3Ddesktopwebshare_permalink) reported that Altman told OpenAI employees that he and Ive plan to ship 100 million of these products. The report notes that Altman described the opportunity as having the potential to be \\\"the biggest thing we've ever done as a company here.\\\"\\n\\nShortly after, industry analyst Ming-Chi Kuo [claimed in a post on X (formerly Twitter)](https://x.com/mingchikuo/status/1925543472993321066) that mass production of the product was expected to begin in 2027.\\n\\n> My industry research indicates the following regarding the new AI hardware device from Jony Ive's collaboration with OpenAI:1. Mass production is expected to start in 2027.2. Assembly and shipping will occur outside China to reduce geopolitical risks, with Vietnam currently the… pic.twitter.com/5IELYEjNyV[May 22, 2025](https://twitter.com/cantworkitout/status/1925543472993321066)\\n\\nSee more\\n\\nMore recently, Altman and Ive confirmed they had prototypes of the upcoming product and expected to start building it within two years, the duo said in November 2026 at Emerson Collective's Demo Day (via [9to5Mac](https://9to5mac.com/2025/11/24/laurene-powell-jobs-interviews-jony-ive-and-sam-altman-about-mysterious-ai-hardware/)).\\n\\n> Finally, we have the first prototypes. I can’t believe how jaw-droppingly good the work is and how exciting it is. But also, now getting to the benefit of hindsight and looking at the progress — the process backwards — how much it’s all in there and how it wouldn’t have worked any other way. And then out of the end of it comes this extraordinary thing.\\n> \\n> \\n> \\n> Sam Altman, OpenAI CEO\\n\\nLeading us to the present day, [The Information](https://go.redirectingat.com/?id=92X1690538&xcust=ac_us_1274118554338730712&xs=1&url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fopenai-ramps-audio-ai-efforts-ahead-device%3Fim_ref%3DSS3QnASnRxycUVXQwTWmgVe1UkpSjz313T%253ArQk0%26sharedid%3D%26irpid%3D27795%26utm_term%3D%26irgwc%3D1%26afsrc%3D1%26utm_source%3Daffiliate%26utm_medium%3Dcpa%26utm_campaign%3D27795-Sovrn%2BCommerce&sref=https%3A%2F%2Fwww.androidcentral.com%2Fapps-software%2Fai%2Fopenais-audio-first-hardware-product-could-launch-this-year-and-im-excited) reported this month that OpenAI is strengthening its audio-based models as it nears closer to building its initial product. The product is expected to ship without displays and instead focus on voice input, explaining the audio focus.\\n\\nBe an expert in 5 minutes\\n\\nGet the latest news from Android Central, your trusted companion in the world of Android\\n\\n- [x] Contact me with news and offers from other Future brands - [x] Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the [Terms & Conditions](https://futureplc.com/terms-conditions/) and [Privacy Policy](https://futureplc.com/privacy-policy/) and are aged 16 or over.\\n\\nNow, we know that OpenAI's timeline might be moving up with a late 2026 reveal and the potential for 2027 availability.\\n\\n[](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited)\\nWhy I think OpenAI's first product is worth watching\\n----------------------------------------------------\\n\\n![Image 46: Humane AI Pin lifestyle](https://cdn.mos.cms.futurecdn.net/qg7zgqqYynueYAgqoPHbsb.jpg)\\n\\nThe now-defunct Humane AI Pin in a press image. (Image credit: Humane)\\n\\nOpenAI's debut hardware product is inching closer to becoming a reality, and that's exciting for tech enthusiasts. We really haven't seen an innovative new form factor find success since the smartphone and the smartwatch. Other emerging wearables, like earbuds and smart glasses, are making noise — but they're far from becoming ubiquitous. Does OpenAI's first consumer product have the potential to change that?\\n\\nWe don't know enough about OpenAI's plans to know for sure. However, the company seems fixed in its position that it will focus on an audio-based device, and that gives me confidence. Screen-based consumer technology products will always compete with existing form factors, like smartphones and smartwatches, which is an uphill battle.\\n\\nThat's true even of products that think outside the box in their implementation of displays, like Humane's AI Pin. That now-discontinued device used a tiny projector to display images on your hand. At the end of the day, a screen is still a screen. Humane's once-hyped AI product fizzled out very quickly, leaving early adopters high and dry.\\n\\nIt's a similar story for the Rabbit R1, another screen-based AI device that never caught on. To Rabbit's credit, the company is still supporting the device and recently overhauled the operating system. Even with that in mind, we're not likely to see the Rabbit R1 — or anything similar — disrupt the smartphone or smartwatch form factor.\\n\\n![Image 47: Vision mode on the Rabbit R1](https://cdn.mos.cms.futurecdn.net/vx3szA693pWtxFHKPmofqP.jpg)\\n\\n(Image credit: Andrew Myrick / Android Central)\\n\\nMeanwhile, it feels like audio-based devices still have room to grow. [AI voice recorders are finding a niche in the business world](https://www.androidcentral.com/accessories/i-used-plaud-note-ai-note-taking-device-and-its-much-better-than-i-imagined-but-theres-an-issue) despite [offering the same functionality as your smartphone](https://www.androidcentral.com/apps-software/ai/i-wore-an-ai-voice-recorder-on-my-wrist-for-a-week-heres-how-it-went). Earbuds are slowly becoming AI devices with [features like Live Translate](https://www.androidcentral.com/apps-software/ai/airpods-pro-3-vs-google-pixel-buds-pro-2-best-for-live-translate). Companies continue to experiment with unique form factors for audio gear, from [open earbuds](https://www.androidcentral.com/accessories/earbuds/best-open-ear-earbuds) and bone-conduction headphones to [pillow speakers](https://www.androidcentral.com/accessories/audio/jabees-peace-pillow-speaker-sleep-experiment).\\n\\nConsumers are voting with their wallets, telling companies that they want more audio products. OpenAI seems to be listening and rising to the occasion. The company confirmed an audio focus for its upcoming product, and [leaks suggest it could take the form of earbuds](https://www.androidcentral.com/accessories/earbuds/openais-first-steps-into-ai-hardware-leaks-and-it-looks-like-a-pair-of-earbuds).\\n\\nThe teasers, leaks, and rumors all point to the same thing. OpenAI is putting its hardware efforts in the right direction, avoiding screen-based devices that'll always lose against the smartphone. Instead, it's supposedly leaning into audio, and it sounds like a winning strategy. Based on today's announcement, we might learn more about what this product might look like later this year.\\n\\nTOPICS\\n\\n[OpenAI](https://www.androidcentral.com/tag/openai)[ChatGPT](https://www.androidcentral.com/tag/chatgpt)\\n\\n![Image 48: Brady Snyder](https://cdn.mos.cms.futurecdn.net/zbABvZgyoU7XuT35T69coJ.jpeg)\\n\\n[Brady Snyder](https://www.androidcentral.com/author/brady-snyder)\\n\\nSocial Links Navigation\\n\\n[](https://www.twitter.com/@BradyPSnyder)[](mailto:bradypsnyder@gmail.com)\\n\\nContributor\\n\\nBrady is a tech journalist for Android Central, with a focus on news, phones, tablets, audio, wearables, and software. He has spent the last three years reporting and commenting on all things related to consumer technology for various publications. Brady graduated from St. John's University with a bachelor's degree in journalism. His work has been published in XDA, Android Police, Tech Advisor, iMore, Screen Rant, and Android Headlines. When he isn't experimenting with the latest tech, you can find Brady running or watching Big East basketball.\\n\\nShow More Comments\\n\\nYou must confirm your public display name before commenting\\n\\nPlease logout and then login again, you will then be prompted to enter your display name.\\n\\n Logout \\n\\nRead more\\n\\n[![Image 49: Android XR prototype glasses in front of a Pixel smartphone](https://cdn.mos.cms.futurecdn.net/jLhj4f6aBKDJry7HKGwgh8.jpg) What I want to see from AI in 2026, from Samsung glasses to OpenAI hardware](https://www.androidcentral.com/apps-software/ai/ai-in-2025-what-we-expect-want-to-see \\\"What I want to see from AI in 2026, from Samsung glasses to OpenAI hardware\\\")\\n\\n[![Image 50: A photo of the Google Logo surrounded by plants at the company&#039;s NYC headquarters building](https://cdn.mos.cms.futurecdn.net/ZQy35xwU77WcDvb9Gkc6AF.jpg) Google in 2026: From foundational gains to future expectations](https://www.androidcentral.com/phones/google-pixel/google-in-2026-what-we-expect-want-to-see \\\"Google in 2026: From foundational gains to future expectations\\\")\\n\\n[![Image 51: The Motorola Project Maxwell pin hanging off a necklace, worn by a woman.](https://cdn.mos.cms.futurecdn.net/KPbirBC7ayEAk8MkxNK3AT.jpg) Tech brands think AI is ready to 'know everything about you.' Is that what we want?](https://www.androidcentral.com/wearables/ces-2026-laid-out-black-mirror-future-of-wearable-ai-thats-always-listening-and-knows-everything-about-you \\\"Tech brands think AI is ready to 'know everything about you.' Is that what we want?\\\")\\n\\n[![Image 52: Xiaomi Redmi Pad 2 Pro charging lifestyle](https://cdn.mos.cms.futurecdn.net/FfBYQBEBUHTeZ6zdLLkoc6.jpg) GenAI is emerging, and it could make the phone's form factor feel irrelevant](https://www.androidcentral.com/apps-software/android-os/genai-is-emerging-and-it-could-make-the-phones-form-factor-less-important \\\"GenAI is emerging, and it could make the phone's form factor feel irrelevant \\\")\\n\\n[![Image 53: Using the new Gemini 3 and Nano Banana Pro models in the Gemini app. ](https://cdn.mos.cms.futurecdn.net/WgvMUEtiWjgH7Rio2m2Kub.jpg) The state of AI in 2025: How Google, Apple, OpenAI, and others fared](https://www.androidcentral.com/apps-software/ai/ai-2025-report-card \\\"The state of AI in 2025: How Google, Apple, OpenAI, and others fared\\\")\\n\\n[![Image 54: Bose QuietComfort Ultra Gen 2 headset testing on Android Central](https://cdn.mos.cms.futurecdn.net/cHhbzKkUiExRp4acTFySvF.jpg) What I want to see from headphones, earbuds, and the audio industry in 2026](https://www.androidcentral.com/accessories/audio/consumer-audio-industry-2026-what-we-expect-want-to-see \\\"What I want to see from headphones, earbuds, and the audio industry in 2026\\\")\\n\\nLatest in AI\\n\\n[![Image 55: ChatGPT conversation screen on a smartphone](https://cdn.mos.cms.futurecdn.net/UxkEjFyJ7VMwPGcRaYjtgP.jpg) OpenAI says yes to ads, testing begins soon as cheaper 'ChatGPT Go' tier debuts](https://www.androidcentral.com/apps-software/ai/openai-says-yes-to-ads-testing-begins-soon-as-cheaper-chatgpt-go-tier-debuts \\\"OpenAI says yes to ads, testing begins soon as cheaper 'ChatGPT Go' tier debuts\\\")\\n\\n[![Image 56: Google Gemini receives Personal Intelligence, rolling out for certain AI subscribers.](https://cdn.mos.cms.futurecdn.net/cGoM9ro8m2dDAKWzP63gdJ.jpg) Get Personal: Gemini's 'Personal Intelligence' uses your Google apps for answers that matter](https://www.androidcentral.com/apps-software/ai/get-personal-geminis-personal-intelligence-uses-your-google-apps-for-answers-that-matter \\\"Get Personal: Gemini's 'Personal Intelligence' uses your Google apps for answers that matter\\\")\\n\\n[![Image 57: Using the new Gemini 3 and Nano Banana Pro models in the Gemini app. ](https://cdn.mos.cms.futurecdn.net/G2ACgqJo6J4HcuDFkDnkub.jpg) Google's Nano Banana Pro hits key milestone, and it couldn't have come at a better time](https://www.androidcentral.com/apps-software/ai/googles-nano-banana-pro-hits-key-milestone-and-it-couldnt-have-come-at-a-better-time \\\"Google's Nano Banana Pro hits key milestone, and it couldn't have come at a better time\\\")\\n\\n[![Image 58: The Google CC agent in Gmail.](https://cdn.mos.cms.futurecdn.net/u9yzt4FqscCgLUgq3ihzCQ.jpg) I tried Google's CC productivity agent in Workspace, and it's the personal assistant I can't afford](https://www.androidcentral.com/apps-software/ai/i-tried-googles-cc-productivity-agent-in-workspace-and-its-the-personal-assistant-i-cant-afford \\\"I tried Google's CC productivity agent in Workspace, and it's the personal assistant I can't afford\\\")\\n\\n[![Image 59: The Apple Intelligence &amp; Siri menu beside a Pixel running Gemini.](https://cdn.mos.cms.futurecdn.net/kwUHPFz8WXsE5EnhhQz4j8.jpg) Here's why Apple leaning on Google for Siri's AI overhaul makes sense](https://www.androidcentral.com/apps-software/ai/why-apple-leaning-on-google-for-siri-ai-overhaul-makes-sense \\\"Here's why Apple leaning on Google for Siri's AI overhaul makes sense\\\")\\n\\n[![Image 60: Waking Bixby up with a &quot;Hi, Bixby&quot; voice prompt on a Samsung Galaxy S24 Ultra](https://cdn.mos.cms.futurecdn.net/kMkpLV8Qv3fqZMJew6qLUP.jpg) Incoming glow up: Samsung Bixby's huge One UI 8.5 upgrade might look like Google](https://www.androidcentral.com/apps-software/ai/incoming-glow-up-samsungs-bixby-huge-one-ui-8-5-upgrade-might-look-like-google \\\"Incoming glow up: Samsung Bixby's huge One UI 8.5 upgrade might look like Google\\\")\\n\\nLatest in Feature\\n\\n[![Image 61: ChatGPT app on an Android phone](https://cdn.mos.cms.futurecdn.net/2dAidsg3greDHeqFxASwSY.jpg) OpenAI's audio-first hardware product could launch this year, and I'm excited](https://www.androidcentral.com/apps-software/ai/openais-audio-first-hardware-product-could-launch-this-year-and-im-excited \\\"OpenAI's audio-first hardware product could launch this year, and I'm excited\\\")\\n\\n[![Image 62: Samsung Galaxy Z Fold 7 review](https://cdn.mos.cms.futurecdn.net/2kWuw6f5DH4oNFJTE2JBtS.jpg) A screen without 'the crease' is exactly what foldables need](https://www.androidcentral.com/phones/a-screen-without-the-crease-is-exactly-what-foldables-need \\\"A screen without 'the crease' is exactly what foldables need\\\")\\n\\n[![Image 63: The back of the DuRoBo Krono with sunshafts of light on it](https://cdn.mos.cms.futurecdn.net/V8CMJdPz4pSu6yBzywAzSQ.jpg) CES's most interesting e-reader still needs a bit of work before it hits prime time](https://www.androidcentral.com/wearables/durobo-krono-e-reader \\\"CES's most interesting e-reader still needs a bit of work before it hits prime time\\\")\\n\\n[![Image 64: Cyberpunk on Acer Chromebook 516 GE alt](https://cdn.mos.cms.futurecdn.net/HBgqZieQ5zYmd5yWUYGba8.jpg) With GeForce Now, NVIDIA is building the cloud gaming service I've always wanted](https://www.androidcentral.com/accessories/smart-home/with-geforce-now-nvidia-is-building-the-cloud-gaming-service-ive-always-wanted \\\"With GeForce Now, NVIDIA is building the cloud gaming service I've always wanted\\\")\\n\\n[![Image 65: Andrew&#039;s Spotify Wrapped 2024 on the Pixel 9 Pro Fold](https://cdn.mos.cms.futurecdn.net/yV6UbV7GLa5oDRF6JrvgsK.jpg) Spotify is basically telling its subscribers to switch with latest price hike](https://www.androidcentral.com/apps-software/spotify/spotify-is-basically-telling-subscribers-to-switch-with-latest-price-hike \\\"Spotify is basically telling its subscribers to switch with latest price hike\\\")\\n\\n[![Image 66: Photoshopped photo of the Garmin Quatix 8 Pro hovering in front of an ocean backdrop, the display showing an SOS conversation stating &quot;help is on the way.&quot;](https://cdn.mos.cms.futurecdn.net/qWhXoeyqHbfZrECmWk4H2S.webp) My hope is building for a 'Garmin Pro' series of satellite watches in 2026](https://www.androidcentral.com/wearables/garmin/my-hope-is-building-for-garmin-pro-series-of-satellite-watches-in-2026 \\\"My hope is building for a 'Garmin Pro' series of satellite watches in 2026\\\")\\n\\nAdvertisement\\n\\nAdvertisement\\n\\nLATEST ARTICLES\\n\\n1.   [![Image 67: The Snapdragon 8 Elite Gen 5 on rocks](https://cdn.mos.cms.futurecdn.net/zv6rPCPvpWFWZsjoiuLdnH.jpg)](https://www.androidcentral.com/phones/qualcomm/qualcomms-next-elite-snapdragon-could-go-pro-for-this-years-flagships \\\"Qualcomm's next 'Elite' Snapdragon could go Pro for this year's flagships\\\")1 [Qualcomm's next 'Elite' Snapdragon could go Pro for this year's flagships](https://www.androidcentral.com/phones/qualcomm/qualcomms-next-elite-snapdragon-could-go-pro-for-this-years-flagships)   \\n2.   2 [Good Lock's 'Home Up' looks better than ever in Samsung's One UI 8.5 update](https://www.androidcentral.com/apps-software/good-locks-home-up-looks-better-than-ever-in-samsungs-one-ui-8-5-update)   \\n3.   3 [New Pixel 10a leak suggests price holds steady despite rising production costs](https://www.androidcentral.com/phones/google-pixel/new-pixel-10a-leak-suggests-price-holds-steady-despite-rising-production-costs)   \\n4.   4 [The E Ink SwitchBot AI Art Frame makes digital art look like print, but I wish it didn't use AI](https://www.androidcentral.com/accessories/smart-home/switchbot-ai-art-frame)   \\n5.   5 [RAM is the only phone spec that matters in 2026](https://www.androidcentral.com/phones/google-pixel/ram-is-the-only-phone-spec-that-matters-in-2026)   \\n\\nAndroid Central is part of Future US Inc, an international media group and leading digital publisher. [Visit our corporate site](https://futureplc.com/).\\n\\n[![Image 68](https://cdn.mos.cms.futurecdn.net/flexiimages/mednnv697g1760357120.png)Add as a preferred source on Google](https://google.com/preferences/source?q=androidcentral.com)\\n*   [Terms and conditions](https://futureplc.com/terms-conditions/)\\n*   [Contact Future's experts](https://futureplc.com/contact/)\\n*   [Privacy policy](https://futureplc.com/privacy-policy/)\\n*   [Cookies policy](https://futureplc.com/cookies-policy/)\\n*   [Accessibility statement](https://futureplc.com/accessibility-statement/)\\n*   [Careers](https://futureplc.com/careers/)\\n*   [Licensing](https://futureplc.com/licensing/)\\n*   [External links disclosure](https://www.futureplc.com/terms-conditions/?utm_source=ac&utm_medium=footer&utm_campaign=navigation)\\n*   [About us](https://www.androidcentral.com/about)\\n*   [Newsletter](https://www.androidcentral.com/newsletter)\\n*   [Advertise with us](https://go.future-advertising.com/Android-Central-Media-Kit.html)\\n*   [Licensing and reprints](https://www.futureplc.com/licensing)\\n*   [Windows Central](https://www.windowscentral.com/)\\n*   [Do not sell or share my personal information](https://www.androidcentral.com/privacy-portal)\\n\\n© Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.\\n\\nClose\\n\\nPlease login or signup to comment\\n\\nPlease wait...\\n\\n Login  Sign Up \\n\\n![Image 69](https://ib.adnxs.com/getuid?https%3A%2F%2Fpixel.servebom.com%2Fpartner%3Fcb%3D3247%26svc%3Dus%26id%3D23%26uid%3D%24UID)![Image 70](https://us-u.openx.net/w/1.0/cm?gdpr=0&gdpr_consent=&id=de2d90e5-4d26-4c8c-a342-3edcde51fdb1&ph=25af9286-f23b-4b02-abcd-f2ee3b564dab&r=https%3A%2F%2Fpixel.servebom.com%2Fpartner%3Fcb%3D9099%26svc%3Dus%26id%3D22%26uid%3D)![Image 71](https://ap.lijit.com/pixel?gdpr=0&gdpr_consent=&redir=https%3A%2F%2Fpixel.servebom.com%2Fpartner%3Fcb%3D7434%26svc%3Dus%26id%3D24%26uid%3D%24UID)![Image 72](https://eb2.3lift.com/getuid?gdpr=0&gdpr_consent=&redir=https%3A%2F%2Fpixel.servebom.com%2Fpartner%3Fcb%3D10975%26svc%3Dus%26id%3D14%26uid%3D%24UID)\\n\\n![Image 73](https://aax-eu.amazon-adsystem.com/s/dcm?pid=cda341cb-196c-4da8-897b-752ce4bb588d&id=26ff7f98-1296-4918-6175-41fd064a5e41&env=mWeb&eventType=map&gdpr=1&gdpr_consent=DBABLA~BVQqAAAAAgA.QA&id_mid_4=26ff7f98-1296-4918-6175-41fd064a5e41&reqId=58149254-3fcf-4833-43c1-a85ecde3fb1f&zdid=2124)![Image 74](https://mwzeom.zeotap.com/mw?zpartnerid=1353&env=mWeb&env=mWeb&eventType=map&gdpr=1&gdpr_consent=DBABLA~BVQqAAAAAgA.QA&id_mid_4=26ff7f98-1296-4918-6175-41fd064a5e41&reqId=58149254-3fcf-4833-43c1-a85ecde3fb1f&zdid=2124)![Image 75](https://s.cpx.to/sync?dsp=ZTP&dsp_uid=26ff7f98-1296-4918-6175-41fd064a5e41)\"}, {\"url\": \"https://openai.com/index/introducing-chatgpt-go/\", \"title\": \"Introducing ChatGPT Go, now available worldwide - OpenAI\", \"content\": \"Keep reading\\n\\nView all\\n\\nImage 1: OAI Ads Blog ArtCard 1x1\\n\\nOur approach to advertising and expanding access to ChatGPT Company Jan 16, 2026\\n\\nImage 2: OpenAI for Healthcare > Cover Image\\n\\nIntroducing OpenAI for Healthcare Product Jan 8, 2026\\n\\nImage 3: OAI ChatGPT Health ArtCard\\n\\nIntroducing ChatGPT Health Product Jan 7, 2026\\n\\nOur Research\\n   Research Index\\n   Research Overview\\n   Research Residency\\n   OpenAI for Science\\n\\nLatest Advancements\\n   GPT-5\\n   OpenAI o3\\n   OpenAI o4-mini\\n   GPT-4o\\n   GPT-4o mini\\n   Sora\\n\\nSafety\\n   Safety Approach\\n   Security & Privacy\\n   Trust & Transparency\\n\\nChatGPT\\n   Explore ChatGPT(opens in a new window)\\n   Business\\n   Enterprise\\n   Education\\n   Pricing(opens in a new window)\\n   Download(opens in a new window)\", \"score\": 0.8047902, \"raw_content\": \"Introducing ChatGPT Go, now available worldwide | OpenAI\\n===============\\n\\n[Skip to main content](https://openai.com/index/introducing-chatgpt-go/#main)\\n\\nLog in\\n\\n[](https://openai.com/)\\n\\nSwitch to\\n\\n*   [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n*   [Sora(opens in a new window)](https://sora.com/)\\n*   [API Platform(opens in a new window)](https://platform.openai.com/)\\n\\n*   [Research](https://openai.com/research/index/) \\n*   [Safety](https://openai.com/safety/) \\n*   [For Business](https://openai.com/business/) \\n*   [For Developers](https://openai.com/api/) \\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true) \\n*   [Sora](https://openai.com/sora/) \\n*   [Stories](https://openai.com/stories/) \\n*   [Company](https://openai.com/about/) \\n*   [News](https://openai.com/news/company-announcements/) \\n\\n*   Research\\n\\nBack to main menu  \\n\\n    *   [Research Index](https://openai.com/research/index/)\\n    *   [Research Overview](https://openai.com/research/)\\n    *   [Research Residency](https://openai.com/residency/)\\n    *   [OpenAI for Science](https://openai.com/science/)\\n    *   Latest Advancements\\n    *   [GPT-5.2](https://openai.com/index/introducing-gpt-5-2/)\\n    *   [GPT-5.1](https://openai.com/index/gpt-5-1/)\\n    *   [Sora 2](https://openai.com/index/sora-2/)\\n    *   [GPT-5](https://openai.com/index/introducing-gpt-5/)\\n    *   [OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n    *   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/)\\n\\n*   Safety\\n\\nBack to main menu  \\n\\n    *   [Safety Approach](https://openai.com/safety/)\\n    *   [Security & Privacy](https://openai.com/security-and-privacy/)\\n\\n*   [For Business](https://openai.com/business/)\\n\\nBack to main menu  \\n\\n    *   [Business Overview](https://openai.com/business/)\\n    *   [Solutions](https://openai.com/solutions/)\\n    *   [Learn](https://openai.com/business/learn/)\\n    *   [Startups](https://openai.com/startups/)\\n    *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Contact Sales](https://openai.com/contact-sales/)\\n\\n*   For Developers\\n\\nBack to main menu  \\n\\n    *   [API Platform](https://openai.com/api/)\\n    *   [API Pricing](https://openai.com/api/pricing/)\\n    *   [Agents](https://openai.com/agent-platform/)\\n    *   [Codex](https://openai.com/codex/)\\n    *   [Open Models](https://openai.com/open-models/)\\n    *   [Community(opens in a new window)](https://community.openai.com/)\\n\\n*   [ChatGPT](https://chatgpt.com/overview?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n\\nBack to main menu  \\n\\n    *   [Explore ChatGPT](https://chatgpt.com/overview?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n    *   [Business](https://chatgpt.com/for-business/team?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n    *   [Enterprise](https://chatgpt.com/for-business/enterprise?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n    *   [Education](https://chatgpt.com/for-business/education?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n    *   [Pricing](https://chatgpt.com/pricing?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n    *   [Download](https://chatgpt.com/download?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n\\n*   [Sora](https://openai.com/sora/)\\n*   [Stories](https://openai.com/stories/)\\n*   Company\\n\\nBack to main menu  \\n\\n    *   [About Us](https://openai.com/about/)\\n    *   [Our Charter](https://openai.com/charter/)\\n    *   [Foundation](https://openai.com/foundation/)\\n    *   [Careers](https://openai.com/careers/)\\n    *   [Brand Guidelines](https://openai.com/brand/)\\n\\n*   [News](https://openai.com/news/company-announcements/)\\n\\nLog in\\n\\nIntroducing ChatGPT Go, now available worldwide | OpenAI\\n\\nTable of contents\\n\\n*   [What you get with ChatGPT Go](https://openai.com/index/introducing-chatgpt-go/#what-you-get-with-chatgpt-go)\\n*   [Supporting accessibility with ads](https://openai.com/index/introducing-chatgpt-go/#supporting-accessibility-with-ads)\\n*   [Plan details](https://openai.com/index/introducing-chatgpt-go/#plan-details)\\n\\nJanuary 16, 2026\\n\\n[Product](https://openai.com/news/product-releases/)\\n\\nIntroducing ChatGPT Go, now available worldwide\\n===============================================\\n\\nListen to article\\n\\nShare\\n\\nIn August 2025, we introduced ChatGPT Go in India as a low-cost subscription designed to expand access to ChatGPT’s most popular features and help more people use advanced AI in their daily life. Since then, ChatGPT Go has rolled out to 170 additional countries, making it our fastest growing plan and among the most affordable AI subscription globally.\\n\\nIn markets where Go has been available, we’ve seen strong adoption and regular everyday use for tasks like writing, learning, image creation, and problem-solving. This early momentum helped inform our decision to make ChatGPT Go available globally.\\n\\nStarting today, ChatGPT Go is rolling out everywhere ChatGPT is available. In the US, Go is available for $8 per month.\\n\\nWith this launch, ChatGPT now offers three subscription tiers globally:\\n\\n*   ChatGPT Go at $8 USD/month*\\n*   ChatGPT Plus at $20 USD/month\\n*   ChatGPT Pro at $200 USD/month\\n\\n*US price displayed. Go pricing is localized in some markets.\\n\\nWhat you get with ChatGPT Go\\n----------------------------\\n\\nChatGPT Go is designed for people who want expanded access to our latest model, GPT‑5.2 Instant, at a lower price point—more messages, more uploads, and more image creation. With ChatGPT Go, you get:\\n\\n*   10x more messages, file uploads and image creation than the free tier, so you can keep chatting with no limits on GPT‑5.2 Instant.\\n*   Longer memory and context window, so ChatGPT can remember more helpful details about you over time.\\n\\nThis now sits alongside our two existing consumer subscription plans: ChatGPT Plus and ChatGPT Pro.\\n\\nChatGPT Plus is designed for work that requires deeper reasoning—like writing and editing documents, learning and research, or data analysis. It offers expanded access to our most advanced models, including GPT‑5.2 Thinking, along with the flexibility to choose legacy models and use our coding agent, Codex. Compared to Go, Plus includes higher limits for messages, file uploads, memory, and context, so ChatGPT can remember more detail from past conversations and support longer, more continuous workflows.\\n\\nChatGPT Pro is built for AI power users pushing the limits of advanced intelligence. It offers full access to our most powerful model, GPT‑5.2 Pro, along with maximum memory and context, and early previews of our newest features.\\n\\nSupporting accessibility with ads\\n---------------------------------\\n\\nWe plan to begin testing ads in the free tier and ChatGPT Go in the US soon. Ads support our commitment to making AI accessible to everyone by helping us keep ChatGPT available at free and affordable price points.\\n\\nChatGPT Plus, Pro, Business and Enterprise will remain ad-free.\\n\\nRead more about how we plan to introduce ads [here⁠](https://openai.com/index/our-approach-to-advertising-and-expanding-access/).\\n\\nPlan details\\n------------\\n\\nTo compare plans and see what’s included, visit [chatgpt.com/pricing⁠(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true).\\n\\n*   [2026](https://openai.com/news/?tags=2026)\\n\\nAuthor\\n------\\n\\n[OpenAI](https://openai.com/news/?author=openai#results)\\n\\nKeep reading\\n------------\\n\\n[View all](https://openai.com/news/product/)\\n\\n![Image 1: OAI Ads Blog ArtCard 1x1](https://images.ctfassets.net/kftzwdyauwt9/41z4Qn4f0i948wZMLWB9lH/f3961891b0e0274306ea19fe368c95d7/OAI_Ads_Blog_ArtCard_1x1.png?w=3840&q=90&fm=webp)\\n\\n[Our approach to advertising and expanding access to ChatGPT Company Jan 16, 2026](https://openai.com/index/our-approach-to-advertising-and-expanding-access/)\\n\\n![Image 2: OpenAI for Healthcare > Cover Image](https://images.ctfassets.net/kftzwdyauwt9/4oQtNGNaY29dDxIKJBVphg/18314fd6a66f31249a5f95ec238272de/OAI_forHealth_ArtCard_1-1_C.png?w=3840&q=90&fm=webp)\\n\\n[Introducing OpenAI for Healthcare Product Jan 8, 2026](https://openai.com/index/openai-for-healthcare/)\\n\\n![Image 3: OAI ChatGPT Health ArtCard](https://images.ctfassets.net/kftzwdyauwt9/3hnWarC0m5jJPEoEU3HZGw/59c55e915ebc3dcf4d49efab8e166a19/OAI_ChatGPT_Health_ArtCard.png?w=3840&q=90&fm=webp)\\n\\n[Introducing ChatGPT Health Product Jan 7, 2026](https://openai.com/index/introducing-chatgpt-health/)\\n\\nOur Research\\n*   [Research Index](https://openai.com/research/index/)\\n*   [Research Overview](https://openai.com/research/)\\n*   [Research Residency](https://openai.com/residency/)\\n*   [OpenAI for Science](https://openai.com/science/)\\n\\nLatest Advancements\\n*   [GPT-5](https://openai.com/gpt-5/)\\n*   [OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [OpenAI o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)\\n*   [GPT-4o](https://openai.com/index/gpt-4o-system-card/)\\n*   [GPT-4o mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)\\n*   [Sora](https://openai.com/index/sora-system-card/)\\n\\nSafety\\n*   [Safety Approach](https://openai.com/safety/)\\n*   [Security & Privacy](https://openai.com/security-and-privacy/)\\n*   [Trust & Transparency](https://openai.com/trust-and-transparency/)\\n\\nChatGPT\\n*   [Explore ChatGPT(opens in a new window)](https://chatgpt.com/overview?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n*   [Business](https://chatgpt.com/business/business-plan?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n*   [Enterprise](https://chatgpt.com/business/enterprise?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n*   [Education](https://chatgpt.com/business/education?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n*   [Pricing(opens in a new window)](https://chatgpt.com/pricing?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n*   [Download(opens in a new window)](https://chatgpt.com/download?openaicom-did=180f0745-7ada-4f1d-82b0-5b8eb462a1ac&openaicom_referred=true)\\n\\nSora\\n*   [Sora Overview](https://openai.com/sora/)\\n*   [Features](https://openai.com/sora/#features)\\n*   [Pricing](https://openai.com/sora/#pricing)\\n*   [Sora log in(opens in a new window)](https://sora.com/)\\n\\nAPI Platform\\n*   [Platform Overview](https://openai.com/api/)\\n*   [Pricing](https://openai.com/api/pricing/)\\n*   [API log in(opens in a new window)](https://platform.openai.com/login)\\n*   [Documentation(opens in a new window)](https://platform.openai.com/docs/overview)\\n*   [Developer Forum(opens in a new window)](https://community.openai.com/)\\n\\nFor Business\\n*   [Business Overview](https://openai.com/business/)\\n*   [Solutions](https://openai.com/solutions/)\\n*   [Contact Sales](https://openai.com/contact-sales/)\\n\\nCompany\\n*   [About Us](https://openai.com/about/)\\n*   [Our Charter](https://openai.com/charter/)\\n*   [Foundation](https://openai.com/foundation/)\\n*   [Careers](https://openai.com/careers/)\\n*   [Brand](https://openai.com/brand/)\\n\\nSupport\\n*   [Help Center(opens in a new window)](https://help.openai.com/)\\n\\nMore\\n*   [News](https://openai.com/news/)\\n*   [Stories](https://openai.com/stories/)\\n*   [Livestreams](https://openai.com/live/)\\n*   [Podcast](https://openai.com/podcast/)\\n*   [RSS](https://openai.com/news/rss.xml)\\n\\nTerms & Policies\\n*   [Terms of Use](https://openai.com/policies/terms-of-use/)\\n*   [Privacy Policy](https://openai.com/policies/privacy-policy/)\\n*   [Other Policies](https://openai.com/policies/)\\n\\n[(opens in a new window)](https://x.com/OpenAI)[(opens in a new window)](https://www.youtube.com/OpenAI)[(opens in a new window)](https://www.linkedin.com/company/openai)[(opens in a new window)](https://github.com/openai)[(opens in a new window)](https://www.instagram.com/openai/)[(opens in a new window)](https://www.tiktok.com/@openai)[(opens in a new window)](https://discord.gg/openai)\\n\\nOpenAI © 2015–2026 Manage Cookies\\n\\nEnglish United States\"}, {\"url\": \"https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI\", \"title\": \"Products and applications of OpenAI - Wikipedia\", \"content\": \"94.   ^\\\"OpenAI launches new AI reasoning models o3 and 04-mini; older models to be phased out\\\". _The Hindu_. The Hindu Bureau. 2025-04-17. ISSN \\\"ISSN (identifier)\\\")0971-751X. Retrieved 2025-04-17.\\n95.   ^\\\"OpenAI launches new AI tool to facilitate research tasks\\\". _Reuters_. February 3, 2025 – via www.reuters.com.\\n96.   ^Lawler, Richard (2025-02-03). \\\"ChatGPT's agent can now do deep research for you\\\". _The Verge_. Retrieved 2025-02-05.\\n97.   ^\\\"OpenAI rolls out free, lightweight Deep Research tool for all ChatGPT users\\\". _India Today_. 2025-04-25. Retrieved 2025-04-25.\\n98.   ^\\\"OpenAI introduces cost-efficient, lightweight version of ChatGPT research tool\\\". _The Times of India_. 2025-04-25. ISSN \\\"ISSN (identifier)\\\")0971-8257. Retrieved 2025-04-25. [...] AgentKit\\n\\n[edit]\\n\\nOn October 6, 2025, Sam Altman announced OpenAI's new AgentKit at the 2025 Dev Day opening keynote. AgentKit is a new integrated suite of tools for building, deploying and optimizing AI agents.\\n\\nAccording to OpenAI, AgentKit builds upon its Responses API released in March, offering a more streamlined approach to agent creation. Several early adopters report significant time savings and efficiency gains when using the new agentic tools.( [...] ### GPT-4.1\\n\\n[edit]\\n\\nOn April 14, 2025, OpenAI released the GPT-4.1 model. They also released two “smaller, faster, and cheaper” models including GPT-4.1 mini and GPT-4.1 nano.(\\n\\n### GPT-5\\n\\n[edit]\\n\\nMain article: GPT-5\\n\\nGPT-5 is OpenAI’s flagship model released on August 7, 2025. It replaced earlier models like GPT-4o, GPT-4.5, and o3.\\n\\nGPT-5 uses a dynamic router that chooses between quick responses and deeper “thinking” when needed. It can perform at PhD-level across domains like math, coding, health, and multimodal tasks. It also achieved a 74.9% on SWE-bench Verified and 88% on Aider polyglot.(\", \"score\": 0.798077, \"raw_content\": \"Products and applications of OpenAI - Wikipedia\\n===============\\n[Jump to content](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#bodyContent)\\n\\n- [x] Main menu \\n\\nMain menu\\n\\nmove to sidebar hide\\n\\n Navigation \\n\\n*   [Main page](https://en.wikipedia.org/wiki/Main_Page \\\"Visit the main page [z]\\\")\\n*   [Contents](https://en.wikipedia.org/wiki/Wikipedia:Contents \\\"Guides to browsing Wikipedia\\\")\\n*   [Current events](https://en.wikipedia.org/wiki/Portal:Current_events \\\"Articles related to current events\\\")\\n*   [Random article](https://en.wikipedia.org/wiki/Special:Random \\\"Visit a randomly selected article [x]\\\")\\n*   [About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About \\\"Learn about Wikipedia and how it works\\\")\\n*   [Contact us](https://en.wikipedia.org/wiki/Wikipedia:Contact_us \\\"How to contact Wikipedia\\\")\\n\\n Contribute \\n\\n*   [Help](https://en.wikipedia.org/wiki/Help:Contents \\\"Guidance on how to use and edit Wikipedia\\\")\\n*   [Learn to edit](https://en.wikipedia.org/wiki/Help:Introduction \\\"Learn how to edit Wikipedia\\\")\\n*   [Community portal](https://en.wikipedia.org/wiki/Wikipedia:Community_portal \\\"The hub for editors\\\")\\n*   [Recent changes](https://en.wikipedia.org/wiki/Special:RecentChanges \\\"A list of recent changes to Wikipedia [r]\\\")\\n*   [Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard \\\"Add images or other media for use on Wikipedia\\\")\\n*   [Special pages](https://en.wikipedia.org/wiki/Special:SpecialPages)\\n\\n[![Image 1](https://en.wikipedia.org/static/images/icons/enwiki-25.svg)![Image 2: Wikipedia](https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en-25.svg)![Image 3: The Free Encyclopedia](https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-tagline-en-25.svg)](https://en.wikipedia.org/wiki/Main_Page)\\n\\n[Search](https://en.wikipedia.org/wiki/Special:Search \\\"Search Wikipedia [f]\\\")\\n\\nSearch\\n\\n- [x] Appearance \\n\\n*   [Donate](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en)\\n*   [Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Products+and+applications+of+OpenAI \\\"You are encouraged to create an account and log in; however, it is not mandatory\\\")\\n*   [Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Products+and+applications+of+OpenAI \\\"You're encouraged to log in; however, it's not mandatory. [o]\\\")\\n\\n- [x] Personal tools \\n\\n*   [Donate](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en)\\n*   [Create account](https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Products+and+applications+of+OpenAI \\\"You are encouraged to create an account and log in; however, it is not mandatory\\\")\\n*   [Log in](https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Products+and+applications+of+OpenAI \\\"You're encouraged to log in; however, it's not mandatory. [o]\\\")\\n\\nContents\\n--------\\n\\nmove to sidebar hide\\n\\n*   [(Top)](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)\\n*   [1 Reinforcement learning](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Reinforcement_learning)Toggle Reinforcement learning subsection\\n    *   [1.1 Gym](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Gym)\\n        *   [1.1.1 Gym Retro](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Gym_Retro)\\n\\n    *   [1.2 RoboSumo](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#RoboSumo)\\n\\n    *   [1.3 OpenAI Five](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#OpenAI_Five)\\n\\n    *   [1.4 Dactyl](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Dactyl)\\n\\n*   [2 API](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#API)\\n\\n*   [3 AgentKit](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#AgentKit)\\n\\n*   [4 Text generation](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Text_generation)Toggle Text generation subsection\\n    *   [4.1 OpenAI's original GPT model (\\\"GPT-1\\\")](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#OpenAI's_original_GPT_model_(%22GPT-1%22))\\n\\n    *   [4.2 GPT-2](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-2)\\n\\n    *   [4.3 GPT-3](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-3)\\n\\n    *   [4.4 Codex](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Codex)\\n\\n    *   [4.5 GPT-4](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-4)\\n\\n    *   [4.6 GPT-4o](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-4o)\\n\\n    *   [4.7 GPT-4.5](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-4.5)\\n\\n    *   [4.8 GPT-4.1](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-4.1)\\n\\n    *   [4.9 GPT-5](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-5)\\n\\n    *   [4.10 o1](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#o1)\\n\\n    *   [4.11 o3](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#o3)\\n\\n    *   [4.12 Deep research](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Deep_research)\\n\\n    *   [4.13 GPT-OSS](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-OSS)\\n\\n*   [5 Image classification](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Image_classification)Toggle Image classification subsection\\n    *   [5.1 CLIP](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#CLIP)\\n\\n*   [6 Text-to-image](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Text-to-image)Toggle Text-to-image subsection\\n    *   [6.1 DALL-E](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#DALL-E)\\n        *   [6.1.1 DALL-E 2](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#DALL-E_2)\\n\\n        *   [6.1.2 DALL-E 3](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#DALL-E_3)\\n\\n*   [7 Text-to-video](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Text-to-video)Toggle Text-to-video subsection\\n    *   [7.1 Sora](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Sora)\\n\\n*   [8 Speech-to-text](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Speech-to-text)Toggle Speech-to-text subsection\\n    *   [8.1 Whisper](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Whisper)\\n\\n*   [9 Music generation](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Music_generation)Toggle Music generation subsection\\n    *   [9.1 MuseNet](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#MuseNet)\\n\\n    *   [9.2 Jukebox](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Jukebox)\\n\\n*   [10 User interfaces](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#User_interfaces)Toggle User interfaces subsection\\n    *   [10.1 Debate Game](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Debate_Game)\\n\\n    *   [10.2 Microscope](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Microscope)\\n\\n    *   [10.3 ChatGPT](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#ChatGPT)\\n\\n    *   [10.4 SearchGPT](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#SearchGPT)\\n\\n    *   [10.5 ChatGPT Atlas](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#ChatGPT_Atlas)\\n\\n*   [11 Stargate and other supercomputers](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Stargate_and_other_supercomputers)\\n\\n*   [12 Hardware development](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Hardware_development)\\n\\n*   [13 Selected bibliography](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Selected_bibliography)\\n\\n*   [14 See also](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#See_also)\\n\\n*   [15 Notes](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#Notes)\\n\\n*   [16 References](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#References)\\n\\n- [x] Toggle the table of contents \\n\\nProducts and applications of OpenAI\\n===================================\\n\\n- [x] 1 language \\n\\n*   [العربية](https://ar.wikipedia.org/wiki/%D9%85%D9%86%D8%AA%D8%AC%D8%A7%D8%AA_%D9%88%D8%AA%D8%B7%D8%A8%D9%8A%D9%82%D8%A7%D8%AA_%D8%A3%D9%88%D8%A8%D9%86_%D8%A5%D9%8A%D9%87_%D8%A2%D9%8A \\\"منتجات وتطبيقات أوبن إيه آي – Arabic\\\")\\n\\n[Edit links](https://www.wikidata.org/wiki/Special:EntityPage/Q135111627#sitelinks-wikipedia \\\"Edit interlanguage links\\\")\\n\\n*   [Article](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI \\\"View the content page [c]\\\")\\n*   [Talk](https://en.wikipedia.org/wiki/Talk:Products_and_applications_of_OpenAI \\\"Discuss improvements to the content page [t]\\\")\\n\\n- [x] English \\n\\n*   [Read](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI)\\n*   [Edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit \\\"Edit this page [e]\\\")\\n*   [View history](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=history \\\"Past revisions of this page [h]\\\")\\n\\n- [x] Tools \\n\\nTools\\n\\nmove to sidebar hide\\n\\n Actions \\n\\n*   [Read](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI)\\n*   [Edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit \\\"Edit this page [e]\\\")\\n*   [View history](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=history)\\n\\n General \\n\\n*   [What links here](https://en.wikipedia.org/wiki/Special:WhatLinksHere/Products_and_applications_of_OpenAI \\\"List of all English Wikipedia pages containing links to this page [j]\\\")\\n*   [Related changes](https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Products_and_applications_of_OpenAI \\\"Recent changes in pages linked from this page [k]\\\")\\n*   [Upload file](https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard \\\"Upload files [u]\\\")\\n*   [Permanent link](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&oldid=1333105405 \\\"Permanent link to this revision of this page\\\")\\n*   [Page information](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=info \\\"More information about this page\\\")\\n*   [Cite this page](https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Products_and_applications_of_OpenAI&id=1333105405&wpFormIdentifier=titleform \\\"Information on how to cite this page\\\")\\n*   [Get shortened URL](https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FProducts_and_applications_of_OpenAI)\\n*   [Download QR code](https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FProducts_and_applications_of_OpenAI)\\n\\n Print/export \\n\\n*   [Download as PDF](https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Products_and_applications_of_OpenAI&action=show-download-screen \\\"Download this page as a PDF file\\\")\\n*   [Printable version](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&printable=yes \\\"Printable version of this page [p]\\\")\\n\\n In other projects \\n\\n*   [Wikidata item](https://www.wikidata.org/wiki/Special:EntityPage/Q135111627 \\\"Structured data on this page hosted by Wikidata [g]\\\")\\n\\nAppearance\\n\\nmove to sidebar hide\\n\\nFrom Wikipedia, the free encyclopedia\\n\\nTechnology made by American organization\\n\\n![Image 4](https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Ionicons_duplicate-sharp.svg/40px-Ionicons_duplicate-sharp.svg.png)This article **contains one or more duplicated citations**. \\n\\nThe reason given is: DuplicateReferences script detected: \\n*   [https://arxiv.org/abs/2005.14165v4](https://arxiv.org/abs/2005.14165v4) (refs: 37, 150)\\n\\n*   [https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) (refs: 50, 54)\\n\\n*   [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165) (refs: 53, 55)\\n\\n*   [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/) (refs: 75, 160)\\n\\n*   [https://techcrunch.com/2025/03/25/chatgpts-image-generation-feature-gets-an-upgrade/](https://techcrunch.com/2025/03/25/chatgpts-image-generation-feature-gets-an-upgrade/) (refs: 77, 128)\\n\\n*   [https://openai.com/index/gpt-4-1/](https://openai.com/index/gpt-4-1/) (refs: 80, 162)\\n\\n*   [https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/](https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/) (refs: 90, 93)\\n\\n*   [https://openai.com/research/video-generation-models-as-world-simulators](https://openai.com/research/video-generation-models-as-world-simulators) (refs: 109, 110)\\n\\n It is recommended to use [named references](https://en.wikipedia.org/wiki/Help:Footnotes#WP:NAMEDREFS \\\"Help:Footnotes\\\") to consolidate citations that are used multiple times._(January 2026)_ _([Learn how and when to remove this message](https://en.wikipedia.org/wiki/Help:Maintenance\\\\_template\\\\_removal \\\"Help:Maintenance template removal\\\"))_\\n\\nPart of a series on\\n[OpenAI](https://en.wikipedia.org/wiki/OpenAI \\\"OpenAI\\\")\\n[![Image 5](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/OpenAI_logo_2025_%28symbol%29.svg/120px-OpenAI_logo_2025_%28symbol%29.svg.png)](https://en.wikipedia.org/wiki/File:OpenAI_logo_2025_(symbol).svg)\\n[Products](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI)\\n*   [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT \\\"ChatGPT\\\")\\n    *   [Search](https://en.wikipedia.org/wiki/ChatGPT_Search \\\"ChatGPT Search\\\")\\n    *   [Deep Research](https://en.wikipedia.org/wiki/ChatGPT_Deep_Research \\\"ChatGPT Deep Research\\\")\\n    *   [GPTs](https://en.wikipedia.org/wiki/GPTs \\\"GPTs\\\")\\n\\n*   [DALL-E](https://en.wikipedia.org/wiki/DALL-E \\\"DALL-E\\\")\\n*   [Sora](https://en.wikipedia.org/wiki/Sora_(text-to-video_model) \\\"Sora (text-to-video model)\\\")\\n*   [Whisper](https://en.wikipedia.org/wiki/Whisper_(speech_recognition_system) \\\"Whisper (speech recognition system)\\\")\\n[Models](https://en.wikipedia.org/wiki/ChatGPT#Model_versions \\\"ChatGPT\\\")\\n*   [GPT-3](https://en.wikipedia.org/wiki/GPT-3 \\\"GPT-3\\\")\\n*   [GPT-3.5](https://en.wikipedia.org/wiki/GPT-3#GPT-3.5 \\\"GPT-3\\\")\\n*   [GPT-4](https://en.wikipedia.org/wiki/GPT-4 \\\"GPT-4\\\")\\n*   [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\")\\n*   [GPT-4.5](https://en.wikipedia.org/wiki/GPT-4.5 \\\"GPT-4.5\\\")\\n*   [GPT-4.1](https://en.wikipedia.org/wiki/GPT-4.1 \\\"GPT-4.1\\\")\\n*   [GPT-5](https://en.wikipedia.org/wiki/GPT-5 \\\"GPT-5\\\")\\n*   [GPT-5.1](https://en.wikipedia.org/wiki/GPT-5.1 \\\"GPT-5.1\\\")\\n*   [GPT-5.2](https://en.wikipedia.org/wiki/GPT-5.2 \\\"GPT-5.2\\\")\\n\\n*   [o1](https://en.wikipedia.org/wiki/OpenAI_o1 \\\"OpenAI o1\\\")\\n*   [o3](https://en.wikipedia.org/wiki/OpenAI_o3 \\\"OpenAI o3\\\")\\n*   [o4-mini](https://en.wikipedia.org/wiki/OpenAI_o4-mini \\\"OpenAI o4-mini\\\")\\nPeople\\n*   [Sam Altman](https://en.wikipedia.org/wiki/Sam_Altman \\\"Sam Altman\\\")\\n*   [Greg Brockman](https://en.wikipedia.org/wiki/Greg_Brockman \\\"Greg Brockman\\\")\\n*   [Jessica Livingston](https://en.wikipedia.org/wiki/Jessica_Livingston \\\"Jessica Livingston\\\")\\n*   [Peter Thiel](https://en.wikipedia.org/wiki/Peter_Thiel \\\"Peter Thiel\\\")\\n*   [Elon Musk](https://en.wikipedia.org/wiki/Elon_Musk \\\"Elon Musk\\\")\\n*   [Andrej Karpathy](https://en.wikipedia.org/wiki/Andrej_Karpathy \\\"Andrej Karpathy\\\")\\nConcepts\\n*   [Hallucination](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence) \\\"Hallucination (artificial intelligence)\\\")\\n*   [Large language model](https://en.wikipedia.org/wiki/Large_language_model \\\"Large language model\\\")\\n*   [Word embedding](https://en.wikipedia.org/wiki/Word_embedding \\\"Word embedding\\\")\\n*   [Training](https://en.wikipedia.org/wiki/Foundation_model#Training \\\"Foundation model\\\")\\n*   [v](https://en.wikipedia.org/wiki/Template:OpenAI_series \\\"Template:OpenAI series\\\")\\n*   [t](https://en.wikipedia.org/wiki/Template_talk:OpenAI_series \\\"Template talk:OpenAI series\\\")\\n*   [e](https://en.wikipedia.org/wiki/Special:EditPage/Template:OpenAI_series \\\"Special:EditPage/Template:OpenAI series\\\")\\n\\nThe American [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence \\\"Artificial intelligence\\\") (AI) organization [OpenAI](https://en.wikipedia.org/wiki/OpenAI \\\"OpenAI\\\") has released a variety of products and applications since its founding in 2013.\\n\\nReinforcement learning\\n----------------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=1 \\\"Edit section: Reinforcement learning\\\")]\\n\\nAt its beginning, OpenAI's research included many projects focused on [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning \\\"Reinforcement learning\\\") (RL).[[1]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-1) OpenAI has been viewed as an important competitor to [DeepMind](https://en.wikipedia.org/wiki/DeepMind \\\"DeepMind\\\").[[2]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-2)\\n\\n### Gym\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=2 \\\"Edit section: Gym\\\")]\\n\\nAnnounced in 2016, Gym was an open-source [Python](https://en.wikipedia.org/wiki/Python_(programming_language) \\\"Python (programming language)\\\") library designed to facilitate the development of reinforcement learning algorithms. It aimed to standardize how environments are defined in AI research, making published research more easily reproducible[[3]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Dave_Gershgorn-2016-3)[[4]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-4) while providing users with a simple interface for interacting with these environments. In 2022, new developments of Gym have been moved to the library Gymnasium.[[5]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-5)[[6]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-6)\\n\\n#### Gym Retro\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=3 \\\"Edit section: Gym Retro\\\")]\\n\\nReleased in 2018, Gym Retro is a platform for reinforcement learning (RL) research on video games[[7]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-7) using RL algorithms and study generalization. Prior RL research focused mainly on optimizing agents to solve single tasks. Gym Retro gives the ability to generalize between games with similar concepts but different appearances.\\n\\n### RoboSumo\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=4 \\\"Edit section: RoboSumo\\\")]\\n\\nReleased in 2017, RoboSumo is a [virtual world](https://en.wikipedia.org/wiki/Virtual_world \\\"Virtual world\\\") where humanoid [metalearning](https://en.wikipedia.org/wiki/Meta-learning_(computer_science) \\\"Meta-learning (computer science)\\\") robot agents initially lack knowledge of how to even walk, but are given the goals of learning to move and to push the opposing agent out of the ring.[[8]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Wired-2017-8) Through this adversarial learning process, the agents learn how to adapt to changing conditions. When an agent is then removed from this virtual environment and placed in a new virtual environment with high winds, the agent braces to remain upright, suggesting it had learned how to balance in a generalized way.[[8]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Wired-2017-8)[[9]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-9) OpenAI's Igor Mordatch argued that competition between agents could create an intelligence \\\"arms race\\\" that could increase an agent's ability to function even outside the context of the competition.[[8]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Wired-2017-8)\\n\\n### OpenAI Five\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=5 \\\"Edit section: OpenAI Five\\\")]\\n\\nMain article: [OpenAI Five](https://en.wikipedia.org/wiki/OpenAI_Five \\\"OpenAI Five\\\")\\n\\nOpenAI Five is a team of five OpenAI-curated [bots](https://en.wikipedia.org/wiki/Video_game_bot \\\"Video game bot\\\") used in the competitive five-on-five video game _[Dota 2](https://en.wikipedia.org/wiki/Dota\\\\_2 \\\"Dota 2\\\")_, that learn to play against human players at a high skill level entirely through trial-and-error algorithms. Before becoming a team of five, the first public demonstration occurred at [The International 2017](https://en.wikipedia.org/wiki/The_International_2017 \\\"The International 2017\\\"), the annual premiere championship tournament for the game, where [Dendi](https://en.wikipedia.org/wiki/Dendi_(Dota_player) \\\"Dendi (Dota player)\\\"), a professional Ukrainian player, lost against a bot in a live one-on-one matchup.[[10]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-10)[[11]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-11) After the match, CTO Greg Brockman explained that the bot had learned by playing against itself for two weeks of [real time](https://en.wikipedia.org/wiki/Elapsed_real_time \\\"Elapsed real time\\\"), and that the learning software was a step in the direction of creating software that can handle complex tasks like a surgeon.[[12]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-12)[[13]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-13) The system uses a form of [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning \\\"Reinforcement learning\\\"), as the bots learn over time by playing against themselves hundreds of times a day for months, and are rewarded for actions such as killing an enemy and taking map objectives.[[14]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Simonite-14)[[15]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-15)[[16]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-16)\\n\\nBy June 2018, the ability of the bots expanded to play together as a full team of five, and they were able to defeat teams of amateur and semi-professional players.[[17]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-17)[[14]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Simonite-14)[[18]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-18)[[19]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-19) At [The International 2018](https://en.wikipedia.org/wiki/The_International_2018 \\\"The International 2018\\\"), OpenAI Five played in two exhibition matches against professional players, but ended up losing both games.[[20]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-20)[[21]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-21)[[22]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-22) In April 2019, OpenAI Five defeated [OG](https://en.wikipedia.org/wiki/OG_(esports) \\\"OG (esports)\\\"), the reigning world champions of the game at the time, 2:0 in a live exhibition match in San Francisco.[[23]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-23)[[24]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-24) The bots' final public appearance came later that month, where they played in 42,729 total games in a four-day open online competition, winning 99.4% of those games.[[25]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-25)\\n\\nOpenAI Five's mechanisms in Dota 2's bot player show the challenges of AI systems in multiplayer online battle arena (MOBA) games and how OpenAI Five has demonstrated the use of deep reinforcement learning (DRL) agents to achieve superhuman competence in Dota 2 matches.[[26]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-26)\\n\\n### Dactyl\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=6 \\\"Edit section: Dactyl\\\")]\\n\\nDeveloped in 2018, Dactyl uses machine learning to train a [Shadow Hand](https://en.wikipedia.org/wiki/Shadow_Hand \\\"Shadow Hand\\\"), a human-like robot hand, to manipulate physical objects.[[27]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-27) It learns entirely in simulation using the same RL algorithms and training code as [OpenAI Five](https://en.wikipedia.org/wiki/OpenAI_Five \\\"OpenAI Five\\\"). OpenAI tackled the object orientation problem by using [domain randomization](https://en.wikipedia.org/wiki/Domain_randomization \\\"Domain randomization\\\"), a simulation approach which exposes the learner to a variety of experiences rather than trying to fit to reality. The setup for Dactyl, aside from having motion tracking cameras, also has [RGB](https://en.wikipedia.org/wiki/RGB_color_model \\\"RGB color model\\\") cameras to allow the robot to manipulate an arbitrary object by seeing it. In 2018, OpenAI showed that the system was able to manipulate a cube and an octagonal prism.[[28]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-28)\\n\\nIn 2019, OpenAI demonstrated that Dactyl could solve a [Rubik's Cube](https://en.wikipedia.org/wiki/Rubik%27s_Cube \\\"Rubik's Cube\\\"). The robot was able to solve the puzzle 60% of the time. Objects like the Rubik's Cube introduce complex physics that is harder to model. OpenAI did this by improving the robustness of Dactyl to perturbations by using Automatic Domain Randomization (ADR), a simulation approach of generating progressively more difficult environments. ADR differs from manual domain randomization by not needing a human to specify randomization ranges.[[29]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-29)\\n\\nAPI\\n---\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=7 \\\"Edit section: API\\\")]\\n\\nIn June 2020, OpenAI announced a multi-purpose [API](https://en.wikipedia.org/wiki/API \\\"API\\\") which it said was \\\"for accessing new AI models developed by OpenAI\\\" to let developers call on it for \\\"any English language AI task\\\".[[30]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt3-whynotfullmodel-30)[[31]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-tech_Tech-31)\\n\\nAgentKit\\n--------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=8 \\\"Edit section: AgentKit\\\")]\\n\\nOn October 6, 2025, Sam Altman announced OpenAI's new AgentKit at the 2025 Dev Day opening keynote. AgentKit is a new integrated suite of tools for building, deploying and optimizing AI agents.\\n\\nAccording to OpenAI, AgentKit builds upon its Responses API released in March, offering a more streamlined approach to agent creation. Several early adopters report significant time savings and efficiency gains when using the new agentic tools.[[32]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-32)\\n\\n| Capability | Description |\\n| --- | --- |\\n| Agent Builder | A visual canvas for creating and versioning multi-agent workflows |\\n| ChatKit | A toolkit for embedding customizable chat-based agent experiences in your product |\\n| Connector Registry | Central admin panel for managing data sources across OpenAI products |\\n| Enhanced Evals | New Evals capabilities, including datasets, trace grading, automated prompt optimization and third-party model support |\\n| Guardrails | Custom guardrail configurations |\\n| Reinforcement Fine-Tuning | Ability to customize OpenAI's reasoning models, including custom tool calls and custom graders |\\n\\nText generation\\n---------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=9 \\\"Edit section: Text generation\\\")]\\n\\nThe company has popularized [generative pretrained transformers](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer \\\"Generative pre-trained transformer\\\") (GPT).[[33]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-33)\\n\\nOpenAI's _GPT-n_ series | Model | Architecture | Parameter count | Training data | Release date | Training cost |\\n| --- | --- | --- | --- | --- | --- |\\n| [GPT-1](https://en.wikipedia.org/wiki/GPT-1 \\\"GPT-1\\\") | 12-level, 12-headed Transformer decoder (no encoder), followed by linear-softmax | 117 million | [BookCorpus](https://en.wikipedia.org/wiki/BookCorpus \\\"BookCorpus\\\"):[[34]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-34) 4.5 GB of text, from 7,000 unpublished books of various genres. | June 11, 2018[[35]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt1-35) | 30 days on 8 [P600](https://en.wikipedia.org/wiki/Quadro \\\"Quadro\\\") graphics cards, or 1 peta[FLOPS](https://en.wikipedia.org/wiki/FLOPS \\\"FLOPS\\\")-day[[35]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt1-35) |\\n| [GPT-2](https://en.wikipedia.org/wiki/GPT-2 \\\"GPT-2\\\") | GPT-1, but with modified normalization | 1.5 billion | WebText: 40 GB of text, 8 million documents, from 45 million webpages [upvoted](https://en.wikipedia.org/wiki/Upvote \\\"Upvote\\\") on [Reddit](https://en.wikipedia.org/wiki/Reddit \\\"Reddit\\\"). | February 14, 2019 (initial/limited version) and November 5, 2019 (full version)[[36]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-36) | \\\"tens of petaFLOPS-days\\\",[[37]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-LM-37) or 1.5 × 10 21 FLOPS[[38]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-TV-38) |\\n| [GPT-3](https://en.wikipedia.org/wiki/GPT-3 \\\"GPT-3\\\") | GPT-2, but with modifications to allow larger scaling | 175 billion[[39]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-39) | 499 billion tokens consisting of [CommonCrawl](https://en.wikipedia.org/wiki/Common_Crawl \\\"Common Crawl\\\") (570 GB), WebText, English Wikipedia, and two books corpora (Books1 and Books2) | May 28, 2020[[37]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-LM-37) | 3640 petaFLOPS-days (Table D.1[[37]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-LM-37)), or 3.1 × 10 23 FLOPS[[38]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-TV-38) |\\n| [GPT-3.5](https://en.wikipedia.org/wiki/GPT-3.5 \\\"GPT-3.5\\\") | Undisclosed | 175 billion[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation\\\\_needed \\\"Wikipedia:Citation needed\\\")_] | Undisclosed | March 15, 2022 | Undisclosed |\\n| [GPT-4](https://en.wikipedia.org/wiki/GPT-4 \\\"GPT-4\\\") | Also trained with both text prediction and [RLHF](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback \\\"Reinforcement learning from human feedback\\\"); accepts [both text and images](https://en.wikipedia.org/wiki/Multimodal_learning \\\"Multimodal learning\\\") as input. Further details are not public.[[40]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt4-report-40) | Undisclosed. Estimated 1.7 trillion.[[41]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-41) | Undisclosed | March 14, 2023 | Undisclosed. Estimated 2.1 × 10 25 FLOPS.[[38]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-TV-38) |\\n| [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\") | ? | ? | ? | May 13, 2024 | ? |\\n| [GPT-4.5](https://en.wikipedia.org/wiki/GPT-4.5 \\\"GPT-4.5\\\") | ? | ? | ? | February 27, 2025 | ? |\\n| [GPT-4.1](https://en.wikipedia.org/wiki/GPT-4.1 \\\"GPT-4.1\\\") | ? | ? | ? | April 14, 2025 | ? |\\n| [GPT-5](https://en.wikipedia.org/wiki/GPT-5 \\\"GPT-5\\\") | ? | ? | ? | August 7, 2025 | ? |\\n\\n### OpenAI's original GPT model (\\\"GPT-1\\\")\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=10 \\\"Edit section: OpenAI's original GPT model (\\\\\\\"GPT-1\\\\\\\")\\\")]\\n\\nFurther information: [Generative pre-trained transformer §History](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer#History \\\"Generative pre-trained transformer\\\")\\n\\n[![Image 6](https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Full_GPT_architecture.svg/250px-Full_GPT_architecture.svg.png)](https://en.wikipedia.org/wiki/File:Full_GPT_architecture.svg)\\n\\nThe original GPT model\\n\\nThe original paper on generative pre-training of a [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model) \\\"Transformer (machine learning model)\\\")-based language model was written by [Alec Radford](https://en.wikipedia.org/w/index.php?title=Alec_Radford&action=edit&redlink=1 \\\"Alec Radford (page does not exist)\\\") and his colleagues, and published as a preprint on OpenAI's website on June 11, 2018.[[42]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-42) It showed how a [generative model](https://en.wikipedia.org/wiki/Generative_model \\\"Generative model\\\") of language could acquire world knowledge and process long-range dependencies by pre-training on a diverse corpus with long stretches of contiguous text.\\n\\n### GPT-2\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=11 \\\"Edit section: GPT-2\\\")]\\n\\nMain article: [GPT-2](https://en.wikipedia.org/wiki/GPT-2 \\\"GPT-2\\\")\\n\\n[![Image 7](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/GPT2-talks-about-GPT2.png/250px-GPT2-talks-about-GPT2.png)](https://en.wikipedia.org/wiki/File:GPT2-talks-about-GPT2.png)\\n\\nAn instance of GPT-2 writing a paragraph based on a prompt from its own Wikipedia article in February 2021\\n\\nGenerative Pre-trained Transformer 2 (\\\"GPT-2\\\") is an [unsupervised](https://en.wikipedia.org/wiki/Unsupervised_learning \\\"Unsupervised learning\\\")[transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model) \\\"Transformer (machine learning model)\\\")[language model](https://en.wikipedia.org/wiki/Language_model \\\"Language model\\\") and the successor to OpenAI's original GPT model (\\\"GPT-1\\\"). GPT-2 was announced in February 2019, with only limited demonstrative versions initially released to the public. The full version of GPT-2 was not immediately released due to concerns about potential misuse, including applications for writing [fake news](https://en.wikipedia.org/wiki/Fake_news \\\"Fake news\\\").[[43]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt2-not-immediate-release-43) Some experts expressed skepticism that GPT-2 posed a significant threat.\\n\\nIn response to GPT-2, the Allen Institute for Artificial Intelligence responded with a tool to detect \\\"neural fake news\\\".[[44]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-44) Other researchers, such as Jeremy Howard, warned of \\\"the technology to totally fill Twitter, email, and the web up with reasonable-sounding, context-appropriate prose, which would drown out all other speech and be impossible to filter\\\".[[45]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-45) In November 2019, OpenAI released the complete version of the GPT-2 language model.[[46]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-46) Several websites host interactive demonstrations of different instances of GPT-2 and other transformer models.[[47]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-47)[[48]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-48)[[49]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-49)\\n\\nGPT-2's authors argue that unsupervised language models are general-purpose learners, illustrated by GPT-2 achieving state-of-the-art accuracy and [perplexity](https://en.wikipedia.org/wiki/Perplexity \\\"Perplexity\\\") on 7 of 8 [zero-shot](https://en.wikipedia.org/wiki/Zero-shot_learning \\\"Zero-shot learning\\\") tasks (i.e., the model was not further trained on any task-specific input-output examples).\\n\\nThe corpus it was trained on, called WebText, contains slightly 40 gigabytes of text from [URLs](https://en.wikipedia.org/wiki/URL \\\"URL\\\") shared in [Reddit](https://en.wikipedia.org/wiki/Reddit \\\"Reddit\\\") submissions with at least 3 [upvotes](https://en.wikipedia.org/wiki/Upvotes \\\"Upvotes\\\"). It avoids certain issues encoding vocabulary with word tokens by using [byte pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding \\\"Byte pair encoding\\\"). This permits representing any string of characters by encoding both individual characters and multiple-character tokens.[[50]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt2-50)\\n\\n### GPT-3\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=12 \\\"Edit section: GPT-3\\\")]\\n\\nMain article: [GPT-3](https://en.wikipedia.org/wiki/GPT-3 \\\"GPT-3\\\")\\n\\nFirst described in May 2020, Generative Pre-trained[[a]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-51) Transformer 3 (GPT-3) is an unsupervised transformer language model and the successor to [GPT-2](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#GPT-2).[[51]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-52)[[52]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-53)[[53]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt3-54) OpenAI stated that the full version of GPT-3 contained 175 billion [parameters](https://en.wikipedia.org/wiki/Parameter_(machine_learning) \\\"Parameter (machine learning)\\\"),[[53]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt3-54) two [orders of magnitude](https://en.wikipedia.org/wiki/Orders_of_magnitude \\\"Orders of magnitude\\\") larger than the 1.5 billion[[54]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt2-with-quote-55) in the full version of GPT-2 (although GPT-3 models with as few as 125 million parameters were also trained).[[55]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt3-with-compare-quote-56)\\n\\nOpenAI stated that GPT-3 succeeded at certain \\\"[meta-learning](https://en.wikipedia.org/wiki/Meta-learning \\\"Meta-learning\\\")\\\" tasks and could generalize the purpose of a single input-output pair. The GPT-3 release paper gave examples of translation and cross-linguistic [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning \\\"Transfer learning\\\") between English and Romanian, and between English and German.[[53]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt3-54)\\n\\nGPT-3 dramatically improved benchmark results over GPT-2. OpenAI cautioned that such scaling-up of language models could be approaching or encountering the fundamental capability limitations of predictive language models.[[56]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-zdnet-openai-statement-57) Pre-training GPT-3 required several thousand petaflop/s-days[[b]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-59) of compute, compared to tens of petaflop/s-days for the full GPT-2 model.[[53]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt3-54) Like its predecessor,[[43]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt2-not-immediate-release-43) the GPT-3 trained model was not immediately released to the public for concerns of possible abuse, although OpenAI planned to allow access through a paid cloud [API](https://en.wikipedia.org/wiki/Application_programming_interface \\\"Application programming interface\\\") after a two-month free private beta that began in June 2020.[[30]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-gpt3-whynotfullmodel-30)[[58]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-60)\\n\\nOn September 23, 2020, GPT-3 was licensed exclusively to Microsoft.[[59]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-61)[[60]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-62)\\n\\n### Codex\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=13 \\\"Edit section: Codex\\\")]\\n\\nMain article: [OpenAI Codex](https://en.wikipedia.org/wiki/OpenAI_Codex \\\"OpenAI Codex\\\")\\n\\nAnnounced in mid-2021, Codex is a descendant of GPT-3 that has additionally been trained on code from 54 million GitHub repositories,[[61]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-OAI-Codex-63)[[62]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-VB-Codex-64) and is the AI powering the code [autocompletion](https://en.wikipedia.org/wiki/Autocompletion \\\"Autocompletion\\\") tool [GitHub Copilot](https://en.wikipedia.org/wiki/GitHub_Copilot \\\"GitHub Copilot\\\").[[62]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-VB-Codex-64) In August 2021, an API was released in private beta.[[63]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-65) According to OpenAI, the model can create working code in over a dozen programming languages, most effectively in Python.[[61]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-OAI-Codex-63)\\n\\nSeveral issues with glitches, design flaws and security vulnerabilities were cited.[[64]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-66)[[65]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-67)\\n\\nOpenAI announced that they would discontinue support for the Codex API on March 23, 2023.[[66]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-68)\\n\\n### GPT-4\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=14 \\\"Edit section: GPT-4\\\")]\\n\\nMain article: [GPT-4](https://en.wikipedia.org/wiki/GPT-4 \\\"GPT-4\\\")\\n\\nOn March 14, 2023, OpenAI announced the release of Generative Pre-trained Transformer 4 (GPT-4), capable of accepting text or image inputs.[[67]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-69) They announced that the updated technology passed a simulated law school bar exam with a score around the top 10% of test takers. (By contrast, GPT-3.5 scored around the bottom 10%.) They said that GPT-4 could also read, analyze or generate up to 25,000 words of text, and write code in all major programming languages.[[68]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-70)\\n\\nObservers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous GPT-3.5-based iteration, with the caveat that GPT-4 retained some of the problems with earlier revisions.[[69]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-vox-71) GPT-4 is also capable of taking images as input on ChatGPT.[[70]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-72) OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.[[71]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-verge_wrong-73)\\n\\n### GPT-4o\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=15 \\\"Edit section: GPT-4o\\\")]\\n\\nOn May 13, 2024, OpenAI announced and released [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\"), which can process and generate text, images and audio.[[72]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-TechCrunch-74) GPT-4o achieved state-of-the-art results in voice, multilingual, and vision benchmarks, setting new records in audio speech recognition and translation.[[73]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-75)[[74]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-76) It scored 88.7% on the Massive Multitask Language Understanding ([MMLU](https://en.wikipedia.org/wiki/MMLU \\\"MMLU\\\")) benchmark compared to 86.5% by GPT-4.[[75]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Hello_GPT-4o-77)\\n\\nOn July 18, 2024, OpenAI released GPT-4o mini, a smaller version of GPT-4o replacing GPT-3.5 Turbo on the ChatGPT interface. Its [API](https://en.wikipedia.org/wiki/API \\\"API\\\") costs $0.15 per million input tokens and $0.60 per million output tokens, compared to $5 and $15, respectively, for GPT-4o. OpenAI expects it to be particularly useful for enterprises, startups and developers seeking to automate services with AI agents.[[76]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-78)\\n\\nIn March 2025, OpenAI released GPT-4o's native image generation feature, as an alternative to DALL-E 3.[[77]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-79)\\n\\n### GPT-4.5\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=16 \\\"Edit section: GPT-4.5\\\")]\\n\\nOn February 27, 2025, OpenAI released [GPT-4.5](https://en.wikipedia.org/wiki/GPT-4.5 \\\"GPT-4.5\\\"), codenamed Orion. Sam Altman claimed that GPT-4.5 would present inaccurate information less frequently than previous models, and described it as a \\\"giant, expensive model\\\".[[78]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-80)\\n\\n### GPT-4.1\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=17 \\\"Edit section: GPT-4.1\\\")]\\n\\nOn April 14, 2025, OpenAI released the [GPT-4.1](https://en.wikipedia.org/wiki/GPT-4.1 \\\"GPT-4.1\\\") model. They also released two “smaller, faster, and cheaper” models including GPT-4.1 mini and GPT-4.1 nano.[[79]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-81)[[80]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-82)[[81]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-83)\\n\\n### GPT-5\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=18 \\\"Edit section: GPT-5\\\")]\\n\\nMain article: [GPT-5](https://en.wikipedia.org/wiki/GPT-5 \\\"GPT-5\\\")\\n\\nGPT-5 is [OpenAI](https://en.wikipedia.org/wiki/OpenAI \\\"OpenAI\\\")’s flagship model released on August 7, 2025. It replaced earlier models like [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\"), [GPT-4.5](https://en.wikipedia.org/wiki/GPT-4.5 \\\"GPT-4.5\\\"), and [o3](https://en.wikipedia.org/wiki/OpenAI_o3 \\\"OpenAI o3\\\").\\n\\nGPT-5 uses a dynamic router that chooses between quick responses and deeper “thinking” when needed. It can perform at PhD-level across domains like math, coding, health, and multimodal tasks. It also achieved a 74.9% on SWE-bench Verified and 88% on Aider polyglot.[[82]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-84)\\n\\nReporters described the GPT-5 launch as a major milestone moving toward AGI, praising its intelligence, accessibility, and affordability.[[83]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-85)[[84]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-86) But some early feedback called it “evolutionary rather than revolutionary”, noting mixed results in creative writing and pointing to competition from models like [Grok](https://en.wikipedia.org/wiki/Grok_(chatbot) \\\"Grok (chatbot)\\\") 4 Heavy.[[85]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-87)\\n\\n### o1\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=19 \\\"Edit section: o1\\\")]\\n\\nMain article: [OpenAI o1](https://en.wikipedia.org/wiki/OpenAI_o1 \\\"OpenAI o1\\\")\\n\\nOn September 12, 2024, OpenAI released the o1-preview and o1-mini models, which have been designed to take more time to think about their responses, leading to higher accuracy. These models are particularly effective in science, coding, and reasoning tasks, and were made available to ChatGPT Plus and Team members.[[86]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-88)[[87]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-89) In December 2024, o1-preview was replaced by o1.[[88]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-90) In March 2025, the o1-Pro model was made available through OpenAI's developer API, which was previously available to ChatGPT Pro users since December 2024. The pricing is $150 per million input tokens and $600 per million output tokens.[[89]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-91)\\n\\n### o3\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=20 \\\"Edit section: o3\\\")]\\n\\nMain article: [OpenAI o3](https://en.wikipedia.org/wiki/OpenAI_o3 \\\"OpenAI o3\\\")\\n\\nOn December 20, 2024, OpenAI unveiled o3, the successor of the o1 reasoning model. OpenAI also unveiled o3-mini, a lighter and faster version of OpenAI o3. As of December 21, 2024, this model is not available for public use. According to OpenAI, they are testing o3 and o3-mini.[[90]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-92)[[91]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-93) Until January 10, 2025, safety and security researchers had the opportunity to apply for early access to these models.[[92]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-94) The model is called o3 rather than o2 to avoid confusion with telecommunications services provider [O2](https://en.wikipedia.org/wiki/O2_(UK) \\\"O2 (UK)\\\").[[93]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-95) In April 2025, OpenAI released o3 to all the paid users. o3 has enhance reasoning and problem-solving capabilities than o1.[[94]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-96)\\n\\n### Deep research\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=21 \\\"Edit section: Deep research\\\")]\\n\\nMain article: [ChatGPT Deep Research](https://en.wikipedia.org/wiki/ChatGPT_Deep_Research \\\"ChatGPT Deep Research\\\")\\n\\nDeep research is an [AI agent](https://en.wikipedia.org/wiki/AI_agent \\\"AI agent\\\") developed by OpenAI, unveiled on February 2, 2025. It leverages the capabilities of OpenAI's o3 model to perform extensive web browsing, data analysis, and synthesis, delivering comprehensive reports within a timeframe of 5 to 30 minutes.[[95]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Reuters_20250203-97) With browsing and [Python](https://en.wikipedia.org/wiki/Python_(programming_language) \\\"Python (programming language)\\\") tools enabled, it reached an accuracy of 26.6 percent on [HLE (Humanity's Last Exam)](https://en.wikipedia.org/wiki/HLE_(Humanity%27s_Last_Exam) \\\"HLE (Humanity's Last Exam)\\\") benchmark.[[96]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Verge_20250203-98) In April 2025, OpenAI started rolling out a lightweight version of Deep Research to all its ChatGPT free users.[[97]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-99)[[98]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-100)\\n\\n### GPT-OSS\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=22 \\\"Edit section: GPT-OSS\\\")]\\n\\nGPT-OSS (stylized as gpt-oss) is a set of open-weight reasoning models released by OpenAI on August 5, 2025.[[99]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-:1-101)[[100]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-102) Currently, they come in two variants—a larger 117-billion-parameter model called gpt-oss-120b and a smaller 21-billion-parameter model called gpt-oss-20b.[[101]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-:0-103) Both models are released under an [Apache 2.0 licence](https://en.wikipedia.org/wiki/Apache_License \\\"Apache License\\\"), allowing commercial and non-commercial use. In terms of performance, they are comparable to [o4-mini](https://en.wikipedia.org/wiki/OpenAI_o4-mini \\\"OpenAI o4-mini\\\") and [o3-mini](https://en.wikipedia.org/wiki/OpenAI_o3 \\\"OpenAI o3\\\") respectively, according to OpenAI.[[101]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-:0-103)\\n\\nImage classification\\n--------------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=23 \\\"Edit section: Image classification\\\")]\\n\\n### CLIP\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=24 \\\"Edit section: CLIP\\\")]\\n\\nMain article: [Contrastive Language-Image Pre-training](https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre-training \\\"Contrastive Language-Image Pre-training\\\")\\n\\nRevealed in 2021, CLIP (Contrastive Language–Image Pre-training) is a model that is trained to analyze the semantic similarity between text and images. It can notably be used for image classification.[[102]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-104)\\n\\nText-to-image\\n-------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=25 \\\"Edit section: Text-to-image\\\")]\\n\\nMain article: [DALL-E](https://en.wikipedia.org/wiki/DALL-E \\\"DALL-E\\\")\\n\\n### DALL-E\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=26 \\\"Edit section: DALL-E\\\")]\\n\\n[![Image 8](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/DALL-E_sample.png/330px-DALL-E_sample.png)](https://en.wikipedia.org/wiki/File:DALL-E_sample.png)\\n\\nImages produced in 2021 by DALL-E when given the text prompt \\\"a professional high-quality illustration of a giraffe dragon chimera. a giraffe imitating a dragon. a giraffe made of dragon.\\\"\\n\\nRevealed in 2021, DALL-E is a Transformer model that creates images from textual descriptions.[[103]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-105) DALL-E uses a 12-billion-parameter version of GPT-3 to interpret natural language inputs (such as \\\"a green leather purse shaped like a pentagon\\\" or \\\"an isometric view of a sad capybara\\\") and generate corresponding images. It can create images of realistic objects (\\\"a stained-glass window with an image of a blue strawberry\\\") as well as objects that do not exist in reality (\\\"a cube with the texture of a porcupine\\\"). As of March 2021, no API or code is available.\\n\\n#### DALL-E 2\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=27 \\\"Edit section: DALL-E 2\\\")]\\n\\nIn April 2022, OpenAI announced DALL-E 2, an updated version of the model with more realistic results.[[104]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-106) In December 2022, OpenAI published on GitHub software for Point-E, a new rudimentary system for converting a text description into a 3-dimensional model.[[105]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-107)\\n\\n#### DALL-E 3\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=28 \\\"Edit section: DALL-E 3\\\")]\\n\\nIn September 2023, OpenAI announced DALL-E 3, a more powerful model better able to generate images from complex descriptions without manual prompt engineering and render complex details like hands and text.[[106]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-108) It was released to the public as a ChatGPT Plus feature in October.[[107]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-109)\\n\\nText-to-video\\n-------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=29 \\\"Edit section: Text-to-video\\\")]\\n\\n### Sora\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=30 \\\"Edit section: Sora\\\")]\\n\\nMain article: [Sora (text-to-video model)](https://en.wikipedia.org/wiki/Sora_(text-to-video_model) \\\"Sora (text-to-video model)\\\")\\n\\nSora is a [text-to-video](https://en.wikipedia.org/wiki/Text-to-video \\\"Text-to-video\\\") model that can generate videos based on short descriptive prompts[[108]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-NYT_CM_2024_02_15-110) as well as extend existing videos forwards or backwards in time.[[109]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-world_sim-111) It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown.\\n\\nSora's development team named it after the [Japanese](https://en.wikipedia.org/wiki/Japanese_language \\\"Japanese language\\\") word for \\\"sky\\\", to signify its \\\"limitless creative potential\\\".[[108]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-NYT_CM_2024_02_15-110) Sora's technology is an adaptation of the technology behind the [DALL·E 3](https://en.wikipedia.org/wiki/DALL%C2%B7E_3 \\\"DALL·E 3\\\")[text-to-image model](https://en.wikipedia.org/wiki/Text-to-image_model \\\"Text-to-image model\\\").[[110]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-WDH_MIT_2024_02_15-112) OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos.[[108]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-NYT_CM_2024_02_15-110)\\n\\nOpenAI demonstrated some Sora-created [high-definition videos](https://en.wikipedia.org/wiki/High-definition_video \\\"High-definition video\\\") to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model's capabilities.[[110]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-WDH_MIT_2024_02_15-112) It acknowledged some of its shortcomings, including struggles simulating complex physics.[[111]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-113) Will Douglas Heaven of the _[MIT Technology Review](https://en.wikipedia.org/wiki/MIT\\\\_Technology\\\\_Review \\\"MIT Technology Review\\\")_ called the demonstration videos \\\"impressive\\\", but noted that they must have been cherry-picked and might not represent Sora's typical output.[[110]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-WDH_MIT_2024_02_15-112)\\n\\nDespite skepticism from some academic leaders following Sora's public demo, notable entertainment-industry figures have shown significant interest in the technology's potential. In an interview, actor/filmmaker [Tyler Perry](https://en.wikipedia.org/wiki/Tyler_Perry \\\"Tyler Perry\\\") expressed his astonishment at the technology's ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora's possibilities was so strong that he had decided to pause plans for expanding his [Atlanta-based movie studio](https://en.wikipedia.org/wiki/Tyler_Perry_Studios \\\"Tyler Perry Studios\\\").[[112]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-114)\\n\\nSora 2 was unveiled on September 30, 2025, with an [iOS](https://en.wikipedia.org/wiki/IOS \\\"IOS\\\") app at the same time.[[113]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-115)\\n\\nSpeech-to-text\\n--------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=31 \\\"Edit section: Speech-to-text\\\")]\\n\\n### Whisper\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=32 \\\"Edit section: Whisper\\\")]\\n\\nMain article: [Whisper (speech recognition system)](https://en.wikipedia.org/wiki/Whisper_(speech_recognition_system) \\\"Whisper (speech recognition system)\\\")\\n\\nReleased in 2022, Whisper is a general-purpose speech recognition model.[[114]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-116) It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.[[115]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Radford_Kim_Xu_Brockman_p.-117)\\n\\nMusic generation\\n----------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=33 \\\"Edit section: Music generation\\\")]\\n\\n### MuseNet\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=34 \\\"Edit section: MuseNet\\\")]\\n\\nReleased in 2019, MuseNet is a deep neural net trained to predict subsequent musical notes in [MIDI](https://en.wikipedia.org/wiki/MIDI \\\"MIDI\\\") music files. It can generate songs with 10 instruments in 15 styles. According to _The Verge_, a song generated by MuseNet tends to start reasonably but then fall into chaos the longer it plays.[[116]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-118)[[117]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-119) In pop culture, initial applications of this tool were used as early as 2020 for the internet psychological thriller [Ben Drowned](https://en.wikipedia.org/wiki/Ben_Drowned \\\"Ben Drowned\\\") to create music for the titular character.[[118]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-120)[[119]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-121)\\n\\n### Jukebox\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=35 \\\"Edit section: Jukebox\\\")]\\n\\nReleased in 2020, Jukebox is an open-sourced algorithm to [generate music](https://en.wikipedia.org/wiki/Computer_music \\\"Computer music\\\") with vocals. After training on 1.2 million samples, the system accepts a genre, an artist, and a snippet of lyrics and outputs song samples. OpenAI stated the songs \\\"show local musical coherence [and] follow traditional chord patterns\\\" but acknowledged that the songs lack \\\"familiar larger musical structures such as choruses that repeat\\\" and that \\\"there is a significant gap\\\" between Jukebox and human-generated music. _The Verge_ stated \\\"It's technologically impressive, even if the results sound like mushy versions of songs that might feel familiar\\\", while _[Business Insider](https://en.wikipedia.org/wiki/Business\\\\_Insider \\\"Business Insider\\\")_ stated \\\"surprisingly, some of the resulting songs are catchy and sound legitimate\\\".[[120]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-122)[[121]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-123)[[122]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-124)\\n\\nUser interfaces\\n---------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=36 \\\"Edit section: User interfaces\\\")]\\n\\n### Debate Game\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=37 \\\"Edit section: Debate Game\\\")]\\n\\nIn 2018, OpenAI launched the Debate Game, which teaches machines to debate [toy problems](https://en.wikipedia.org/wiki/Toy_problem \\\"Toy problem\\\") in front of a human judge. The purpose is to research whether such an approach may assist in auditing AI decisions and in developing [explainable AI](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence \\\"Explainable artificial intelligence\\\").[[123]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-125)[[124]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-126)\\n\\n### Microscope\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=38 \\\"Edit section: Microscope\\\")]\\n\\nReleased in 2020, Microscope[[125]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-127) is a collection of visualizations of every significant layer and neuron of eight neural network models which are often studied in interpretability.[[126]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-128) Microscope was created to analyze the features that form inside these neural networks easily. The models included are [AlexNet](https://en.wikipedia.org/wiki/AlexNet \\\"AlexNet\\\"), [VGG-19](https://en.wikipedia.org/wiki/VGG-19 \\\"VGG-19\\\"), different versions of [Inception](https://en.wikipedia.org/wiki/Inceptionv3 \\\"Inceptionv3\\\"), and different versions of [CLIP](https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre-training \\\"Contrastive Language-Image Pre-training\\\")[Resnet](https://en.wikipedia.org/wiki/Residual_neural_network \\\"Residual neural network\\\").[[127]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-129)\\n\\n### ChatGPT\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=39 \\\"Edit section: ChatGPT\\\")]\\n\\nMain article: [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT \\\"ChatGPT\\\")\\n\\n[![Image 9](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/OpenAI_logo_2025_%28symbol%29.svg/250px-OpenAI_logo_2025_%28symbol%29.svg.png)](https://en.wikipedia.org/wiki/File:OpenAI_logo_2025_(symbol).svg)\\n\\nOpenAI's \\\"Blossom\\\" is used as a symbol for ChatGPT and the company.\\n\\nLaunched in November 2022, ChatGPT is a [generative AI](https://en.wikipedia.org/wiki/Generative_AI \\\"Generative AI\\\")[chatbot](https://en.wikipedia.org/wiki/Chatbot \\\"Chatbot\\\") that uses OpenAI's GPT models to generate content. Users can interact with it through text or voice conversations. It can generate images using [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\"), which replaced [DALL-E 3](https://en.wikipedia.org/wiki/DALL-E_3 \\\"DALL-E 3\\\").[[128]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-130) ChatGPT gained 100 million users during the two months following its launch.[[129]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-:8-131)\\n\\nOpenAI launched multiple subscription plans: Plus, Pro, Team, and Enterprise. Users on ChatGPT's free tier can access [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\"), but at a reduced limit. The ChatGPT subscriptions \\\"Plus\\\", \\\"Pro\\\", \\\"Team\\\", and \\\"Enterprise\\\" provide increased usage limits and access to additional features or models.[[130]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-132)\\n\\nIn May 2023, OpenAI launched a user interface for ChatGPT for the [App Store](https://en.wikipedia.org/wiki/App_Store_(Apple) \\\"App Store (Apple)\\\") on iOS and later in July 2023 for the [Play Store](https://en.wikipedia.org/wiki/Google_Play \\\"Google Play\\\") on Android.[[131]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-verge-android-133) In December 2024, OpenAI launched a new feature allowing users to call ChatGPT for up to 15 minutes per month for free.[[132]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-134)[[133]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-135)\\n\\n### SearchGPT\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=40 \\\"Edit section: SearchGPT\\\")]\\n\\nMain article: [SearchGPT](https://en.wikipedia.org/wiki/SearchGPT \\\"SearchGPT\\\")\\n\\nSearchGPT, a prototype [search engine](https://en.wikipedia.org/wiki/Search_engine \\\"Search engine\\\") developed by OpenAI, was unveiled on July 25, 2024, with an initial limited release to 10,000 test users. It combines traditional search engine features with generative AI capabilities.[[134]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-136)[[135]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-137)\\n\\n### ChatGPT Atlas\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=41 \\\"Edit section: ChatGPT Atlas\\\")]\\n\\nMain article: [ChatGPT Atlas](https://en.wikipedia.org/wiki/ChatGPT_Atlas \\\"ChatGPT Atlas\\\")\\n\\nIn October 2025, OpenAI released a [web browser](https://en.wikipedia.org/wiki/Web_browser \\\"Web browser\\\") called ChatGPT Atlas.[[136]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-138)[[137]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-139)\\n\\nStargate and other supercomputers\\n---------------------------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=42 \\\"Edit section: Stargate and other supercomputers\\\")]\\n\\nUnveiled in 2024, Stargate was initially a $100 billion project between OpenAI and [Microsoft](https://en.wikipedia.org/wiki/Microsoft \\\"Microsoft\\\") to build data-centers.[[138]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Bajwa-2024-140) The name \\\"Stargate\\\" is a [homage](https://en.wikipedia.org/wiki/Homage_(arts) \\\"Homage (arts)\\\") to the 1994 sci-fi film [_Stargate_](https://en.wikipedia.org/wiki/Stargate_(film) \\\"Stargate (film)\\\").[[139]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-The_Information-2024-141) It eventually became a company, [Stargate LLC](https://en.wikipedia.org/wiki/Stargate_LLC \\\"Stargate LLC\\\"), which was founded in January 2025 as a partnership between OpenAI, [Oracle](https://en.wikipedia.org/wiki/Oracle_Corporation \\\"Oracle Corporation\\\"), [SoftBank](https://en.wikipedia.org/wiki/SoftBank_Group \\\"SoftBank Group\\\") and [MGX](https://en.wikipedia.org/wiki/MGX_Fund_Management_Limited \\\"MGX Fund Management Limited\\\").[[140]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-142)[[138]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-Bajwa-2024-140)\\n\\nHardware development\\n--------------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=43 \\\"Edit section: Hardware development\\\")]\\n\\nOn May 21, 2025, OpenAI announced the acquisition of io, an AI hardware startup founded by former Apple designer [Jony Ive](https://en.wikipedia.org/wiki/Jony_Ive \\\"Jony Ive\\\").[[141]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-OpenAI-Sam_and_Jony-143) The deal, valued at approximately $6.5 billion, marks OpenAI's strategic entry into the consumer hardware market.[[142]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-144) Ive, known for designing the [iPhone](https://en.wikipedia.org/wiki/IPhone \\\"IPhone\\\"), [iPad](https://en.wikipedia.org/wiki/IPad \\\"IPad\\\") and [iMac](https://en.wikipedia.org/wiki/IMac \\\"IMac\\\"), will lead hardware and design efforts for OpenAI.[[143]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-145)\\n\\nOpenAI CEO Sam Altman and Ive have expressed a shared vision for developing AI-native devices that go beyond conventional screens and interfaces. Though specific product details have not been released, the Washington Post reports that Ive and Altman have already been working on a new product. \\\"The first one I’ve been working on has just completely captured my imagination,” said Jony Ive. Altman added, “I think it is the coolest piece of technology that the world will have ever seen.”[[144]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-146)[[141]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-OpenAI-Sam_and_Jony-143)\\n\\nThe company has also started to work in the robotics space with the goal of creating general purpose robots.[[145]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-147)\\n\\nSelected bibliography\\n---------------------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=44 \\\"Edit section: Selected bibliography\\\")]\\n\\nThis section lists the main official publications from OpenAI on its GPT models.\\n\\n*   GPT-1: report, GitHub release.[[146]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-148)\\n*   GPT-2: blog announcement,[[147]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-149) report on its decision of \\\"staged release\\\",[[148]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-150) GitHub release.[[149]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-151)\\n*   GPT-3: report.[[150]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-LM2-152) No GitHub or any other form of code release thenceforth.\\n*   WebGPT: blog announcement,[[151]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-153) report.[[152]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-154)\\n*   InstructGPT: blog announcement,[[153]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-155) report.[[154]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-156)\\n*   ChatGPT: blog announcement[[155]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-157) (no report).\\n*   GPT-4: blog announcement,[[156]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-158) reports,[[157]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-159)[[158]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-160) model card.[[159]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-161)\\n*   GPT-4o: blog announcement.[[160]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-162)\\n*   GPT-4.5: blog announcement.[[161]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-163)\\n*   GPT-4.1: blog announcement.[[162]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-164)\\n*   GPT-OSS: blog announcement,[[99]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-:1-101) model card.[[101]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-:0-103)\\n*   GPT-5: blog announcement.[[163]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-165)\\n\\nSee also\\n--------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=45 \\\"Edit section: See also\\\")]\\n\\n*   [List of large language models](https://en.wikipedia.org/wiki/List_of_large_language_models \\\"List of large language models\\\")\\n\\nNotes\\n-----\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=46 \\\"Edit section: Notes\\\")]\\n\\n1.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-51)**The term \\\"pre-training\\\" refers to general language training as distinct from fine-tuning for specific tasks.\\n2.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-59)**One petaflop/s-day is approximately equal to 10 20 neural net operations.[[57]](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_note-58)\\n\\nReferences\\n----------\\n\\n[[edit](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&action=edit&section=47 \\\"Edit section: References\\\")]\\n\\n1.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-1)**Wiggers, Kyle (July 16, 2021). [\\\"OpenAI disbands its robotics research team\\\"](https://venturebeat.com/business/openai-disbands-its-robotics-research-team/). _VentureBeat_. [Archived](https://web.archive.org/web/20230212150930/https://venturebeat.com/business/openai-disbands-its-robotics-research-team/) from the original on February 12, 2023. Retrieved February 12, 2023.\\n2.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-2)**Lee, Dave (October 15, 2019). [\\\"Robot solves Rubik's cube, but not grand challenge\\\"](https://www.bbc.com/news/technology-50064225). _BBC News_. [Archived](https://web.archive.org/web/20200403202722/https://www.bbc.com/news/technology-50064225) from the original on April 3, 2020. Retrieved February 29, 2020.\\n3.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Dave_Gershgorn-2016_3-0)**Dave Gershgorn (April 27, 2016). [\\\"Elon Musk's Artificial Intelligence Group Opens A 'Gym' To Train A.I.\\\"](http://www.popsci.com/elon-musks-artificial-intelligence-group-opens-gym-to-train-ai)_Popular Science_. [Archived](https://web.archive.org/web/20160430045139/http://www.popsci.com/elon-musks-artificial-intelligence-group-opens-gym-to-train-ai) from the original on April 30, 2016. Retrieved April 29, 2016.\\n4.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-4)**Greg Brockman; John Schulman (April 27, 2016). [\\\"OpenAI Gym Beta\\\"](https://openai.com/blog/openai-gym-beta/). _OpenAI Blog_. OpenAI. [Archived](https://web.archive.org/web/20190226173517/https://openai.com/blog/openai-gym-beta/) from the original on February 26, 2019. Retrieved April 29, 2016.\\n5.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-5)**[\\\"openai/gym\\\"](https://github.com/openai/gym). _GitHub_. [Archived](https://web.archive.org/web/20240823033813/https://github.com/openai/gym) from the original on August 23, 2024. Retrieved August 29, 2024. The team that has been maintaining Gym since 2021 has moved all future development to Gymnasium, a drop in replacement for Gym (import gymnasium as gym), and Gym will not be receiving any future updates.\\n6.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-6)**[\\\"Announcing The Farama Foundation - The future of open source reinforcement learning\\\"](https://farama.org/Announcing-The-Farama-Foundation). _The Farama Foundation_. October 25, 2022. [Archived](https://web.archive.org/web/20240829061404/https://farama.org/Announcing-The-Farama-Foundation) from the original on August 29, 2024. Retrieved August 29, 2024.\\n7.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-7)**[\\\"Gym Retro\\\"](https://openai.com/blog/gym-retro/). _OpenAI_. May 25, 2018. [Archived](https://web.archive.org/web/20230212155510/https://openai.com/blog/gym-retro/) from the original on February 12, 2023. Retrieved February 12, 2023.\\n8.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Wired-2017_8-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Wired-2017_8-1)[_**c**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Wired-2017_8-2)[\\\"AI Sumo Wrestlers Could Make Future Robots More Nimble\\\"](https://www.wired.com/story/ai-sumo-wrestlers-could-make-future-robots-more-nimble/). _Wired_. October 11, 2017. [Archived](https://web.archive.org/web/20171107024652/https://www.wired.com/story/ai-sumo-wrestlers-could-make-future-robots-more-nimble/) from the original on November 7, 2017. Retrieved November 2, 2017.\\n9.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-9)**[\\\"OpenAI's Goofy Sumo-Wrestling Bots Are Smarter Than They Look\\\"](https://www.technologyreview.com/the-download/609117/openais-goofy-sumo-wrestling-bots-are-smarter-than-they-look/). _MIT Technology Review_. [Archived](https://web.archive.org/web/20181109021143/https://www.technologyreview.com/the-download/609117/openais-goofy-sumo-wrestling-bots-are-smarter-than-they-look/) from the original on November 9, 2018. Retrieved November 2, 2017.\\n10.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-10)**Savov, Vlad (August 14, 2017). [\\\"My favorite game has been invaded by killer AI bots and Elon Musk hype\\\"](https://www.theverge.com/2017/8/14/16141938/dota-2-openai-bots-elon-musk-artificial-intelligence). _The Verge_. [Archived](https://web.archive.org/web/20180626030145/https://www.theverge.com/2017/8/14/16141938/dota-2-openai-bots-elon-musk-artificial-intelligence) from the original on June 26, 2018. Retrieved June 25, 2018.\\n11.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-11)**Frank, Blair Hanley. [\\\"OpenAI's bot beats top Dota 2 player so badly that he quits\\\"](https://web.archive.org/web/20170812065202/https://venturebeat.com/2017/08/11/openais-bot-beats-top-dota-2-player-so-badly-that-he-quits/). _Venture Beat_. Archived from [the original](https://venturebeat.com/2017/08/11/openais-bot-beats-top-dota-2-player-so-badly-that-he-quits/) on August 12, 2017. Retrieved August 12, 2017.\\n12.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-12)**[\\\"Dota 2\\\"](https://blog.openai.com/dota-2/). _blog.openai.com_. August 11, 2017. [Archived](https://web.archive.org/web/20170811235617/https://blog.openai.com/dota-2/) from the original on August 11, 2017. Retrieved August 12, 2017.\\n13.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-13)**[\\\"More on Dota 2\\\"](https://blog.openai.com/more-on-dota-2/). _blog.openai.com_. August 16, 2017. [Archived](https://web.archive.org/web/20190223171009/https://blog.openai.com/more-on-dota-2/) from the original on February 23, 2019. Retrieved August 16, 2017.\\n14.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Simonite_14-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Simonite_14-1)Simonite, Tom. [\\\"Can Bots Outwit Humans in One of the Biggest Esports Games?\\\"](https://www.wired.com/story/can-bots-outwit-humans-in-one-of-the-biggest-esports-games/). _Wired_. [Archived](https://web.archive.org/web/20180625213810/https://www.wired.com/story/can-bots-outwit-humans-in-one-of-the-biggest-esports-games/) from the original on June 25, 2018. Retrieved June 25, 2018.\\n15.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-15)**Kahn, Jeremy (June 25, 2018). [\\\"A Bot Backed by Elon Musk Has Made an AI Breakthrough in Video Game World\\\"](https://www.bloomberg.com/news/articles/2018-06-25/musk-backed-bot-conquers-e-gamer-teams-in-ai-breakthrough). _Bloomberg.com_. Bloomberg L.P. [Archived](https://web.archive.org/web/20180627144300/https://www.bloomberg.com/news/articles/2018-06-25/musk-backed-bot-conquers-e-gamer-teams-in-ai-breakthrough) from the original on June 27, 2018. Retrieved June 27, 2018.\\n16.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-16)**Clifford, Catherine (June 28, 2018). [\\\"Bill Gates says gamer bots from Elon Musk-backed nonprofit are 'huge milestone' in A.I.\\\"](https://www.cnbc.com/2018/06/27/bill-gates-openai-robots-beating-humans-at-dota-2-is-ai-milestone.html) CNBC. [Archived](https://web.archive.org/web/20180628231125/https://www.cnbc.com/2018/06/27/bill-gates-openai-robots-beating-humans-at-dota-2-is-ai-milestone.html) from the original on June 28, 2018. Retrieved June 29, 2018.\\n17.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-17)**[\\\"OpenAI Five Benchmark\\\"](https://blog.openai.com/openai-five-benchmark/). _blog.openai.com_. July 18, 2018. [Archived](https://web.archive.org/web/20190213165905/https://blog.openai.com/openai-five-benchmark/) from the original on February 13, 2019. Retrieved August 25, 2018.\\n18.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-18)**Vincent, James (June 25, 2018). [\\\"AI bots trained for 180 years a day to beat humans at Dota 2\\\"](https://www.theverge.com/2018/6/25/17492918/openai-dota-2-bot-ai-five-5v5-matches). _The Verge_. [Archived](https://web.archive.org/web/20180625183203/https://www.theverge.com/2018/6/25/17492918/openai-dota-2-bot-ai-five-5v5-matches) from the original on June 25, 2018. Retrieved June 25, 2018.\\n19.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-19)**Savov, Vlad (August 6, 2018). [\\\"The OpenAI Dota 2 bots just defeated a team of former pros\\\"](https://www.theverge.com/2018/8/6/17655086/dota2-openai-bots-professional-gaming-ai). _The Verge_. [Archived](https://web.archive.org/web/20180807113227/https://www.theverge.com/2018/8/6/17655086/dota2-openai-bots-professional-gaming-ai) from the original on August 7, 2018. Retrieved August 7, 2018.\\n20.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-20)**Simonite, Tom. [\\\"Pro Gamers Fend off Elon Musk-Backed AI Bots—for Now\\\"](https://www.wired.com/story/pro-gamers-fend-off-elon-musks-ai-bots/). _Wired_. [Archived](https://web.archive.org/web/20180824120523/https://www.wired.com/story/pro-gamers-fend-off-elon-musks-ai-bots/) from the original on August 24, 2018. Retrieved August 25, 2018.\\n21.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-21)**Quach, Katyanna. [\\\"Game over, machines: Humans defeat OpenAI bots once again at video games Olympics\\\"](https://www.theregister.co.uk/2018/08/24/openai_bots_eliminated_dota_2/). _The Register_. [Archived](https://web.archive.org/web/20180825110329/https://www.theregister.co.uk/2018/08/24/openai_bots_eliminated_dota_2/) from the original on August 25, 2018. Retrieved August 25, 2018.\\n22.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-22)**[\\\"The International 2018: Results\\\"](https://blog.openai.com/the-international-2018-results/). _blog.openai.com_. August 24, 2018. [Archived](https://web.archive.org/web/20180824131639/https://blog.openai.com/the-international-2018-results/) from the original on August 24, 2018. Retrieved August 25, 2018.\\n23.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-23)**Statt, Nick (April 13, 2019). [\\\"OpenAI's Dota 2 AI steamrolls world champion e-sports team with back-to-back victories\\\"](https://www.theverge.com/2019/4/13/18309459/openai-five-dota-2-finals-ai-bot-competition-og-e-sports-the-international-champion). _The Verge_. [Archived](https://web.archive.org/web/20190415011925/https://www.theverge.com/2019/4/13/18309459/openai-five-dota-2-finals-ai-bot-competition-og-e-sports-the-international-champion) from the original on April 15, 2019. Retrieved July 20, 2019.\\n24.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-24)**[\\\"How to Train Your OpenAI Five\\\"](https://openai.com/blog/how-to-train-your-openai-five/). _OpenAI Blog_. April 15, 2019. [Archived](https://web.archive.org/web/20190630013455/https://openai.com/blog/how-to-train-your-openai-five/) from the original on June 30, 2019. Retrieved July 20, 2019.\\n25.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-25)**Wiggers, Kyle (April 22, 2019). [\\\"OpenAI's Dota 2 bot defeated 99.4% of players in public matches\\\"](https://venturebeat.com/2019/04/22/openais-dota-2-bot-defeated-99-4-of-players-in-public-matches/). _Venture Beat_. [Archived](https://web.archive.org/web/20190711151127/https://venturebeat.com/2019/04/22/openais-dota-2-bot-defeated-99-4-of-players-in-public-matches/) from the original on July 11, 2019. Retrieved April 22, 2019.\\n26.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-26)**Fangasadha, Edbert Felix; Soeroredjo, Steffi; Anderies; Gunawan, Alexander Agung Santoso (September 17, 2022). \\\"Literature Review of OpenAI Five's Mechanisms in Dota 2's Bot Player\\\". _2022 International Seminar on Application for Technology of Information and Communication (ISemantic)_. IEEE. pp.183–190. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) \\\"Doi (identifier)\\\"):[10.1109/iSemantic55962.2022.9920480](https://doi.org/10.1109%2FiSemantic55962.2022.9920480). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) \\\"ISBN (identifier)\\\")[978-1-6654-8837-2](https://en.wikipedia.org/wiki/Special:BookSources/978-1-6654-8837-2 \\\"Special:BookSources/978-1-6654-8837-2\\\"). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) \\\"S2CID (identifier)\\\")[253047170](https://api.semanticscholar.org/CorpusID:253047170).\\n27.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-27)**Vincent, James (July 30, 2018). [\\\"OpenAI sets new benchmark for robot dexterity\\\"](https://www.theverge.com/2018/7/30/17621112/openai-robot-dexterity-dactyl-artificial-intelligence). _The Verge_. [Archived](https://web.archive.org/web/20230212152342/https://www.theverge.com/2018/7/30/17621112/openai-robot-dexterity-dactyl-artificial-intelligence) from the original on February 12, 2023. Retrieved February 12, 2023.\\n28.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-28)**OpenAI; Andrychowicz, Marcin; Baker, Bowen; Chociej, Maciej; Józefowicz, Rafał; McGrew, Bob; Pachocki, Jakub; Petron, Arthur; Plappert, Matthias; Powell, Glenn; Ray, Alex; Schneider, Jonas; Sidor, Szymon; Tobin, Josh; Welinder, Peter; Weng, Lilian; Zaremba, Wojciech (2019). \\\"Learning Dexterous In-Hand Manipulation\\\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[1808.00177v5](https://arxiv.org/abs/1808.00177v5) [[cs.LG](https://arxiv.org/archive/cs.LG)].\\n29.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-29)**OpenAI; Akkaya, Ilge; Andrychowicz, Marcin; Chociej, Maciek; Litwin, Mateusz; McGrew, Bob; Petron, Arthur; Paino, Alex; Plappert, Matthias; Powell, Glenn; Ribas, Raphael (2019). \\\"Solving Rubik's Cube with a Robot Hand\\\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[1910.07113v1](https://arxiv.org/abs/1910.07113v1) [[cs.LG](https://arxiv.org/archive/cs.LG)].\\n30.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt3-whynotfullmodel_30-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt3-whynotfullmodel_30-1)[\\\"OpenAI API\\\"](https://openai.com/blog/openai-api/). _OpenAI_. June 11, 2020. [Archived](https://web.archive.org/web/20200611150951/https://openai.com/blog/openai-api/) from the original on June 11, 2020. Retrieved June 14, 2020. Why did OpenAI choose to release an API instead of open-sourcing the models?\\n\\nThere are three main reasons we did this. First, commercializing the technology helps us pay for our ongoing AI research, safety, and policy efforts. Second, many of the models underlying the API are very large, taking a lot of expertise to develop and deploy and making them very expensive to run. This makes it hard for anyone except larger companies to benefit from the underlying technology. We're hopeful that the API will make powerful AI systems more accessible to smaller businesses and organizations. Third, the API model allows us to more easily respond to misuse of the technology. Since it is hard to predict the downstream use cases of our models, it feels inherently safer to release them via an API and broaden access over time, rather than release an [open source](https://en.wikipedia.org/wiki/Open_source \\\"Open source\\\") model where access cannot be adjusted if it turns out to have harmful applications.\\n31.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-tech_Tech_31-0)**Coldewey, Devin (June 11, 2020). [\\\"OpenAI makes an all-purpose API for its text-based AI capabilities\\\"](https://techcrunch.com/2020/06/11/openai-makes-an-all-purpose-api-for-its-text-based-ai-capabilities/). _TechCrunch_. [Archived](https://web.archive.org/web/20200612041855/https://techcrunch.com/2020/06/11/openai-makes-an-all-purpose-api-for-its-text-based-ai-capabilities/) from the original on June 12, 2020. Retrieved June 11, 2020. If you've ever wanted to try out OpenAI's vaunted machine learning toolset, it just got a lot easier. The company has released an API that lets developers call its AI tools in on \\\"virtually any English language task.\\\"\\n32.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-32)**Hawley, Michelle. [\\\"OpenAI Launches AgentKit to Streamline AI Agent Development\\\"](https://www.vktr.com/ai-news/openai-launches-agentkit-to-streamline-ai-agent-development/). _VKTR.com_. Retrieved 2025-10-06.\\n33.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-33)**[\\\"GPT-1 to GPT-4: Each of OpenAI's GPT Models Explained and Compared\\\"](https://www.makeuseof.com/gpt-models-explained-and-compared/). April 11, 2023. [Archived](https://web.archive.org/web/20230415175013/https://www.makeuseof.com/gpt-models-explained-and-compared/) from the original on April 15, 2023. Retrieved April 29, 2023.\\n34.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-34)**Zhu, Yukun; Kiros, Ryan; Zemel, Rich; Salakhutdinov, Ruslan; Urtasun, Raquel; Torralba, Antonio; Fidler, Sanja (2015). [_Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books_](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html). IEEE International Conference on Computer Vision (ICCV) 2015. pp.19–27. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[1506.06724](https://arxiv.org/abs/1506.06724). [Archived](https://web.archive.org/web/20230205222219/https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html) from the original on February 5, 2023. Retrieved February 7, 2023.\\n35.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt1_35-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt1_35-1)[\\\"Improving language understanding with unsupervised learning\\\"](https://openai.com/research/language-unsupervised). _openai.com_. June 11, 2018. [Archived](https://web.archive.org/web/20230318210736/https://openai.com/research/language-unsupervised) from the original on March 18, 2023. Retrieved March 18, 2023.\\n36.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-36)**Vincent, James (November 7, 2019). [\\\"OpenAI has published the text-generating AI it said was too dangerous to share\\\"](https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters). _The Verge_. [Archived](https://web.archive.org/web/20200611054114/https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters) from the original on June 11, 2020. Retrieved April 28, 2023.\\n37.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-LM_37-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-LM_37-1)[_**c**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-LM_37-2)Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (May 28, 2020). \\\"Language Models are Few-Shot Learners\\\". _NeurIPS_. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2005.14165v4](https://arxiv.org/abs/2005.14165v4).\\n38.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-TV_38-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-TV_38-1)[_**c**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-TV_38-2)[\\\"ML input trends visualization\\\"](https://epochai.org/mlinputs/visualization). _Epoch_. [Archived](https://web.archive.org/web/20230716134652/https://epochai.org/mlinputs/visualization) from the original on July 16, 2023. Retrieved May 2, 2023.\\n39.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-39)**Ver Meer, Dave (June 1, 2023). [\\\"ChatGPT Statistics\\\"](https://www.namepepper.com/chatgpt-users). _NamePepper_. [Archived](https://web.archive.org/web/20230605230914/https://www.namepepper.com/chatgpt-users) from the original on June 5, 2023. Retrieved June 9, 2023.\\n40.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt4-report_40-0)**OpenAI (2023). [\\\"GPT-4 Technical Report\\\"](https://cdn.openai.com/papers/gpt-4.pdf)(PDF). [Archived](https://web.archive.org/web/20230314190904/https://cdn.openai.com/papers/gpt-4.pdf)(PDF) from the original on March 14, 2023. Retrieved March 16, 2023.\\n41.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-41)**[\\\"GPT-4 has more than a trillion parameters – Report\\\"](https://the-decoder.com/gpt-4-has-a-trillion-parameters/). March 25, 2023. [Archived](https://web.archive.org/web/20240304161007/https://the-decoder.com/gpt-4-has-a-trillion-parameters/) from the original on March 4, 2024. Retrieved October 23, 2023.\\n42.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-42)**[\\\"Improving Language Understanding by Generative Pre-Training\\\"](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)(PDF). [Archived](https://web.archive.org/web/20210126024542/https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)(PDF) from the original on January 26, 2021. Retrieved June 9, 2020.\\n43.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt2-not-immediate-release_43-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt2-not-immediate-release_43-1)Hern, Alex (February 14, 2019). [\\\"New AI fake text generator may be too dangerous to release, say creators\\\"](https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction). _The Guardian_. [Archived](https://web.archive.org/web/20190214173112/https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction) from the original on February 14, 2019. Retrieved February 14, 2019.\\n44.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-44)**Schwartz, Oscar (July 4, 2019). [\\\"Could 'fake text' be the next global political threat?\\\"](https://www.theguardian.com/technology/2019/jul/04/ai-fake-text-gpt-2-concerns-false-information). _The Guardian_. [Archived](https://web.archive.org/web/20190716035703/https://www.theguardian.com/technology/2019/jul/04/ai-fake-text-gpt-2-concerns-false-information) from the original on July 16, 2019. Retrieved July 16, 2019.\\n45.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-45)**Vincent, James (February 14, 2019). [\\\"OpenAI's new multitalented AI writes, translates, and slanders\\\"](https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2). _The Verge_. [Archived](https://web.archive.org/web/20201218091707/https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2) from the original on December 18, 2020. Retrieved July 16, 2019.\\n46.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-46)**[\\\"GPT-2: 1.5B Release\\\"](https://openai.com/blog/gpt-2-1-5b-release/). _OpenAI_. November 5, 2019. [Archived](https://web.archive.org/web/20191114074358/https://openai.com/blog/gpt-2-1-5b-release/) from the original on November 14, 2019. Retrieved November 14, 2019.\\n47.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-47)**[\\\"Write With Transformer\\\"](https://transformer.huggingface.co/). [Archived](https://web.archive.org/web/20191204060111/https://transformer.huggingface.co/) from the original on December 4, 2019. Retrieved December 4, 2019.\\n48.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-48)**[\\\"Talk to Transformer\\\"](https://talktotransformer.com/). [Archived](https://web.archive.org/web/20191204015009/https://talktotransformer.com/) from the original on December 4, 2019. Retrieved December 4, 2019.\\n49.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-49)**[\\\"CreativeEngines\\\"](https://creativeengines.ai/). [Archived](https://web.archive.org/web/20230203201104/https://creativeengines.ai/) from the original on February 3, 2023. Retrieved June 25, 2021.\\n50.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt2_50-0)**[_Language Models are Unsupervised Multitask Learners_](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)(PDF), [archived](https://web.archive.org/web/20191212223916/https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)(PDF) from the original on December 12, 2019, retrieved December 4, 2019\\n51.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-52)**[\\\"openai/gpt-3\\\"](https://github.com/openai/gpt-3). OpenAI. May 29, 2020. [Archived](https://web.archive.org/web/20201114165742/https://github.com/openai/gpt-3) from the original on November 14, 2020. Retrieved May 29, 2020.\\n52.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-53)**Sagar, Ram (June 3, 2020). [\\\"OpenAI Releases GPT-3, The Largest Model So Far\\\"](https://analyticsindiamag.com/open-ai-gpt-3-language-model/). _Analytics India Magazine_. [Archived](https://web.archive.org/web/20200804173452/https://analyticsindiamag.com/open-ai-gpt-3-language-model/) from the original on August 4, 2020. Retrieved June 14, 2020.\\n53.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt3_54-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt3_54-1)[_**c**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt3_54-2)[_**d**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt3_54-3)Brown, Tom; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini (June 1, 2020). \\\"Language Models are Few-Shot Learners\\\". p.appendix. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2005.14165](https://arxiv.org/abs/2005.14165) [[cs.CL](https://arxiv.org/archive/cs.CL)].\\n54.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt2-with-quote_55-0)**[_Language Models are Unsupervised Multitask Learners_](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)(PDF), [archived](https://web.archive.org/web/20191212223916/https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)(PDF) from the original on December 12, 2019, retrieved December 4, 2019, GPT-2, is a 1.5B parameter Transformer\\n55.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-gpt3-with-compare-quote_56-0)**Brown, Tom; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini (June 1, 2020). \\\"Language Models are Few-Shot Learners\\\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2005.14165](https://arxiv.org/abs/2005.14165) [[cs.CL](https://arxiv.org/archive/cs.CL)]. Since we increase the capacity by over two orders of magnitude from GPT-2 to GPT-3\\n56.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-zdnet-openai-statement_57-0)**Ray, Tiernan (2020). [\\\"OpenAI's gigantic GPT-3 hints at the limits of language models for AI\\\"](https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/). ZDNet. [Archived](https://web.archive.org/web/20200601081629/https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/) from the original on June 1, 2020. Retrieved June 5, 2020.\\n57.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-58)**Amodei, Dario; Hernandez, Danny (May 16, 2018). [\\\"AI and Compute\\\"](https://openai.com/blog/ai-and-compute/#fn2). [Archived](https://web.archive.org/web/20200617200602/https://openai.com/blog/ai-and-compute/#fn2) from the original on June 17, 2020. Retrieved August 30, 2020. A petaflop/s-day (pfs-day) consists of performing 10 15 neural net operations per second for one day, or a total of about 10 20 operations. The compute-time product serves as a mental convenience, similar to kW-hr for energy.\\n58.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-60)**Eadicicco, Lisa. [\\\"The artificial intelligence company that Elon Musk helped found is now selling the text-generation software it previously said was too dangerous to launch\\\"](https://www.businessinsider.com/elon-musk-openai-sell-text-tool-it-said-was-dangerous-2020-6). _Business Insider_. [Archived](https://web.archive.org/web/20201114205255/https://www.businessinsider.com/elon-musk-openai-sell-text-tool-it-said-was-dangerous-2020-6) from the original on November 14, 2020. Retrieved July 6, 2020.\\n59.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-61)**[\\\"OpenAI is giving Microsoft exclusive access to its GPT-3 language model\\\"](https://www.technologyreview.com/2020/09/23/1008729/openai-is-giving-microsoft-exclusive-access-to-its-gpt-3-language-model/). _MIT Technology Review_. [Archived](https://web.archive.org/web/20210205121656/https://www.technologyreview.com/2020/09/23/1008729/openai-is-giving-microsoft-exclusive-access-to-its-gpt-3-language-model/) from the original on February 5, 2021. Retrieved September 24, 2020.\\n60.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-62)**[\\\"Microsoft gets exclusive license for OpenAI's GPT-3 language model\\\"](https://venturebeat.com/2020/09/22/microsoft-gets-exclusive-license-for-openais-gpt-3-language-model/). _VentureBeat_. September 22, 2020. [Archived](https://web.archive.org/web/20201108090524/https://venturebeat.com/2020/09/22/microsoft-gets-exclusive-license-for-openais-gpt-3-language-model/) from the original on November 8, 2020. Retrieved September 24, 2020.\\n61.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-OAI-Codex_63-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-OAI-Codex_63-1)Alford, Anthony (August 31, 2021). [\\\"OpenAI Announces 12 Billion Parameter Code-Generation AI Codex\\\"](https://www.infoq.com/news/2021/08/openai-codex/). _InfoQ_. [Archived](https://web.archive.org/web/20220709221205/https://www.infoq.com/news/2021/08/openai-codex/) from the original on July 9, 2022. Retrieved September 3, 2021.\\n62.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-VB-Codex_64-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-VB-Codex_64-1)Wiggers, Kyle (July 8, 2021). [\\\"OpenAI warns AI behind GitHub's Copilot may be susceptible to bias\\\"](https://venturebeat.com/2021/07/08/openai-warns-ai-behind-githubs-copilot-may-be-susceptible-to-bias/). _[VentureBeat](https://en.wikipedia.org/wiki/VentureBeat \\\"VentureBeat\\\")_. [Archived](https://web.archive.org/web/20230203201912/https://venturebeat.com/business/openai-warns-ai-behind-githubs-copilot-may-be-susceptible-to-bias/) from the original on February 3, 2023. Retrieved September 3, 2021.\\n63.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-65)**[Zaremba, Wojciech](https://en.wikipedia.org/wiki/Wojciech_Zaremba \\\"Wojciech Zaremba\\\") (August 10, 2021). [\\\"OpenAI Codex\\\"](https://openai.com/blog/openai-codex/). _OpenAI_. [Archived](https://web.archive.org/web/20230203201912/https://openai.com/blog/openai-codex/) from the original on February 3, 2023. Retrieved September 3, 2021.\\n64.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-66)**Dickson, Ben (August 16, 2021). [\\\"What to expect from OpenAI's Codex API\\\"](https://venturebeat.com/2021/08/16/what-to-expect-from-openais-codex-api/). _[VentureBeat](https://en.wikipedia.org/wiki/VentureBeat \\\"VentureBeat\\\")_. [Archived](https://web.archive.org/web/20230203201913/https://venturebeat.com/ai/what-to-expect-from-openais-codex-api/) from the original on February 3, 2023. Retrieved September 3, 2021.\\n65.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-67)**Claburn, Thomas (August 25, 2021). [\\\"GitHub's Copilot may steer you into dangerous waters about 40% of the time – study\\\"](https://www.theregister.com/2021/08/25/github_copilot_study/). _[The Register](https://en.wikipedia.org/wiki/The\\\\_Register \\\"The Register\\\")_. [Archived](https://web.archive.org/web/20230203201913/https://www.theregister.com/2021/08/25/github_copilot_study/) from the original on February 3, 2023. Retrieved September 3, 2021.\\n66.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-68)**[\\\"OpenAI Might Invite Legal Trouble\\\"](https://analyticsindiamag.com/openai-might-invite-legal-trouble/). _Analytics India Magazine_. March 21, 2023. [Archived](https://web.archive.org/web/20230323205407/https://analyticsindiamag.com/openai-might-invite-legal-trouble/) from the original on March 23, 2023. Retrieved March 23, 2023.\\n67.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-69)**Vincent, James (March 14, 2023). [\\\"OpenAI announces GPT-4—the next generation of its AI language model\\\"](https://www.theverge.com/2023/3/14/23638033/openai-gpt-4-chatgpt-multimodal-deep-learning). _The Verge_. [Archived](https://web.archive.org/web/20230314195326/https://www.theverge.com/2023/3/14/23638033/openai-gpt-4-chatgpt-multimodal-deep-learning) from the original on March 14, 2023. Retrieved March 14, 2023.\\n68.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-70)**Wiggers, Kyle (March 14, 2023). [\\\"OpenAI releases GPT-4, a multimodal AI that it claims is state-of-the-art\\\"](https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/). _TechCrunch_. [Archived](https://web.archive.org/web/20230315003723/https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/) from the original on March 15, 2023. Retrieved March 14, 2023.\\n69.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-vox_71-0)**Belfield, Haydn (March 25, 2023). [\\\"If your AI model is going to sell, it has to be safe\\\"](https://www.vox.com/future-perfect/2023/3/25/23655082/ai-openai-gpt-4-safety-microsoft-facebook-meta). _[Vox](https://en.wikipedia.org/wiki/Vox\\\\_(website) \\\"Vox (website)\\\")_. [Archived](https://web.archive.org/web/20230328192017/https://www.vox.com/future-perfect/2023/3/25/23655082/ai-openai-gpt-4-safety-microsoft-facebook-meta) from the original on March 28, 2023. Retrieved March 30, 2023.\\n70.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-72)**Roose, Kevin (September 28, 2023). [\\\"The New ChatGPT Can 'See' and 'Talk.' Here's What It's Like\\\"](https://www.nytimes.com/2023/09/27/technology/new-chatgpt-can-see-hear.html). _The New York Times_. [Archived](https://web.archive.org/web/20231031055345/https://www.nytimes.com/2023/09/27/technology/new-chatgpt-can-see-hear.html) from the original on October 31, 2023. Retrieved December 1, 2023.\\n71.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-verge_wrong_73-0)**Vincent, James (March 15, 2023). [\\\"OpenAI co-founder on company's past approach to openly sharing research: \\\"We were wrong\\\"\\\"](https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview). _[The Verge](https://en.wikipedia.org/wiki/The\\\\_Verge \\\"The Verge\\\")_. [Archived](https://web.archive.org/web/20230317210900/https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview) from the original on March 17, 2023. Retrieved March 18, 2023.\\n72.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-TechCrunch_74-0)**Wiggers, Kyle (May 13, 2024). [\\\"OpenAI debuts GPT-4o 'omni' model now powering ChatGPT\\\"](https://techcrunch.com/2024/05/13/openais-newest-model-is-gpt-4o/). _TechCrunch_. [Archived](https://web.archive.org/web/20240522094111/https://techcrunch.com/2024/05/13/openais-newest-model-is-gpt-4o/) from the original on May 22, 2024. Retrieved May 13, 2024.\\n73.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-75)**van Rijmenam, Mark (May 13, 2024). [\\\"OpenAI Launched GPT-4o: The Future of AI Interactions Is Here\\\"](https://www.thedigitalspeaker.com/openai-gpt4o-future-ai-interactions/). _The Digital Speaker_. [Archived](https://web.archive.org/web/20240517013424/https://www.thedigitalspeaker.com/openai-gpt4o-future-ai-interactions/) from the original on May 17, 2024. Retrieved May 17, 2024.\\n74.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-76)**Daws, Ryan (May 14, 2024). [\\\"GPT-4o delivers human-like AI interaction with text, audio, and vision integration\\\"](https://www.artificialintelligence-news.com/2024/05/14/gpt-4o-human-like-ai-interaction-text-audio-vision-integration/). _AI News_. [Archived](https://web.archive.org/web/20240518131148/https://www.artificialintelligence-news.com/2024/05/14/gpt-4o-human-like-ai-interaction-text-audio-vision-integration/) from the original on May 18, 2024. Retrieved May 18, 2024.\\n75.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Hello_GPT-4o_77-0)**[\\\"Hello GPT-4o\\\"](https://openai.com/index/hello-gpt-4o/). _OpenAI_. [Archived](https://web.archive.org/web/20240514024319/https://openai.com/index/hello-gpt-4o/) from the original on May 14, 2024. Retrieved July 14, 2024.\\n76.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-78)**Franzen, Carl (July 18, 2024). [\\\"OpenAI unveils GPT-4o mini — a smaller, much cheaper multimodal AI model\\\"](https://venturebeat.com/ai/openai-unveils-gpt-4o-mini-a-smaller-much-cheaper-multimodal-ai-model/). _VentureBeat_. [Archived](https://web.archive.org/web/20240718185315/https://venturebeat.com/ai/openai-unveils-gpt-4o-mini-a-smaller-much-cheaper-multimodal-ai-model/) from the original on July 18, 2024. Retrieved July 18, 2024.\\n77.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-79)**Zeff, Kyle Wiggers, Maxwell (2025-03-25). [\\\"ChatGPT's image-generation feature gets an upgrade\\\"](https://techcrunch.com/2025/03/25/chatgpts-image-generation-feature-gets-an-upgrade/). _TechCrunch_. Retrieved 2025-03-27.`{{cite web}}`: CS1 maint: multiple names: authors list ([link](https://en.wikipedia.org/wiki/Category:CS1_maint:_multiple_names:_authors_list \\\"Category:CS1 maint: multiple names: authors list\\\"))\\n78.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-80)**Novet, Jordan (2025-02-27). [\\\"OpenAI launching GPT-4.5, its next general-purpose large language model\\\"](https://www.cnbc.com/2025/02/27/openai-launching-gpt-4point5-general-purpose-large-language-model.html). _CNBC_. Retrieved 2025-03-18.\\n79.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-81)**Weatherbed, Jess (2025-04-14). [\\\"OpenAI debuts its GPT-4.1 flagship AI model\\\"](https://www.theverge.com/news/647896/openai-chatgpt-gpt-4-1-mini-nano-launch-availability). _The Verge_. Retrieved 2025-04-15.\\n80.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-82)**[\\\"Introducing GPT-4.1 in the API\\\"](https://openai.com/index/gpt-4-1/). _openai.com_. Retrieved 2025-04-15.\\n81.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-83)**Knight, Will. [\\\"OpenAI's New GPT 4.1 Models Excel at Coding\\\"](https://www.wired.com/story/openai-announces-4-1-ai-model-coding/). _Wired_. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[1059-1028](https://search.worldcat.org/issn/1059-1028). Retrieved 2025-04-15.\\n82.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-84)**[\\\"Introducing GPT‑5 for developers\\\"](https://openai.com/index/introducing-gpt-5-for-developers/). _OpenAI_. 2025-08-07. Retrieved 2025-08-09.\\n83.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-85)**Robison, Kylie. [\\\"OpenAI Finally Launched GPT-5. Here's Everything You Need to Know\\\"](https://www.wired.com/story/openais-gpt-5-is-here/). _Wired_. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[1059-1028](https://search.worldcat.org/issn/1059-1028). Retrieved 2025-08-09.\\n84.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-86)**[\\\"ChatGPT-5 Arrives This Month - Are You Ready for What Comes Next?\\\"](https://economictimes.indiatimes.com/ai/ai-insights/chatgpt-5-arrives-this-month-are-you-ready-for-what-comes-next/articleshow/123132446.cms?from=mdr). _The Economic Times_. 2025-08-06. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[0013-0389](https://search.worldcat.org/issn/0013-0389). Retrieved 2025-08-09.\\n85.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-87)**[\\\"Can OpenAI's GPT-5 model live up to sky-high expectations?\\\"](https://www.ft.com/content/63435cb1-832d-4154-b2a5-60ccd609d75c). _Financial Times_. 2025-08-08. Retrieved 2025-08-09.\\n86.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-88)**Knight, Will. [\\\"OpenAI Announces a New AI Model, Code-Named Strawberry, That Solves Difficult Problems Step by Step\\\"](https://www.wired.com/story/openai-o1-strawberry-problem-reasoning/). _Wired_. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[1059-1028](https://search.worldcat.org/issn/1059-1028). [Archived](https://web.archive.org/web/20240914005013/https://www.wired.com/story/openai-o1-strawberry-problem-reasoning/) from the original on September 14, 2024. Retrieved September 14, 2024.\\n87.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-89)**Robison, Kylie (September 12, 2024). [\\\"OpenAI releases o1, its first model with 'reasoning' abilities\\\"](https://www.theverge.com/2024/9/12/24242439/openai-o1-model-reasoning-strawberry-chatgpt). _The Verge_. [Archived](https://web.archive.org/web/20240913134303/https://www.theverge.com/2024/9/12/24242439/openai-o1-model-reasoning-strawberry-chatgpt) from the original on September 13, 2024. Retrieved September 17, 2024.\\n88.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-90)**Franzen, Carl (2024-12-05). [\\\"OpenAI launches full o1 model with image uploads and analysis, debuts ChatGPT Pro\\\"](https://venturebeat.com/ai/openai-launches-full-o1-model-with-34-reduced-error-rate-debuts-chatgpt-pro/). _VentureBeat_. [Archived](https://web.archive.org/web/20241207181403/https://venturebeat.com/ai/openai-launches-full-o1-model-with-34-reduced-error-rate-debuts-chatgpt-pro/) from the original on December 7, 2024. Retrieved 2024-12-07.\\n89.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-91)**Wiggers, Kyle (2025-03-19). [\\\"OpenAI's o1-pro is the company's most expensive AI model yet\\\"](https://techcrunch.com/2025/03/19/openais-o1-pro-is-its-most-expensive-model-yet/). _TechCrunch_. Retrieved 2025-03-21.\\n90.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-92)**Zeff, Maxwell; Wiggers, Kyle (2024-12-20). [\\\"OpenAI announces new o3 models\\\"](https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/). _TechCrunch_. [Archived](https://web.archive.org/web/20241220201039/https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/) from the original on December 20, 2024. Retrieved 2024-12-20.\\n91.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-93)**Knight, Will. [\\\"OpenAI Upgrades Its Smartest AI Model With Improved Reasoning Skills\\\"](https://www.wired.com/story/openai-o3-reasoning-model-google-gemini/). _Wired_. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[1059-1028](https://search.worldcat.org/issn/1059-1028). [Archived](https://web.archive.org/web/20241220200335/https://www.wired.com/story/openai-o3-reasoning-model-google-gemini/) from the original on December 20, 2024. Retrieved 2024-12-20.\\n92.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-94)**[\\\"Early access for safety testing\\\"](https://openai.com/index/early-access-for-safety-testing/). _OpenAI_. December 20, 2024. [Archived](https://web.archive.org/web/20241221081849/https://openai.com/index/early-access-for-safety-testing/) from the original on December 21, 2024. Retrieved 2024-12-23.\\n93.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-95)**Zeff, Maxwell; Wiggers, Kyle (2024-12-20). [\\\"OpenAI announces new o3 models\\\"](https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/). _TechCrunch_. [Archived](https://web.archive.org/web/20241220201039/https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/) from the original on December 20, 2024. Retrieved 2024-12-23.\\n94.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-96)**[\\\"OpenAI launches new AI reasoning models o3 and 04-mini; older models to be phased out\\\"](https://www.thehindu.com/sci-tech/technology/openai-launches-new-ai-reasoning-models-o3-and-04-mini-older-models-to-be-phased-out/article69459565.ece). _The Hindu_. The Hindu Bureau. 2025-04-17. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[0971-751X](https://search.worldcat.org/issn/0971-751X). Retrieved 2025-04-17.\\n95.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Reuters_20250203_97-0)**[\\\"OpenAI launches new AI tool to facilitate research tasks\\\"](https://www.reuters.com/technology/openai-launches-new-ai-tool-facilitate-research-tasks-2025-02-03/). _Reuters_. February 3, 2025 – via www.reuters.com.\\n96.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Verge_20250203_98-0)**Lawler, Richard (2025-02-03). [\\\"ChatGPT's agent can now do deep research for you\\\"](https://www.theverge.com/news/604902/chagpt-deep-research-ai-agent). _The Verge_. Retrieved 2025-02-05.\\n97.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-99)**[\\\"OpenAI rolls out free, lightweight Deep Research tool for all ChatGPT users\\\"](https://www.indiatoday.in/technology/news/story/openai-rolls-out-free-lightweight-deep-research-tool-for-all-chatgpt-users-2715040-2025-04-25). _India Today_. 2025-04-25. Retrieved 2025-04-25.\\n98.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-100)**[\\\"OpenAI introduces cost-efficient, lightweight version of ChatGPT research tool\\\"](https://timesofindia.indiatimes.com/technology/artificial-intelligence/openai-introduces-cost-efficient-lightweight-version-of-chatgpt-research-tool/articleshow/120603631.cms). _The Times of India_. 2025-04-25. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[0971-8257](https://search.worldcat.org/issn/0971-8257). Retrieved 2025-04-25.\\n99.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-:1_101-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-:1_101-1)[\\\"Introducing gpt-oss\\\"](https://openai.com/index/introducing-gpt-oss/). _openai.com_. 2025-08-04. Retrieved 2025-08-05.\\n100.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-102)**Heath, Alex (2025-08-05). [\\\"OpenAI releases a free GPT model that can run on your laptop\\\"](https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release). _The Verge_. Retrieved 2025-08-05.\\n101.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-:0_103-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-:0_103-1)[_**c**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-:0_103-2)[\\\"gpt-oss-120b & gpt-oss-20b Model Card\\\"](https://openai.com/index/gpt-oss-model-card/). _openai.com_. 2025-08-05. Retrieved 2025-08-05.\\n102.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-104)**[\\\"CLIP: Connecting Text and Images\\\"](https://openai.com/blog/clip/). January 5, 2021. [Archived](https://web.archive.org/web/20210325202038/https://openai.com/blog/clip/) from the original on March 25, 2021. Retrieved March 27, 2021.\\n103.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-105)**[\\\"DALL·E: Creating Images from Text\\\"](https://openai.com/blog/dall-e/). January 5, 2021. [Archived](https://web.archive.org/web/20210327133043/https://openai.com/blog/dall-e/) from the original on March 27, 2021. Retrieved March 27, 2021.\\n104.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-106)**[\\\"DALL·E 2\\\"](https://openai.com/dall-e-2/). _OpenAI_. [Archived](https://web.archive.org/web/20220406141035/https://openai.com/dall-e-2/) from the original on April 6, 2022. Retrieved April 6, 2022.\\n105.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-107)**[\\\"ChatGPT: A scientist explains the hidden genius and pitfalls of OpenAI's chatbot\\\"](https://www.sciencefocus.com/news/chatgpt-scientist-openai-chatbot/). _BBC Science Focus Magazine_. 2022. [Archived](https://web.archive.org/web/20230203201910/https://www.sciencefocus.com/news/chatgpt-scientist-openai-chatbot/) from the original on February 3, 2023. Retrieved December 30, 2022.\\n106.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-108)**[\\\"OpenAI's new AI image generator pushes the limits in detail and prompt fidelity\\\"](https://web.archive.org/web/20231116152507/https://arstechnica.com/information-technology/2023/09/openai-announces-dall-e-3-a-next-gen-ai-image-generator-based-on-chatgpt/). Archived from [the original](https://arstechnica.com/information-technology/2023/09/openai-announces-dall-e-3-a-next-gen-ai-image-generator-based-on-chatgpt/) on November 16, 2023. Retrieved November 21, 2023.\\n107.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-109)**[\\\"DALL·E 3 is now available in ChatGPT Plus and Enterprise\\\"](https://web.archive.org/web/20231120155249/https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise). Archived from [the original](https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise) on November 20, 2023. Retrieved November 21, 2023.\\n108.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-NYT_CM_2024_02_15_110-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-NYT_CM_2024_02_15_110-1)[_**c**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-NYT_CM_2024_02_15_110-2)Metz, Cade (February 15, 2024). [\\\"OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos\\\"](https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html). _[The New York Times](https://en.wikipedia.org/wiki/The\\\\_New\\\\_York\\\\_Times \\\"The New York Times\\\")_. [Archived](https://web.archive.org/web/20240215220626/https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html) from the original on February 15, 2024. Retrieved February 16, 2024.\\n109.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-world_sim_111-0)**[\\\"Video generation models as world simulators\\\"](https://openai.com/research/video-generation-models-as-world-simulators). OpenAI. February 15, 2024. [Archived](https://web.archive.org/web/20240216072133/https://openai.com/research/video-generation-models-as-world-simulators) from the original on February 16, 2024. Retrieved February 16, 2024.\\n110.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-WDH_MIT_2024_02_15_112-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-WDH_MIT_2024_02_15_112-1)[_**c**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-WDH_MIT_2024_02_15_112-2)Brooks, Tim; Peebles, Bill; Holmes, Connor; DePue, Will; Guo, Yufei; Jing, Li; Schnurr, David; Taylor, Joe; Luhman, Troy; Luhman, Eric; Ng, Clarence Wing Yin; Wang, Ricky; Ramesh, Aditya (February 15, 2024). [\\\"Video generation models as world simulators\\\"](https://openai.com/research/video-generation-models-as-world-simulators). _Openai.com_. OpenAI. [Archived](https://web.archive.org/web/20240216072133/https://openai.com/research/video-generation-models-as-world-simulators) from the original on February 16, 2024. Retrieved February 16, 2024.\\n111.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-113)**Pequeño IV, Antonio (February 15, 2024). [\\\"OpenAI Reveals 'Sora': AI Video Model Capable Of Realistic Text-To-Video Prompts\\\"](https://www.forbes.com/sites/antoniopequenoiv/2024/02/15/openai-reveals-sora-ai-video-model-capable-of-realistic-text-to-video-prompts/). _[Forbes](https://en.wikipedia.org/wiki/Forbes \\\"Forbes\\\")_. [Archived](https://web.archive.org/web/20240215220634/https://www.forbes.com/sites/antoniopequenoiv/2024/02/15/openai-reveals-sora-ai-video-model-capable-of-realistic-text-to-video-prompts/) from the original on February 15, 2024. Retrieved February 16, 2024.\\n112.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-114)**Clark, Elijah. [\\\"Tyler Perry Warns Of AI Threat After Sora Debut Halts An Million Studio Expansion\\\"](https://www.forbes.com/sites/elijahclark/2024/02/23/tyler-perry-warns-of-ai-threat-to-jobs-after-viewing-openai-sora/). _Forbes_. Retrieved March 24, 2024.\\n113.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-115)**[\\\"Sora 2 is here\\\"](https://openai.com/index/sora-2/). _openai.com_. 2025-09-30. Retrieved 2025-10-22.\\n114.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-116)**Wiggers, Kyle (September 21, 2022). [\\\"OpenAI open-sources Whisper, a multilingual speech recognition system\\\"](https://techcrunch.com/2022/09/21/openai-open-sources-whisper-a-multilingual-speech-recognition-system/). _TechCrunch_. [Archived](https://web.archive.org/web/20230212154543/https://techcrunch.com/2022/09/21/openai-open-sources-whisper-a-multilingual-speech-recognition-system/) from the original on February 12, 2023. Retrieved February 12, 2023.\\n115.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Radford_Kim_Xu_Brockman_p._117-0)**Radford, Alec; Kim, Jong Wook; Xu, Tao; Brockman, Greg; McLeavey, Christine; Sutskever, Ilya (2022). \\\"Robust Speech Recognition via Large-Scale Weak Supervision\\\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2212.04356](https://arxiv.org/abs/2212.04356) [[eess.AS](https://arxiv.org/archive/eess.AS)].\\n116.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-118)**[\\\"OpenAI's MuseNet generates AI music at the push of a button\\\"](https://www.theverge.com/2019/4/26/18517803/openai-musenet-artificial-intelligence-ai-music-generation-lady-gaga-harry-potter-mozart). _The Verge_. April 2019. [Archived](https://web.archive.org/web/20190628164236/https://www.theverge.com/2019/4/26/18517803/openai-musenet-artificial-intelligence-ai-music-generation-lady-gaga-harry-potter-mozart) from the original on June 28, 2019. Retrieved June 8, 2020.\\n117.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-119)**[\\\"MuseNet\\\"](https://openai.com/blog/musenet/). OpenAI. April 25, 2019. [Archived](https://web.archive.org/web/20200613055143/https://openai.com/blog/musenet/) from the original on June 13, 2020. Retrieved June 8, 2020.\\n118.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-120)**[\\\"Arcade Attack Podcast – September (4 of 4) 2020 - Alex Hall (Ben Drowned) - Interview\\\"](https://www.arcadeattack.co.uk/podcast-september-4-2020/). _Arcade Attack_. September 28, 2020. [Archived](https://web.archive.org/web/20230203201108/https://www.arcadeattack.co.uk/podcast-september-4-2020/) from the original on February 3, 2023. Retrieved January 29, 2023.\\n119.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-121)**Alexander Hall (June 25, 2020). [\\\"Tweets don't have titles and do not archive\\\"](https://mobile.twitter.com/alexanderdhall/status/1276186528264392707). _X (formerly Twitter)_. [Archived](https://web.archive.org/web/20230203201107/https://mobile.twitter.com/alexanderdhall/status/1276186528264392707) from the original on February 3, 2023. Retrieved January 29, 2023.\\n120.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-122)**[\\\"OpenAI introduces Jukebox, a new AI model that generates genre-specific music\\\"](https://www.theverge.com/2020/4/30/21243038/openai-jukebox-model-raw-audio-lyrics-ai-generated-copyright). _The Verge_. April 30, 2020. [Archived](https://web.archive.org/web/20200608043659/https://www.theverge.com/2020/4/30/21243038/openai-jukebox-model-raw-audio-lyrics-ai-generated-copyright) from the original on June 8, 2020. Retrieved June 8, 2020.\\n121.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-123)**Stephen, Bijan (April 30, 2020). [\\\"OpenAI introduces Jukebox, a new AI model that generates genre-specific music\\\"](https://www.businessinsider.com/jukebox-ai-music-generator-realistic-songs-machine-learning-algorithm-deepfakes-2020-5). _Business Insider_. [Archived](https://web.archive.org/web/20200608043703/https://www.businessinsider.com/jukebox-ai-music-generator-realistic-songs-machine-learning-algorithm-deepfakes-2020-5) from the original on June 8, 2020. Retrieved June 8, 2020.\\n122.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-124)**[\\\"Jukebox\\\"](https://openai.com/blog/jukebox/). OpenAI. April 30, 2020. [Archived](https://web.archive.org/web/20200608043703/https://openai.com/blog/jukebox/) from the original on June 8, 2020. Retrieved June 8, 2020.\\n123.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-125)**Greene, Tristan (May 4, 2018). [\\\"OpenAI's Debate Game teaches you and your friends how to lie like robots\\\"](https://thenextweb.com/artificial-intelligence/2018/05/04/openais-debate-game-teaches-you-and-your-friends-how-to-lie-like-robots/). _The Next Web_. [Archived](https://web.archive.org/web/20180505005129/https://thenextweb.com/artificial-intelligence/2018/05/04/openais-debate-game-teaches-you-and-your-friends-how-to-lie-like-robots/) from the original on May 5, 2018. Retrieved May 31, 2018.\\n124.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-126)**[\\\"Why Scientists Think AI Systems Should Debate Each Other\\\"](https://www.fastcompany.com/40569116/why-scientists-think-ai-systems-should-debate-each-other). _Fast Company_. May 8, 2018. [Archived](https://web.archive.org/web/20180519140829/https://www.fastcompany.com/40569116/why-scientists-think-ai-systems-should-debate-each-other) from the original on May 19, 2018. Retrieved June 2, 2018.\\n125.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-127)**[\\\"OpenAI Microscope\\\"](https://openai.com/blog/microscope/). April 14, 2020. [Archived](https://web.archive.org/web/20230203201911/https://openai.com/blog/microscope/) from the original on February 3, 2023. Retrieved March 27, 2021.\\n126.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-128)**Johnson, Khari (April 14, 2020). [\\\"OpenAI launches Microscope to visualize the neurons in popular machine learning models\\\"](https://venturebeat.com/ai/openai-launches-microscope-to-visualize-the-neurons-in-popular-machine-learning-models/). _VentureBeat_. [Archived](https://web.archive.org/web/20230212154926/https://venturebeat.com/ai/openai-launches-microscope-to-visualize-the-neurons-in-popular-machine-learning-models/) from the original on February 12, 2023. Retrieved February 12, 2023.\\n127.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-129)**[\\\"OpenAI Microscope\\\"](https://microscope.openai.com/models). _OpenAI Microscope_. [Archived](https://web.archive.org/web/20230203191623/https://microscope.openai.com/models) from the original on February 3, 2023. Retrieved March 27, 2021.\\n128.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-130)**[\\\"ChatGPT's image-generation feature gets an upgrade\\\"](https://techcrunch.com/2025/03/25/chatgpts-image-generation-feature-gets-an-upgrade/). _TechCrunch_. 2025-03-25. Retrieved 2025-06-12.\\n129.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-:8_131-0)**Milmo, Dan (December 2, 2023). [\\\"ChatGPT reaches 100 million users two months after launch\\\"](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app). _The Guardian_. [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) \\\"ISSN (identifier)\\\")[0261-3077](https://search.worldcat.org/issn/0261-3077). [Archived](https://web.archive.org/web/20230203051356/https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app) from the original on February 3, 2023. Retrieved February 3, 2023.\\n130.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-132)**Sharma, Shubham (May 14, 2024). [\\\"With OpenAI offering GPT-4o for free, who should be paying for ChatGPT Plus?\\\"](https://venturebeat.com/ai/with-openai-offering-gpt-4o-for-free-who-should-be-paying-for-chatgpt-plus/). _VentureBeat_. [Archived](https://web.archive.org/web/20240521212929/https://venturebeat.com/ai/with-openai-offering-gpt-4o-for-free-who-should-be-paying-for-chatgpt-plus/) from the original on May 21, 2024. Retrieved May 21, 2024.\\n131.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-verge-android_133-0)**Lawler, Richard (July 25, 2023). [\\\"ChatGPT for Android is now available\\\"](https://www.theverge.com/2023/7/25/23807012/chatgpt-android-ai-chatbot-openai-llm). _The Verge_. [Archived](https://web.archive.org/web/20230816172328/https://www.theverge.com/2023/7/25/23807012/chatgpt-android-ai-chatbot-openai-llm) from the original on August 16, 2023. Retrieved August 17, 2023.\\n132.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-134)**[\\\"OpenAI launches free 15-minute phone calls with ChatGPT\\\"](https://www.socialsamosa.com/news-2/openai-launches-15-minute-phone-calls-chatgpt-8532973). _www.socialsamosa.com_. 2024-12-20. [Archived](https://web.archive.org/web/20241220175224/https://www.socialsamosa.com/news-2/openai-launches-15-minute-phone-calls-chatgpt-8532973) from the original on December 20, 2024. Retrieved 2024-12-20.\\n133.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-135)**Field, Hayden (2024-12-18). [\\\"OpenAI makes ChatGPT available for phone calls and texts\\\"](https://www.cnbc.com/2024/12/18/openai-makes-chatgpt-available-for-phone-chats.html). _CNBC_. [Archived](https://web.archive.org/web/20241220135320/https://www.cnbc.com/2024/12/18/openai-makes-chatgpt-available-for-phone-chats.html) from the original on December 20, 2024. Retrieved 2024-12-20.\\n134.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-136)**Robison, Kylie (July 25, 2024). [\\\"OpenAI announces SearchGPT, its AI-powered search engine\\\"](https://www.theverge.com/2024/7/25/24205701/openai-searchgpt-ai-search-engine-google-perplexity-rival). _The Verge_. [Archived](https://web.archive.org/web/20240726180050/https://www.theverge.com/2024/7/25/24205701/openai-searchgpt-ai-search-engine-google-perplexity-rival) from the original on July 26, 2024. Retrieved July 27, 2024.\\n135.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-137)**Wiggers, Kyle (July 25, 2024). [\\\"With Google in its sights, OpenAI unveils SearchGPT\\\"](https://techcrunch.com/2024/07/25/with-google-in-its-sights-openai-unveils-searchgpt/). _TechCrunch_. [Archived](https://web.archive.org/web/20240726010010/https://techcrunch.com/2024/07/25/with-google-in-its-sights-openai-unveils-searchgpt/) from the original on July 26, 2024. Retrieved July 26, 2024.\\n136.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-138)**Jamali, Lily (21 October 2025). [\\\"ChatGPT-maker OpenAI releases browser in attempt to rival Google\\\"](https://www.bbc.com/news/articles/c07mz10m1k9o). _BBC_. Retrieved 21 October 2025.\\n137.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-139)**[\\\"Introducing ChatGPT Atlas\\\"](https://openai.com/index/introducing-chatgpt-atlas/). _openai.com_. 2025-10-21. Retrieved 2025-10-22.\\n138.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Bajwa-2024_140-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-Bajwa-2024_140-1)Bajwa, Arsheeya; Simao, Paul; Gregorio, David (March 29, 2024). [\\\"Microsoft, OpenAI plan billion data-center project, media report says\\\"](https://www.reuters.com/technology/microsoft-openai-planning-100-billion-data-center-project-information-reports-2024-03-29/). _[Reuters](https://en.wikipedia.org/wiki/Reuters \\\"Reuters\\\")_. [Archived](https://web.archive.org/web/20240620203250/https://www.reuters.com/technology/microsoft-openai-planning-100-billion-data-center-project-information-reports-2024-03-29/) from the original on June 20, 2024. Retrieved June 6, 2024.\\n139.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-The_Information-2024_141-0)**[\\\"Microsoft and OpenAI Plot Billion Stargate AI Supercomputer\\\"](https://www.theinformation.com/articles/microsoft-and-openai-plot-100-billion-stargate-ai-supercomputer). _[The Information](https://en.wikipedia.org/wiki/The\\\\_Information\\\\_(website) \\\"The Information (website)\\\")_. March 29, 2024. Retrieved June 6, 2024.\\n140.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-142)**[\\\"Stargate: Tech giants announce AI plan worth up to bn\\\"](https://www.bbc.com/news/articles/cy4m84d2xz2o). _BBC_. 2025-01-22. Retrieved 2025-05-31.\\n141.   ^ [_**a**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-OpenAI-Sam_and_Jony_143-0)[_**b**_](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-OpenAI-Sam_and_Jony_143-1)[\\\"Sam and Jony introduce io\\\"](https://openai.com/sam-and-jony/). _openai.com_. Retrieved 2025-05-21.\\n142.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-144)**Tatananni, Angela Palumbo|Mackenzie. [\\\"OpenAI to Buy iPhone Designer Jony Ive's AI Devices Start-Up for Billion. Apple Stock Falls\\\"](https://www.barrons.com/articles/openai-jony-ive-ai-acquisition-537d3269). _barrons_. Retrieved 2025-05-22.\\n143.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-145)**Peters, Jay (2025-05-21). [\\\"OpenAI is buying Jony Ive's AI hardware company\\\"](https://www.theverge.com/news/671838/openai-jony-ive-ai-hardware-apple). _The Verge_. Retrieved 2025-05-22.\\n144.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-146)**De Vynck, Gerrit (2025-05-21). [\\\"iPhone designer Jony Ive will join OpenAI to build AI-powered devices\\\"](https://www.washingtonpost.com/technology/2025/05/21/jony-ive-openai-altman-io/). _Washington Post_. Retrieved 2025-05-21.\\n145.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-147)**Franzen, Carl (2025-01-10). [\\\"OpenAI has begun building out its robotics team\\\"](https://venturebeat.com/ai/openai-has-begun-building-out-its-robotics-team/). _VentureBeat_. Retrieved 2025-08-25.\\n146.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-148)**[_finetune-transformer-lm_](https://github.com/openai/finetune-transformer-lm), OpenAI, June 11, 2018, [archived](https://web.archive.org/web/20230519062127/https://github.com/openai/finetune-transformer-lm) from the original on May 19, 2023, retrieved May 1, 2023\\n147.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-149)**[\\\"GPT-2: 1.5B release\\\"](https://openai.com/research/gpt-2-1-5b-release). _OpenAI_. 2019-11-05. [Archived](https://web.archive.org/web/20230331004642/https://openai.com/research/gpt-2-1-5b-release) from the original on March 31, 2023. Retrieved May 1, 2023.\\n148.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-150)**[Solaiman, Irene](https://en.wikipedia.org/wiki/Irene_Solaiman \\\"Irene Solaiman\\\"); Brundage, Miles; Clark, Jack; Askell, Amanda; Herbert-Voss, Ariel; Wu, Jeff; Radford, Alec; Krueger, Gretchen; Kim, Jong Wook; Kreps, Sarah; McCain, Miles; Newhouse, Alex; Blazakis, Jason; McGuffie, Kris; Wang, Jasmine (November 12, 2019). \\\"Release Strategies and the Social Impacts of Language Models\\\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[1908.09203](https://arxiv.org/abs/1908.09203) [[cs.CL](https://arxiv.org/archive/cs.CL)].\\n149.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-151)**[_gpt-2_](https://github.com/openai/gpt-2), OpenAI, May 1, 2023, [archived](https://web.archive.org/web/20230311154936/https://github.com/openai/gpt-2) from the original on March 11, 2023, retrieved May 1, 2023\\n150.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-LM2_152-0)**Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (May 28, 2020). \\\"Language Models are Few-Shot Learners\\\". _NeurIPS_. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2005.14165v4](https://arxiv.org/abs/2005.14165v4).\\n151.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-153)**[\\\"WebGPT: Improving the factual accuracy of language models through web browsing\\\"](https://openai.com/research/webgpt). _OpenAI_. 2021-12-16. [Archived](https://web.archive.org/web/20230621182942/https://openai.com/research/webgpt) from the original on June 21, 2023. Retrieved July 2, 2023.\\n152.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-154)**Nakano, Reiichiro; Hilton, Jacob; [Balaji, Suchir](https://en.wikipedia.org/wiki/Suchir_Balaji \\\"Suchir Balaji\\\"); Wu, Jeff; Ouyang, Long; Kim, Christina; Hesse, Christopher; Jain, Shantanu; Kosaraju, Vineet; Saunders, William; Jiang, Xu; Cobbe, Karl; Eloundou, Tyna; Krueger, Gretchen; Button, Kevin (December 1, 2021). [\\\"WebGPT: Browser-assisted question-answering with human feedback\\\"](https://ui.adsabs.harvard.edu/abs/2021arXiv211209332N). _CoRR_. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2112.09332](https://arxiv.org/abs/2112.09332). [Archived](https://web.archive.org/web/20230702191323/https://ui.adsabs.harvard.edu/abs/2021arXiv211209332N) from the original on July 2, 2023. Retrieved July 2, 2023.\\n153.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-155)**[\\\"Aligning language models to follow instructions\\\"](https://openai.com/index/instruction-following/). _OpenAI_. 2024-02-14. Retrieved 2025-08-10.\\n154.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-156)**Ouyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll L.; Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex; Schulman, John; Hilton, Jacob; Kelton, Fraser; Miller, Luke; Simens, Maddie; Askell, Amanda; Welinder, Peter; Christiano, Paul; Leike, Jan; Lowe, Ryan (2022). \\\"Training language models to follow instructions with human feedback\\\". _NeurIPS_. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2203.02155](https://arxiv.org/abs/2203.02155).\\n155.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-157)**[\\\"Introducing ChatGPT\\\"](https://openai.com/index/chatgpt/). _OpenAI_. 2024-03-13.\\n156.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-158)**[\\\"GPT-4\\\"](https://openai.com/research/gpt-4). _OpenAI_. 2023-03-14. [Archived](https://web.archive.org/web/20230314174531/https://openai.com/research/gpt-4) from the original on March 14, 2023. Retrieved May 1, 2023.\\n157.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-159)**OpenAI (March 27, 2023). \\\"GPT-4 Technical Report\\\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2303.08774](https://arxiv.org/abs/2303.08774) [[cs.CL](https://arxiv.org/archive/cs.CL)].\\n158.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-160)**Bubeck, Sébastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (April 13, 2023). \\\"Sparks of Artificial General Intelligence: Early experiments with GPT-4\\\". [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) \\\"ArXiv (identifier)\\\"):[2303.12712](https://arxiv.org/abs/2303.12712) [[cs.CL](https://arxiv.org/archive/cs.CL)].\\n159.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-161)**[GPT-4 System Card](https://cdn.openai.com/papers/gpt-4-system-card.pdf)[Archived](https://web.archive.org/web/20230407201347/https://cdn.openai.com/papers/gpt-4-system-card.pdf) April 7, 2023, at the [Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine \\\"Wayback Machine\\\"), OpenAI, March 23, 2023 (Accessed May 22, 2023).\\n160.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-162)**[\\\"Hello GPT-4o\\\"](https://openai.com/index/hello-gpt-4o/). _OpenAI_. May 13, 2024. [Archived](https://web.archive.org/web/20240514024319/https://openai.com/index/hello-gpt-4o/) from the original on May 14, 2024. Retrieved August 8, 2024.\\n161.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-163)**[\\\"Introducing GPT-4.5\\\"](https://openai.com/index/introducing-gpt-4-5). _OpenAI_. February 27, 2025. [Archived](https://web.archive.org/web/20250319141909/https://openai.com/index/introducing-gpt-4-5/) from the original on March 19, 2025. Retrieved March 18, 2025.\\n162.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-164)**[\\\"Introducing GPT-4.1 in the API\\\"](https://openai.com/index/gpt-4-1/). _OpenAI_. April 14, 2025. [Archived](https://web.archive.org/web/20250517080149/https://openai.com/index/gpt-4-1/) from the original on May 17, 2025. Retrieved April 14, 2025.\\n163.   **[^](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#cite_ref-165)**[\\\"Introducing GPT-5\\\"](https://openai.com/index/introducing-gpt-5/). _openai.com_. 2025-08-07. Retrieved 2025-08-11.\\n\\n| * [v](https://en.wikipedia.org/wiki/Template:OpenAI \\\"Template:OpenAI\\\") * [t](https://en.wikipedia.org/wiki/Template_talk:OpenAI \\\"Template talk:OpenAI\\\") * [e](https://en.wikipedia.org/wiki/Special:EditPage/Template:OpenAI \\\"Special:EditPage/Template:OpenAI\\\") [OpenAI](https://en.wikipedia.org/wiki/OpenAI \\\"OpenAI\\\") |\\n| --- |\\n| [Products](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI) | | [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT \\\"ChatGPT\\\") | * [Atlas](https://en.wikipedia.org/wiki/ChatGPT_Atlas \\\"ChatGPT Atlas\\\") * [Deep Research](https://en.wikipedia.org/wiki/ChatGPT_Deep_Research \\\"ChatGPT Deep Research\\\") * [GPT Store](https://en.wikipedia.org/wiki/GPT_Store \\\"GPT Store\\\") * [Search](https://en.wikipedia.org/wiki/ChatGPT_Search \\\"ChatGPT Search\\\") | | --- | | [Foundation models](https://en.wikipedia.org/wiki/Foundation_model \\\"Foundation model\\\") | | [GPT models](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer \\\"Generative pre-trained transformer\\\") | * [GPT-1](https://en.wikipedia.org/wiki/GPT-1 \\\"GPT-1\\\") * [GPT-2](https://en.wikipedia.org/wiki/GPT-2 \\\"GPT-2\\\") * [GPT-3](https://en.wikipedia.org/wiki/GPT-3 \\\"GPT-3\\\") * [GPT-4](https://en.wikipedia.org/wiki/GPT-4 \\\"GPT-4\\\") * [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\") * [o1](https://en.wikipedia.org/wiki/OpenAI_o1 \\\"OpenAI o1\\\") * [o3](https://en.wikipedia.org/wiki/OpenAI_o3 \\\"OpenAI o3\\\") * [GPT-4.5](https://en.wikipedia.org/wiki/GPT-4.5 \\\"GPT-4.5\\\") * [GPT-4.1](https://en.wikipedia.org/wiki/GPT-4.1 \\\"GPT-4.1\\\") * [o4-mini](https://en.wikipedia.org/wiki/OpenAI_o4-mini \\\"OpenAI o4-mini\\\") * [GPT-OSS](https://en.wikipedia.org/wiki/GPT-OSS \\\"GPT-OSS\\\") * [GPT-5](https://en.wikipedia.org/wiki/GPT-5 \\\"GPT-5\\\") * [GPT-5.1](https://en.wikipedia.org/wiki/GPT-5.1 \\\"GPT-5.1\\\") * [GPT-5.2](https://en.wikipedia.org/wiki/GPT-5.2 \\\"GPT-5.2\\\") | | --- | | Specialized | * [DALL-E](https://en.wikipedia.org/wiki/DALL-E \\\"DALL-E\\\") * [GPT Image](https://en.wikipedia.org/wiki/GPT_Image \\\"GPT Image\\\") * [Sora](https://en.wikipedia.org/wiki/Sora_(text-to-video_model) \\\"Sora (text-to-video model)\\\") * [Whisper](https://en.wikipedia.org/wiki/Whisper_(speech_recognition_system) \\\"Whisper (speech recognition system)\\\") | | | [Intelligent agents](https://en.wikipedia.org/wiki/Intelligent_agent \\\"Intelligent agent\\\") | * [Codex](https://en.wikipedia.org/wiki/OpenAI_Codex \\\"OpenAI Codex\\\") * [Operator](https://en.wikipedia.org/wiki/OpenAI_Operator \\\"OpenAI Operator\\\") | | [![Image 10](https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/OpenAI_logo_2025_%28wordmark%29.svg/250px-OpenAI_logo_2025_%28wordmark%29.svg.png)](https://en.wikipedia.org/wiki/File:OpenAI_logo_2025_(wordmark).svg) |\\n| People | | [Senior management](https://en.wikipedia.org/wiki/Senior_management \\\"Senior management\\\") | | Current | * [Sam Altman](https://en.wikipedia.org/wiki/Sam_Altman \\\"Sam Altman\\\") * [removal](https://en.wikipedia.org/wiki/Removal_of_Sam_Altman_from_OpenAI \\\"Removal of Sam Altman from OpenAI\\\") * [Greg Brockman](https://en.wikipedia.org/wiki/Greg_Brockman \\\"Greg Brockman\\\") * [Sarah Friar](https://en.wikipedia.org/wiki/Sarah_Friar \\\"Sarah Friar\\\") * [Jakub Pachocki](https://en.wikipedia.org/wiki/Jakub_Pachocki \\\"Jakub Pachocki\\\") * [Scott Schools](https://en.wikipedia.org/wiki/Scott_Schools \\\"Scott Schools\\\") | | --- | | Former | * [Mira Murati](https://en.wikipedia.org/wiki/Mira_Murati \\\"Mira Murati\\\") * [Emmett Shear](https://en.wikipedia.org/wiki/Emmett_Shear \\\"Emmett Shear\\\") | | | --- | | [Board of directors](https://en.wikipedia.org/wiki/Board_of_directors \\\"Board of directors\\\") | | Current | * [Sam Altman](https://en.wikipedia.org/wiki/Sam_Altman \\\"Sam Altman\\\") * [Adam D'Angelo](https://en.wikipedia.org/wiki/Adam_D%27Angelo \\\"Adam D'Angelo\\\") * [Sue Desmond-Hellmann](https://en.wikipedia.org/wiki/Sue_Desmond-Hellmann \\\"Sue Desmond-Hellmann\\\") * [Zico Kolter](https://en.wikipedia.org/wiki/Zico_Kolter \\\"Zico Kolter\\\") * [Paul Nakasone](https://en.wikipedia.org/wiki/Paul_Nakasone \\\"Paul Nakasone\\\") * [Adebayo Ogunlesi](https://en.wikipedia.org/wiki/Adebayo_Ogunlesi \\\"Adebayo Ogunlesi\\\") * [Nicole Seligman](https://en.wikipedia.org/wiki/Nicole_Seligman \\\"Nicole Seligman\\\") * [Fidji Simo](https://en.wikipedia.org/wiki/Fidji_Simo \\\"Fidji Simo\\\") * [Bret Taylor](https://en.wikipedia.org/wiki/Bret_Taylor \\\"Bret Taylor\\\") (chair) | | --- | | Former | * [Greg Brockman](https://en.wikipedia.org/wiki/Greg_Brockman \\\"Greg Brockman\\\") (2017–2023) * [Reid Hoffman](https://en.wikipedia.org/wiki/Reid_Hoffman \\\"Reid Hoffman\\\") (2019–2023) * [Will Hurd](https://en.wikipedia.org/wiki/Will_Hurd \\\"Will Hurd\\\") (2021–2023) * [Holden Karnofsky](https://en.wikipedia.org/wiki/Holden_Karnofsky \\\"Holden Karnofsky\\\") (2017–2021) * [Elon Musk](https://en.wikipedia.org/wiki/Elon_Musk \\\"Elon Musk\\\") (2015–2018) * [Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever \\\"Ilya Sutskever\\\") (2017–2023) * [Helen Toner](https://en.wikipedia.org/wiki/Helen_Toner \\\"Helen Toner\\\") (2021–2023) * [Shivon Zilis](https://en.wikipedia.org/wiki/Shivon_Zilis \\\"Shivon Zilis\\\") (2019–2023) * [Lawrence Summers](https://en.wikipedia.org/wiki/Lawrence_Summers \\\"Lawrence Summers\\\") (2023-2025) | | |\\n| [JVs](https://en.wikipedia.org/wiki/Joint_venture \\\"Joint venture\\\") | * [Stargate LLC](https://en.wikipedia.org/wiki/Stargate_LLC \\\"Stargate LLC\\\") |\\n| Related | * [ChatGPT in education](https://en.wikipedia.org/wiki/ChatGPT_in_education \\\"ChatGPT in education\\\") * [Apple Intelligence](https://en.wikipedia.org/wiki/Apple_Intelligence \\\"Apple Intelligence\\\") * _[AI Dungeon](https://en.wikipedia.org/wiki/AI\\\\_Dungeon \\\"AI Dungeon\\\")_ * [AutoGPT](https://en.wikipedia.org/wiki/AutoGPT \\\"AutoGPT\\\") * [GitHub Copilot](https://en.wikipedia.org/wiki/GitHub_Copilot \\\"GitHub Copilot\\\") * [Contrastive Language-Image Pre-training](https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre-training \\\"Contrastive Language-Image Pre-training\\\") * \\\"[Deep Learning](https://en.wikipedia.org/wiki/Deep_Learning_(South_Park) \\\"Deep Learning (South Park)\\\")\\\" * [LangChain](https://en.wikipedia.org/wiki/LangChain \\\"LangChain\\\") * [Microsoft Copilot](https://en.wikipedia.org/wiki/Microsoft_Copilot \\\"Microsoft Copilot\\\") * [OpenAI Five](https://en.wikipedia.org/wiki/OpenAI_Five \\\"OpenAI Five\\\") * [Transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture) \\\"Transformer (deep learning architecture)\\\") |\\n| * ![Image 11](https://upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/20px-Symbol_category_class.svg.png)[Category](https://en.wikipedia.org/wiki/Category:OpenAI \\\"Category:OpenAI\\\") |\\n\\n| * [v](https://en.wikipedia.org/wiki/Template:Generative_AI \\\"Template:Generative AI\\\") * [t](https://en.wikipedia.org/wiki/Template_talk:Generative_AI \\\"Template talk:Generative AI\\\") * [e](https://en.wikipedia.org/wiki/Special:EditPage/Template:Generative_AI \\\"Special:EditPage/Template:Generative AI\\\") [Generative AI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence \\\"Generative artificial intelligence\\\") |\\n| --- |\\n| Concepts | * [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder \\\"Autoencoder\\\") * [Deep learning](https://en.wikipedia.org/wiki/Deep_learning \\\"Deep learning\\\") * [Fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning) \\\"Fine-tuning (deep learning)\\\") * [Foundation model](https://en.wikipedia.org/wiki/Foundation_model \\\"Foundation model\\\") * [Generative adversarial network](https://en.wikipedia.org/wiki/Generative_adversarial_network \\\"Generative adversarial network\\\") * [Generative pre-trained transformer](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer \\\"Generative pre-trained transformer\\\") * [Large language model](https://en.wikipedia.org/wiki/Large_language_model \\\"Large language model\\\") * [Model Context Protocol](https://en.wikipedia.org/wiki/Model_Context_Protocol \\\"Model Context Protocol\\\") * [Neural network](https://en.wikipedia.org/wiki/Neural_network_(machine_learning) \\\"Neural network (machine learning)\\\") * [Prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering \\\"Prompt engineering\\\") * [Reinforcement learning from human feedback](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback \\\"Reinforcement learning from human feedback\\\") * [Retrieval-augmented generation](https://en.wikipedia.org/wiki/Retrieval-augmented_generation \\\"Retrieval-augmented generation\\\") * [Self-supervised learning](https://en.wikipedia.org/wiki/Self-supervised_learning \\\"Self-supervised learning\\\") * [Stochastic parrot](https://en.wikipedia.org/wiki/Stochastic_parrot \\\"Stochastic parrot\\\") * [Synthetic data](https://en.wikipedia.org/wiki/Synthetic_data \\\"Synthetic data\\\") * [Top-p sampling](https://en.wikipedia.org/wiki/Top-p_sampling \\\"Top-p sampling\\\") * [Transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture) \\\"Transformer (deep learning architecture)\\\") * [Variational autoencoder](https://en.wikipedia.org/wiki/Variational_autoencoder \\\"Variational autoencoder\\\") * [Vibe coding](https://en.wikipedia.org/wiki/Vibe_coding \\\"Vibe coding\\\") * [Vision transformer](https://en.wikipedia.org/wiki/Vision_transformer \\\"Vision transformer\\\") * [Word embedding](https://en.wikipedia.org/wiki/Word_embedding \\\"Word embedding\\\") |\\n| Chatbots | * [Character.ai](https://en.wikipedia.org/wiki/Character.ai \\\"Character.ai\\\") * [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT \\\"ChatGPT\\\") * [Copilot](https://en.wikipedia.org/wiki/Microsoft_Copilot \\\"Microsoft Copilot\\\") * [DeepSeek](https://en.wikipedia.org/wiki/DeepSeek_(chatbot) \\\"DeepSeek (chatbot)\\\") * [Ernie](https://en.wikipedia.org/wiki/Ernie_Bot \\\"Ernie Bot\\\") * [Gemini](https://en.wikipedia.org/wiki/Google_Gemini \\\"Google Gemini\\\") * [Grok](https://en.wikipedia.org/wiki/Grok_(chatbot) \\\"Grok (chatbot)\\\") * [Perplexity.ai](https://en.wikipedia.org/wiki/Perplexity.ai \\\"Perplexity.ai\\\") |\\n| Models | | Text | * [Claude](https://en.wikipedia.org/wiki/Claude_(language_model) \\\"Claude (language model)\\\") * [Gemini](https://en.wikipedia.org/wiki/Gemini_(language_model) \\\"Gemini (language model)\\\") * [Gemma](https://en.wikipedia.org/wiki/Gemma_(language_model) \\\"Gemma (language model)\\\") * [GPT](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer \\\"Generative pre-trained transformer\\\") * [1](https://en.wikipedia.org/wiki/GPT-1 \\\"GPT-1\\\") * [2](https://en.wikipedia.org/wiki/GPT-2 \\\"GPT-2\\\") * [3](https://en.wikipedia.org/wiki/GPT-3 \\\"GPT-3\\\") * [J](https://en.wikipedia.org/wiki/GPT-J \\\"GPT-J\\\") * [4](https://en.wikipedia.org/wiki/GPT-4 \\\"GPT-4\\\") * [4o](https://en.wikipedia.org/wiki/GPT-4o \\\"GPT-4o\\\") * [4.5](https://en.wikipedia.org/wiki/GPT-4.5 \\\"GPT-4.5\\\") * [4.1](https://en.wikipedia.org/wiki/GPT-4.1 \\\"GPT-4.1\\\") * [OSS](https://en.wikipedia.org/wiki/GPT-OSS \\\"GPT-OSS\\\") * [5](https://en.wikipedia.org/wiki/GPT-5 \\\"GPT-5\\\") * [5.1](https://en.wikipedia.org/wiki/GPT-5.1 \\\"GPT-5.1\\\") * [5.2](https://en.wikipedia.org/wiki/GPT-5.2 \\\"GPT-5.2\\\") * [Llama](https://en.wikipedia.org/wiki/Llama_(language_model) \\\"Llama (language model)\\\") * [o1](https://en.wikipedia.org/wiki/OpenAI_o1 \\\"OpenAI o1\\\") * [o3](https://en.wikipedia.org/wiki/OpenAI_o3 \\\"OpenAI o3\\\") * [o4-mini](https://en.wikipedia.org/wiki/OpenAI_o4-mini \\\"OpenAI o4-mini\\\") * [Qwen](https://en.wikipedia.org/wiki/Qwen \\\"Qwen\\\") * [Velvet](https://en.wikipedia.org/wiki/Velvet_AI \\\"Velvet AI\\\") | | --- | | Coding | * [Claude Code](https://en.wikipedia.org/wiki/Claude_Code \\\"Claude Code\\\") * [Cursor](https://en.wikipedia.org/wiki/Cursor_(code_editor) \\\"Cursor (code editor)\\\") * [Devstral](https://en.wikipedia.org/wiki/Mistral_AI \\\"Mistral AI\\\") * [GitHub Copilot](https://en.wikipedia.org/wiki/GitHub_Copilot \\\"GitHub Copilot\\\") * [Kimi](https://en.wikipedia.org/wiki/Kimi_(chatbot) \\\"Kimi (chatbot)\\\") * [Qwen3-Coder](https://en.wikipedia.org/wiki/Qwen \\\"Qwen\\\") * [Replit](https://en.wikipedia.org/wiki/Replit \\\"Replit\\\") | | [Image](https://en.wikipedia.org/wiki/Text-to-image_model \\\"Text-to-image model\\\") | * [Aurora](https://en.wikipedia.org/wiki/Aurora_(text-to-image_model) \\\"Aurora (text-to-image model)\\\") * [Firefly](https://en.wikipedia.org/wiki/Adobe_Firefly \\\"Adobe Firefly\\\") * [DALL-E](https://en.wikipedia.org/wiki/DALL-E \\\"DALL-E\\\") * [Flux](https://en.wikipedia.org/wiki/Flux_(text-to-image_model) \\\"Flux (text-to-image model)\\\") * [GPT Image](https://en.wikipedia.org/wiki/GPT_Image \\\"GPT Image\\\") * [Ideogram](https://en.wikipedia.org/wiki/Ideogram_(text-to-image_model) \\\"Ideogram (text-to-image model)\\\") * [Imagen](https://en.wikipedia.org/wiki/Imagen_(text-to-image_model) \\\"Imagen (text-to-image model)\\\") * [Nano Banana](https://en.wikipedia.org/wiki/Nano_Banana \\\"Nano Banana\\\") * [Midjourney](https://en.wikipedia.org/wiki/Midjourney \\\"Midjourney\\\") * [Qwen-Image](https://en.wikipedia.org/wiki/Qwen \\\"Qwen\\\") * [Recraft](https://en.wikipedia.org/wiki/Recraft \\\"Recraft\\\") * [Seedream](https://en.wikipedia.org/wiki/Seedream \\\"Seedream\\\") * [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion \\\"Stable Diffusion\\\") | | [Video](https://en.wikipedia.org/wiki/Text-to-video_model \\\"Text-to-video model\\\") | * [Dream Machine](https://en.wikipedia.org/wiki/Dream_Machine_(text-to-video_model) \\\"Dream Machine (text-to-video model)\\\") * [Hailuo AI](https://en.wikipedia.org/wiki/MiniMax_(company)#Hailuo_AI \\\"MiniMax (company)\\\") * [Kling](https://en.wikipedia.org/wiki/Kling_(text-to-video_model) \\\"Kling (text-to-video model)\\\") * [Runway Gen](https://en.wikipedia.org/wiki/Runway_(company)#Services_and_technologies \\\"Runway (company)\\\") * [Seedance](https://en.wikipedia.org/wiki/ByteDance \\\"ByteDance\\\") * [LTX-2](https://en.wikipedia.org/wiki/LTX-2 \\\"LTX-2\\\") * [Sora](https://en.wikipedia.org/wiki/Sora_(text-to-video_model) \\\"Sora (text-to-video model)\\\") * [Veo](https://en.wikipedia.org/wiki/Veo_(text-to-video_model) \\\"Veo (text-to-video model)\\\") * [Wan](https://en.wikipedia.org/wiki/Alibaba_Group#Cloud_computing_and_artificial_intelligence_technology \\\"Alibaba Group\\\") | | [Speech](https://en.wikipedia.org/wiki/Speech_synthesis#Text-to-speech_systems \\\"Speech synthesis\\\") | * [15.ai](https://en.wikipedia.org/wiki/15.ai \\\"15.ai\\\") * [Eleven](https://en.wikipedia.org/wiki/ElevenLabs#Products \\\"ElevenLabs\\\") * [MiniMax Speech 2.5](https://en.wikipedia.org/wiki/MiniMax_(company) \\\"MiniMax (company)\\\") * [WaveNet](https://en.wikipedia.org/wiki/WaveNet \\\"WaveNet\\\") | | Music | * [Eleven Music](https://en.wikipedia.org/wiki/ElevenLabs#Products \\\"ElevenLabs\\\") * [Endel](https://en.wikipedia.org/wiki/Endel_(app) \\\"Endel (app)\\\") * [Lyria](https://en.wikipedia.org/wiki/Google_DeepMind#Music_generation \\\"Google DeepMind\\\") * [Riffusion](https://en.wikipedia.org/wiki/Riffusion \\\"Riffusion\\\") * [Suno](https://en.wikipedia.org/wiki/Suno_(platform) \\\"Suno (platform)\\\") * [Udio](https://en.wikipedia.org/wiki/Udio \\\"Udio\\\") | |\\n| [Controversies](https://en.wikipedia.org/wiki/Artificial_intelligence_controversies \\\"Artificial intelligence controversies\\\") | * [Generative AI pornography](https://en.wikipedia.org/wiki/Generative_AI_pornography \\\"Generative AI pornography\\\") * [Deepfake pornography](https://en.wikipedia.org/wiki/Deepfake_pornography \\\"Deepfake pornography\\\") * [Taylor Swift's](https://en.wikipedia.org/wiki/Taylor_Swift_deepfake_pornography_controversy \\\"Taylor Swift deepfake pornography controversy\\\") * [Google Gemini image generation](https://en.wikipedia.org/wiki/Google_Gemini_image_generation_controversy \\\"Google Gemini image generation controversy\\\") * [Pause Giant AI Experiments](https://en.wikipedia.org/wiki/Pause_Giant_AI_Experiments:_An_Open_Letter \\\"Pause Giant AI Experiments: An Open Letter\\\") * [Removal of Sam Altman from OpenAI](https://en.wikipedia.org/wiki/Removal_of_Sam_Altman_from_OpenAI \\\"Removal of Sam Altman from OpenAI\\\") * [Statement on AI Risk](https://en.wikipedia.org/wiki/Statement_on_AI_Risk \\\"Statement on AI Risk\\\") * [Tay (chatbot)](https://en.wikipedia.org/wiki/Tay_(chatbot) \\\"Tay (chatbot)\\\") * _[Théâtre D'opéra Spatial](https://en.wikipedia.org/wiki/Th%C3%A9%C3%A2tre\\\\_D%27op%C3%A9ra\\\\_Spatial \\\"Théâtre D'opéra Spatial\\\")_ * [Voiceverse NFT plagiarism](https://en.wikipedia.org/wiki/Voiceverse_NFT_plagiarism_scandal \\\"Voiceverse NFT plagiarism scandal\\\") |\\n| [Agents](https://en.wikipedia.org/wiki/Intelligent_agent \\\"Intelligent agent\\\") | * [Agentforce](https://en.wikipedia.org/wiki/Salesforce#Artificial_intelligence \\\"Salesforce\\\") * [AutoGLM](https://en.wikipedia.org/wiki/Zhipu_AI#AutoGLM \\\"Zhipu AI\\\") * [AutoGPT](https://en.wikipedia.org/wiki/AutoGPT \\\"AutoGPT\\\") * [ChatGPT Agent](https://en.wikipedia.org/wiki/ChatGPT#Agents \\\"ChatGPT\\\") * [Devin AI](https://en.wikipedia.org/wiki/Devin_AI \\\"Devin AI\\\") * [Manus](https://en.wikipedia.org/wiki/Manus_(AI_agent) \\\"Manus (AI agent)\\\") * [OpenAI Codex](https://en.wikipedia.org/wiki/OpenAI_Codex \\\"OpenAI Codex\\\") * [Operator](https://en.wikipedia.org/wiki/OpenAI_Operator \\\"OpenAI Operator\\\") * [Replit Agent](https://en.wikipedia.org/wiki/Replit \\\"Replit\\\") |\\n| [Companies](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_companies \\\"List of artificial intelligence companies\\\") | * [Aleph Alpha](https://en.wikipedia.org/wiki/Aleph_Alpha \\\"Aleph Alpha\\\") * [Anthropic](https://en.wikipedia.org/wiki/Anthropic \\\"Anthropic\\\") * [Anysphere](https://en.wikipedia.org/wiki/Anysphere \\\"Anysphere\\\") * [Cognition AI](https://en.wikipedia.org/wiki/Cognition_AI \\\"Cognition AI\\\") * [Cohere](https://en.wikipedia.org/wiki/Cohere \\\"Cohere\\\") * [Contextual AI](https://en.wikipedia.org/wiki/Contextual_AI \\\"Contextual AI\\\") * [DeepSeek](https://en.wikipedia.org/wiki/DeepSeek \\\"DeepSeek\\\") * [EleutherAI](https://en.wikipedia.org/wiki/EleutherAI \\\"EleutherAI\\\") * [ElevenLabs](https://en.wikipedia.org/wiki/ElevenLabs \\\"ElevenLabs\\\") * [Google DeepMind](https://en.wikipedia.org/wiki/Google_DeepMind \\\"Google DeepMind\\\") * [HeyGen](https://en.wikipedia.org/wiki/HeyGen \\\"HeyGen\\\") * [Hugging Face](https://en.wikipedia.org/wiki/Hugging_Face \\\"Hugging Face\\\") * [Inflection AI](https://en.wikipedia.org/wiki/Inflection_AI \\\"Inflection AI\\\") * [Krikey AI](https://en.wikipedia.org/wiki/Krikey_AI \\\"Krikey AI\\\") * [Kuaishou](https://en.wikipedia.org/wiki/Kuaishou \\\"Kuaishou\\\") * [Lightricks](https://en.wikipedia.org/wiki/Lightricks \\\"Lightricks\\\") * [Luma Labs](https://en.wikipedia.org/wiki/Luma_Labs \\\"Luma Labs\\\") * [Meta AI](https://en.wikipedia.org/wiki/Meta_AI \\\"Meta AI\\\") * [MiniMax](https://en.wikipedia.org/wiki/MiniMax_(company) \\\"MiniMax (company)\\\") * [Mistral AI](https://en.wikipedia.org/wiki/Mistral_AI \\\"Mistral AI\\\") * [Moonshot AI](https://en.wikipedia.org/wiki/Moonshot_AI \\\"Moonshot AI\\\") * [OpenAI](https://en.wikipedia.org/wiki/OpenAI \\\"OpenAI\\\") * [Perplexity AI](https://en.wikipedia.org/wiki/Perplexity_AI \\\"Perplexity AI\\\") * [Runway](https://en.wikipedia.org/wiki/Runway_(company) \\\"Runway (company)\\\") * [Safe Superintelligence](https://en.wikipedia.org/wiki/Safe_Superintelligence_Inc. \\\"Safe Superintelligence Inc.\\\") * [Salesforce](https://en.wikipedia.org/wiki/Salesforce \\\"Salesforce\\\") * [Scale AI](https://en.wikipedia.org/wiki/Scale_AI \\\"Scale AI\\\") * [SoundHound](https://en.wikipedia.org/wiki/SoundHound \\\"SoundHound\\\") * [Stability AI](https://en.wikipedia.org/wiki/Stability_AI \\\"Stability AI\\\") * [StepFun](https://en.wikipedia.org/wiki/StepFun \\\"StepFun\\\") * [Synthesia](https://en.wikipedia.org/wiki/Synthesia_(company) \\\"Synthesia (company)\\\") * [Thinking Machines Lab](https://en.wikipedia.org/wiki/Thinking_Machines_Lab \\\"Thinking Machines Lab\\\") * [Upstage](https://en.wikipedia.org/wiki/Upstage_(company) \\\"Upstage (company)\\\") * [xAI](https://en.wikipedia.org/wiki/XAI_(company) \\\"XAI (company)\\\") * [Z.ai](https://en.wikipedia.org/wiki/Z.ai \\\"Z.ai\\\") |\\n| * ![Image 12](https://upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/20px-Symbol_category_class.svg.png)[Category](https://en.wikipedia.org/wiki/Category:Generative_artificial_intelligence \\\"Category:Generative artificial intelligence\\\") |\\n\\n[Portals](https://en.wikipedia.org/wiki/Wikipedia:Contents/Portals \\\"Wikipedia:Contents/Portals\\\"):\\n*   ![Image 13](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Industry5.svg/20px-Industry5.svg.png)[Companies](https://en.wikipedia.org/wiki/Portal:Companies \\\"Portal:Companies\\\")\\n*   [![Image 14: icon](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Octicons-terminal.svg/20px-Octicons-terminal.svg.png)](https://en.wikipedia.org/wiki/File:Octicons-terminal.svg)[Computer programming](https://en.wikipedia.org/wiki/Portal:Computer_programming \\\"Portal:Computer programming\\\")\\n*   [![Image 15: icon](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Crystal_Clear_app_linneighborhood.svg/20px-Crystal_Clear_app_linneighborhood.svg.png)](https://en.wikipedia.org/wiki/File:Crystal_Clear_app_linneighborhood.svg)[Internet](https://en.wikipedia.org/wiki/Portal:Internet \\\"Portal:Internet\\\")\\n*   [![Image 16: icon](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Noun-technology.svg/20px-Noun-technology.svg.png)](https://en.wikipedia.org/wiki/File:Noun-technology.svg)[Technology](https://en.wikipedia.org/wiki/Portal:Technology \\\"Portal:Technology\\\")\\n\\nRetrieved from \\\"[https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&oldid=1333105405](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&oldid=1333105405)\\\"\\n\\n[Categories](https://en.wikipedia.org/wiki/Help:Category \\\"Help:Category\\\"): \\n*   [OpenAI](https://en.wikipedia.org/wiki/Category:OpenAI \\\"Category:OpenAI\\\")\\n*   [Machine learning](https://en.wikipedia.org/wiki/Category:Machine_learning \\\"Category:Machine learning\\\")\\n\\nHidden categories: \\n*   [CS1 maint: multiple names: authors list](https://en.wikipedia.org/wiki/Category:CS1_maint:_multiple_names:_authors_list \\\"Category:CS1 maint: multiple names: authors list\\\")\\n*   [Webarchive template wayback links](https://en.wikipedia.org/wiki/Category:Webarchive_template_wayback_links \\\"Category:Webarchive template wayback links\\\")\\n*   [Articles with short description](https://en.wikipedia.org/wiki/Category:Articles_with_short_description \\\"Category:Articles with short description\\\")\\n*   [Short description matches Wikidata](https://en.wikipedia.org/wiki/Category:Short_description_matches_Wikidata \\\"Category:Short description matches Wikidata\\\")\\n*   [Wikipedia references cleanup from January 2026](https://en.wikipedia.org/wiki/Category:Wikipedia_references_cleanup_from_January_2026 \\\"Category:Wikipedia references cleanup from January 2026\\\")\\n*   [All articles needing references cleanup](https://en.wikipedia.org/wiki/Category:All_articles_needing_references_cleanup \\\"Category:All articles needing references cleanup\\\")\\n*   [Articles covered by WikiProject Wikify from January 2026](https://en.wikipedia.org/wiki/Category:Articles_covered_by_WikiProject_Wikify_from_January_2026 \\\"Category:Articles covered by WikiProject Wikify from January 2026\\\")\\n*   [All articles covered by WikiProject Wikify](https://en.wikipedia.org/wiki/Category:All_articles_covered_by_WikiProject_Wikify \\\"Category:All articles covered by WikiProject Wikify\\\")\\n*   [All articles with duplicate citations](https://en.wikipedia.org/wiki/Category:All_articles_with_duplicate_citations \\\"Category:All articles with duplicate citations\\\")\\n*   [All articles with unsourced statements](https://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements \\\"Category:All articles with unsourced statements\\\")\\n*   [Articles with unsourced statements from July 2025](https://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_July_2025 \\\"Category:Articles with unsourced statements from July 2025\\\")\\n\\n*    This page was last edited on 15 January 2026, at 19:19(UTC).\\n*   Text is available under the [Creative Commons Attribution-ShareAlike 4.0 License](https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License \\\"Wikipedia:Text of the Creative Commons Attribution-ShareAlike 4.0 International License\\\"); additional terms may apply. By using this site, you agree to the [Terms of Use](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use \\\"foundation:Special:MyLanguage/Policy:Terms of Use\\\") and [Privacy Policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy \\\"foundation:Special:MyLanguage/Policy:Privacy policy\\\"). Wikipedia® is a registered trademark of the [Wikimedia Foundation, Inc.](https://wikimediafoundation.org/), a non-profit organization.\\n\\n*   [Privacy policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)\\n*   [About Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:About)\\n*   [Disclaimers](https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer)\\n*   [Contact Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Contact_us)\\n*   [Legal & safety contacts](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Legal:Wikimedia_Foundation_Legal_and_Safety_Contact_Information)\\n*   [Code of Conduct](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct)\\n*   [Developers](https://developer.wikimedia.org/)\\n*   [Statistics](https://stats.wikimedia.org/#/en.wikipedia.org)\\n*   [Cookie statement](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement)\\n*   [Mobile view](https://en.wikipedia.org/w/index.php?title=Products_and_applications_of_OpenAI&mobileaction=toggle_view_mobile)\\n\\n*   [![Image 18: Wikimedia Foundation](https://en.wikipedia.org/static/images/footer/wikimedia.svg)](https://www.wikimedia.org/)\\n*   [![Image 19: Powered by MediaWiki](https://en.wikipedia.org/w/resources/assets/mediawiki_compact.svg)](https://www.mediawiki.org/)\\n\\nSearch\\n\\nSearch\\n\\n- [x] Toggle the table of contents \\n\\nProducts and applications of OpenAI\\n\\n[](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)[](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)[](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)[](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)[](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)[](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)[](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)\\n\\n1 language[Add topic](https://en.wikipedia.org/wiki/Products_and_applications_of_OpenAI#)\"}], \"response_time\": 11.99, \"request_id\": \"89c363b3-3926-402e-8d66-6da4b5f53378\"}\n"
          ]
        }
      ],
      "id": "h-zYQrB6383i"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary: Key Takeaways\n",
        "\n",
        "### What We Built\n",
        "An augmented LLM that can:\n",
        "- Decide when to use external tools\n",
        "- Execute web searches for current information\n",
        "- Return results to the user\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "| Concept | Description |\n",
        "|---------|-------------|\n",
        "| **@tool decorator** | Converts Python functions to LLM-callable tools |\n",
        "| **bind_tools()** | Attaches tools to an LLM |\n",
        "| **ToolNode** | Pre-built node that executes tool calls |\n",
        "| **tools_condition** | Pre-built routing based on tool_calls |\n",
        "\n",
        "### The Tool-Use Pattern\n",
        "\n",
        "```\n",
        "1. LLM receives query\n",
        "2. LLM decides: Can I answer directly, or do I need tools?\n",
        "3a. Direct answer → Return response → END\n",
        "3b. Need tools → Generate tool_call → ToolNode executes → Return results\n",
        "```\n",
        "\n",
        "### Important Limitation\n",
        "**This version has no feedback loop!** The tool results go to END, not back to the LLM.\n",
        "This means:\n",
        "- The LLM can't process tool results\n",
        "- No human-readable response from tool outputs\n",
        "- Can't chain multiple tool calls\n",
        "\n",
        "**Solution**: In the next notebook, we'll add a **feedback loop** to create a true AI Agent!\n",
        "\n",
        "### Next Steps\n",
        "Build a complete **Tool-Use AI Agent** with feedback loops that:\n",
        "- Processes tool results with the LLM\n",
        "- Generates human-readable responses\n",
        "- Can call multiple tools in sequence"
      ],
      "id": "6e8c4fb9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": null,
      "outputs": [],
      "id": "a895e9d8"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}